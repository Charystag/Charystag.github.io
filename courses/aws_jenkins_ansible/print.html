<!DOCTYPE HTML>
<html lang="fr" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Formation AWS Jenkins &amp; Ansible</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="aws/introduction.html"><strong aria-hidden="true">1.</strong> Présentation générale d'AWS</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="aws/sections/01_introduction.html"><strong aria-hidden="true">1.1.</strong> Introduction sur AWS</a></li><li class="chapter-item expanded "><a href="aws/sections/02_AWS_overview.html"><strong aria-hidden="true">1.2.</strong> Les Bases d'AWS</a></li><li class="chapter-item expanded "><a href="aws/sections/03_AWS_EC2.html"><strong aria-hidden="true">1.3.</strong> Les Instances EC2</a></li><li class="chapter-item expanded "><a href="aws/sections/04_AWS_S3.html"><strong aria-hidden="true">1.4.</strong> Les Buckets S3</a></li></ol></li><li class="chapter-item expanded "><a href="jenkins/introduction.html"><strong aria-hidden="true">2.</strong> Présentation générale de Jenkins</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="jenkins/sections/01_Introduction.html"><strong aria-hidden="true">2.1.</strong> Introduction sur Jenkins</a></li><li class="chapter-item expanded "><a href="jenkins/sections/02_First_Steps.html"><strong aria-hidden="true">2.2.</strong> Premiers pas avec Jenkins</a></li><li class="chapter-item expanded "><a href="jenkins/sections/03_Pipelines.html"><strong aria-hidden="true">2.3.</strong> Les bases des Pipelines</a></li><li class="chapter-item expanded "><a href="jenkins/sections/04_Pipelines_Advanced.html"><strong aria-hidden="true">2.4.</strong> Plus de pipelines!</a></li><li class="chapter-item expanded "><a href="jenkins/sections/05_modules_libraries.html"><strong aria-hidden="true">2.5.</strong> Modules et librairies dans Jenkins</a></li><li class="chapter-item expanded "><a href="jenkins/sections/06_AWS_automation.html"><strong aria-hidden="true">2.6.</strong> Automatisation dans AWS</a></li><li class="chapter-item expanded "><a href="jenkins/sections/07_Real_Life_Example.html"><strong aria-hidden="true">2.7.</strong> Application concrète</a></li></ol></li><li class="chapter-item expanded "><a href="ansible/introduction.html"><strong aria-hidden="true">3.</strong> Présentation générale d'Ansible</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ansible/sections/01_Introduction.html"><strong aria-hidden="true">3.1.</strong> Introduction à Ansible</a></li><li class="chapter-item expanded "><a href="ansible/sections/02_Basics.html"><strong aria-hidden="true">3.2.</strong> Bases d'ansible</a></li><li class="chapter-item expanded "><a href="ansible/sections/03_Automation.html"><strong aria-hidden="true">3.3.</strong> Automatisation avec ansible</a></li><li class="chapter-item expanded "><a href="ansible/sections/04_S3_management.html"><strong aria-hidden="true">3.4.</strong> Gestion de S3 avec ansible</a></li><li class="chapter-item expanded "><a href="ansible/sections/05_Jenkins_AWS_Pipeline.html"><strong aria-hidden="true">3.5.</strong> Ansible dans une pipeline Jenkins</a></li><li class="chapter-item expanded "><a href="ansible/sections/06_Best_Practices.html"><strong aria-hidden="true">3.6.</strong> Meilleures pratiques pour Ansible</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Formation AWS Jenkins &amp; Ansible</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <p><strong>Présentation Générale d'AWS (Amazon Web Services)</strong></p>
<hr />
<h3 id="introduction"><a class="header" href="#introduction">Introduction</a></h3>
<p>Amazon Web Services (AWS) est une plateforme de services cloud créée par Amazon. Lancée en 2006, elle propose des solutions de calcul, de stockage, de bases de données, d'intelligence artificielle, et bien plus, pour des entreprises de toutes tailles. AWS permet de construire des infrastructures évolutives et flexibles, de façon sécurisée, et avec des coûts ajustés à la consommation.</p>
<hr />
<h3 id="les-principaux-services-aws"><a class="header" href="#les-principaux-services-aws">Les Principaux Services AWS</a></h3>
<p>AWS compte plus de 200 services répartis en plusieurs catégories :</p>
<ol>
<li>
<p><strong>Calcul (Compute)</strong> : Ces services permettent d'héberger et d'exécuter des applications, de provisionner des serveurs, ou de gérer des conteneurs et des fonctions sans serveur.</p>
<ul>
<li><strong>EC2 (Elastic Compute Cloud)</strong> : Service de machines virtuelles pour exécuter des applications sur des serveurs configurables.</li>
<li><strong>Lambda</strong> : Service de calcul sans serveur pour exécuter du code en réponse à des événements sans provisionner de serveurs.</li>
<li><strong>ECS (Elastic Container Service)</strong> et <strong>EKS (Elastic Kubernetes Service)</strong> : Services pour l'orchestration de conteneurs Docker.</li>
</ul>
</li>
<li>
<p><strong>Stockage (Storage)</strong> : AWS propose plusieurs solutions de stockage pour répondre aux besoins de performance, de sécurité et d'évolutivité des données.</p>
<ul>
<li><strong>S3 (Simple Storage Service)</strong> : Stockage d'objets haute disponibilité pour les données de tout type, avec des options de gestion du cycle de vie.</li>
<li><strong>EBS (Elastic Block Store)</strong> : Stockage de type bloc pour les instances EC2, destiné aux applications exigeant une faible latence.</li>
<li><strong>Glacier</strong> : Service de stockage à faible coût pour l'archivage et la sauvegarde des données.</li>
</ul>
</li>
<li>
<p><strong>Bases de Données</strong> : AWS offre des bases de données relationnelles, non relationnelles et des bases de données spécialisées.</p>
<ul>
<li><strong>RDS (Relational Database Service)</strong> : Service géré pour les bases de données relationnelles comme MySQL, PostgreSQL et Oracle.</li>
<li><strong>DynamoDB</strong> : Base de données NoSQL rapide et entièrement gérée.</li>
<li><strong>Redshift</strong> : Service de data warehouse pour l'analyse de données à grande échelle.</li>
</ul>
</li>
<li>
<p><strong>Mise en Réseau (Networking)</strong> : Les services de réseau d'AWS permettent de gérer les connexions et la sécurité des infrastructures cloud.</p>
<ul>
<li><strong>VPC (Virtual Private Cloud)</strong> : Service permettant de créer un réseau privé dans le cloud.</li>
<li><strong>Route 53</strong> : Service DNS pour la gestion des noms de domaine et du routage des requêtes.</li>
<li><strong>CloudFront</strong> : Réseau de distribution de contenu (CDN) pour la diffusion de contenu avec faible latence.</li>
</ul>
</li>
<li>
<p><strong>Sécurité et Identité</strong> : AWS propose des outils de gestion des identités, des accès et des contrôles de sécurité.</p>
<ul>
<li><strong>IAM (Identity and Access Management)</strong> : Gestion des utilisateurs et des permissions pour contrôler l'accès aux ressources AWS.</li>
<li><strong>KMS (Key Management Service)</strong> : Service de gestion des clés de chiffrement pour sécuriser les données.</li>
<li><strong>GuardDuty</strong> et <strong>Inspector</strong> : Services de détection des menaces et d'analyse de sécurité.</li>
</ul>
</li>
<li>
<p><strong>Outils d’Analyse et de Big Data</strong> : AWS propose des outils pour l’analyse de données, le traitement des big data et l’apprentissage automatique.</p>
<ul>
<li><strong>EMR (Elastic MapReduce)</strong> : Service de traitement de big data compatible avec Hadoop et Spark.</li>
<li><strong>Athena</strong> : Service d’interrogation de données stockées dans S3 avec SQL.</li>
<li><strong>SageMaker</strong> : Plateforme pour développer, entraîner et déployer des modèles de machine learning.</li>
</ul>
</li>
<li>
<p><strong>Outils DevOps et CI/CD</strong> : AWS offre des outils pour automatiser le déploiement, la surveillance et la gestion des applications.</p>
<ul>
<li><strong>CodePipeline</strong> : Orchestration des étapes de CI/CD pour automatiser le déploiement de logiciels.</li>
<li><strong>CloudFormation</strong> : Infrastructure-as-code pour définir et provisionner l’infrastructure.</li>
<li><strong>CloudWatch</strong> : Surveillance des ressources et applications AWS.</li>
</ul>
</li>
</ol>
<hr />
<h3 id="avantages-daws"><a class="header" href="#avantages-daws">Avantages d’AWS</a></h3>
<ol>
<li><strong>Évolutivité</strong> : AWS permet de démarrer avec de petites ressources et de les augmenter en fonction de la demande.</li>
<li><strong>Tarification à la consommation</strong> : AWS facture uniquement les ressources utilisées, avec des options de réduction des coûts grâce aux instances réservées et à l'optimisation des ressources.</li>
<li><strong>Sécurité et conformité</strong> : AWS propose des services de sécurité avancés et répond à de nombreuses normes de conformité, notamment SOC, PCI-DSS, et GDPR.</li>
<li><strong>Disponibilité mondiale</strong> : AWS est réparti sur plusieurs régions géographiques dans le monde, offrant une disponibilité et une tolérance aux pannes accrues.</li>
<li><strong>Flexibilité et choix</strong> : Avec des centaines de services disponibles, AWS permet de choisir les outils et solutions les plus adaptés à chaque besoin technique.</li>
</ol>
<hr />
<h3 id="cas-dusage-courants"><a class="header" href="#cas-dusage-courants">Cas d'Usage Courants</a></h3>
<ol>
<li><strong>Hébergement de Sites Web et Applications</strong> : AWS est utilisé pour héberger des sites web et des applications web évolutifs grâce à EC2, S3, et CloudFront.</li>
<li><strong>Big Data et Analyse</strong> : Les entreprises utilisent AWS pour collecter, stocker et analyser des données en temps réel avec EMR, Redshift, et Athena.</li>
<li><strong>Applications Serverless</strong> : Grâce à AWS Lambda et aux API Gateway, il est possible de créer des applications sans infrastructure de serveur.</li>
<li><strong>Machine Learning et IA</strong> : AWS SageMaker permet aux développeurs et data scientists de créer et déployer des modèles d’intelligence artificielle rapidement.</li>
<li><strong>Disaster Recovery et Sauvegarde</strong> : AWS offre des options de sauvegarde et de récupération de données pour garantir la résilience des infrastructures, avec des services comme S3 et Glacier.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="1-introduction"><a class="header" href="#1-introduction">1. <strong>Introduction</strong></a></h2>
<p>Ce guide s’adresse aux étudiants en master spécialisé en <strong>cloud computing</strong> et <strong>ingénierie des données</strong> souhaitant maîtriser trois outils incontournables pour l’automatisation et le DevOps : <strong>Amazon Web Services (AWS)</strong>, <strong>Jenkins</strong>, et <strong>Ansible</strong>. Nous partirons des concepts de base pour progresser vers des configurations avancées et une intégration complète, idéale pour des infrastructures cloud et des flux de données.</p>
<p>En combinant AWS pour les ressources cloud scalables, Jenkins pour l’automatisation des pipelines CI/CD, et Ansible pour la gestion de configuration, ce guide vise à développer des compétences essentielles pour concevoir des environnements résilients et optimisés, adaptés aux exigences des projets modernes en cloud et données.</p>
<hr />
<h3 id="11-objectif-du-document"><a class="header" href="#11-objectif-du-document">1.1 <strong>Objectif du document</strong></a></h3>
<p>Ce document vise à offrir une compréhension complète et progressive d’AWS, Jenkins et Ansible pour construire des infrastructures cloud modernes et automatiser le cycle de vie du développement, de la configuration au déploiement continu. Ensemble, ces technologies permettent une gestion agile et efficace des ressources dans le cloud.</p>
<hr />
<h3 id="12-public-cible-et-prérequis"><a class="header" href="#12-public-cible-et-prérequis">1.2 <strong>Public cible et prérequis</strong></a></h3>
<p>Ce guide est conçu pour les étudiants en master dans les domaines du <strong>cloud computing</strong> et de l’<strong>ingénierie des données</strong>, avec un intérêt pour les pratiques DevOps. Les prérequis recommandés sont :</p>
<ul>
<li><strong>Linux</strong> et commandes de base, utiles pour naviguer dans les environnements cloud.</li>
<li><strong>Notions de réseau</strong> : compréhension de TCP/IP et SSH pour les configurations réseau sécurisées.</li>
<li><strong>Scripts et programmation</strong> (comme Bash ou Python) pour faciliter l'utilisation d'Ansible et Jenkins.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="2-vue-densemble-daws"><a class="header" href="#2-vue-densemble-daws">2. <strong>Vue d'ensemble d'AWS</strong></a></h2>
<h3 id="21-quest-ce-quaws-"><a class="header" href="#21-quest-ce-quaws-">2.1 <strong>Qu'est-ce qu'AWS ?</strong></a></h3>
<p>Amazon Web Services (AWS) est une plateforme de <strong>cloud computing</strong> qui offre un large éventail de services permettant aux entreprises de gérer des applications et des données de manière évolutive, sécurisée et sur demande. AWS permet de louer des ressources (par exemple, puissance de calcul, stockage, bases de données) au lieu d’acheter une infrastructure physique, ce qui facilite la flexibilité opérationnelle et réduit les coûts. Aujourd’hui, AWS est le leader mondial du cloud, utilisé dans des secteurs allant de la finance à la santé en passant par les technologies de l'information.</p>
<p><img src="aws/sections/../images/02_AWS_overview/aws-advantages.png" alt="Main advantages of AWS cloud" /></p>
<hr />
<h3 id="22-principaux-concepts-de-la-gestion-cloud-avec-aws"><a class="header" href="#22-principaux-concepts-de-la-gestion-cloud-avec-aws">2.2 <strong>Principaux concepts de la gestion cloud avec AWS</strong></a></h3>
<h4 id="introduction-au-cloud-computing"><a class="header" href="#introduction-au-cloud-computing">Introduction au Cloud Computing</a></h4>
<p>Le <strong>cloud computing</strong> est un modèle qui permet d'accéder à des ressources informatiques à la demande, sans la gestion directe d'infrastructures physiques. Cela offre des avantages tels que la <strong>scalabilité</strong> instantanée, la <strong>sécurité</strong>, et la possibilité d'économiser des coûts en ne payant que pour les ressources utilisées.</p>
<h4 id="vue-densemble-des-services-aws"><a class="header" href="#vue-densemble-des-services-aws">Vue d’ensemble des services AWS</a></h4>
<p>AWS offre une large gamme de services, répartis dans plusieurs catégories :</p>
<ul>
<li><strong>Calcul (EC2, Lambda)</strong> : pour héberger et exécuter des applications, des instances virtuelles et des fonctions sans serveur.</li>
<li><strong>Stockage (S3, EBS)</strong> : pour le stockage sécurisé des données avec de nombreuses options de résilience.</li>
<li><strong>Bases de données (RDS, DynamoDB)</strong> : pour la gestion de données structurées et non structurées.</li>
<li><strong>Réseau et contenu (VPC, CloudFront)</strong> : pour contrôler l’accès et distribuer du contenu efficacement et de manière sécurisée.</li>
<li><strong>Outils de gestion et surveillance (CloudWatch, CloudTrail)</strong> : pour surveiller et gérer l’activité des services AWS.</li>
</ul>
<p><img src="aws/sections/../images/02_AWS_overview/aws-console.jpg" alt="AWS console" /></p>
<hr />
<h3 id="23-principaux-services-aws"><a class="header" href="#23-principaux-services-aws">2.3 <strong>Principaux services AWS</strong></a></h3>
<p>Examinons certains des services AWS les plus utilisés, essentiels pour toute infrastructure cloud.</p>
<h4 id="calcul--amazon-ec2-et-aws-lambda"><a class="header" href="#calcul--amazon-ec2-et-aws-lambda">Calcul : Amazon EC2 et AWS Lambda</a></h4>
<ul>
<li><strong>Amazon EC2 (Elastic Compute Cloud)</strong> : Ce service permet de créer et gérer des instances (machines virtuelles) pour exécuter des applications. Il prend en charge une grande variété de types d’instances et offre une flexibilité inégalée dans la configuration des ressources.</li>
<li><strong>AWS Lambda</strong> : Ce service sans serveur permet d’exécuter du code en réponse à des événements sans avoir besoin de gérer des serveurs sous-jacents. Idéal pour les applications basées sur des événements, il fonctionne sur un modèle de facturation à l'utilisation, garantissant ainsi des coûts contrôlés.</li>
</ul>
<h4 id="stockage--amazon-s3-et-amazon-ebs"><a class="header" href="#stockage--amazon-s3-et-amazon-ebs">Stockage : Amazon S3 et Amazon EBS</a></h4>
<ul>
<li><strong>Amazon S3 (Simple Storage Service)</strong> : Un service de stockage d'objets offrant une durabilité de 99,999999999% et la capacité de stocker une quantité illimitée de données. S3 est hautement disponible, sécurisé, et flexible, parfait pour la gestion des sauvegardes, de l’archivage, ou des données de big data.</li>
<li><strong>Amazon EBS (Elastic Block Store)</strong> : Conçu pour être utilisé avec EC2, EBS fournit des disques persistants que les instances peuvent monter comme stockage local. Idéal pour les applications qui nécessitent des performances élevées et une persistance des données.</li>
</ul>
<h4 id="bases-de-données--amazon-rds-et-amazon-dynamodb"><a class="header" href="#bases-de-données--amazon-rds-et-amazon-dynamodb">Bases de données : Amazon RDS et Amazon DynamoDB</a></h4>
<ul>
<li><strong>Amazon RDS (Relational Database Service)</strong> : Un service géré pour les bases de données relationnelles comme MySQL, PostgreSQL, et Oracle, facilitant la mise en place, la maintenance et l’extensibilité des bases de données relationnelles.</li>
<li><strong>Amazon DynamoDB</strong> : Une base de données NoSQL entièrement gérée, conçue pour un stockage rapide et scalable de données non structurées, idéale pour les applications web et mobiles.</li>
</ul>
<p><img src="aws/sections/../images/02_AWS_overview/aws-components.png" alt="AWS Components" /></p>
<hr />
<h3 id="24-gestion-des-ressources-sécurité-et-facturation-dans-aws"><a class="header" href="#24-gestion-des-ressources-sécurité-et-facturation-dans-aws">2.4 <strong>Gestion des ressources, sécurité et facturation dans AWS</strong></a></h3>
<h4 id="gestion-des-ressources"><a class="header" href="#gestion-des-ressources">Gestion des ressources</a></h4>
<p>Avec AWS, la gestion des ressources est centralisée via la <strong>console AWS Management Console</strong> et l’<strong>API AWS CLI</strong> (Command Line Interface). Ces outils offrent une vue d'ensemble pour surveiller les ressources, gérer les configurations, et automatiser les tâches.</p>
<h4 id="sécurité-et-conformité"><a class="header" href="#sécurité-et-conformité">Sécurité et conformité</a></h4>
<p>AWS propose des services de sécurité intégrés et rigoureux pour garantir la conformité aux normes industrielles :</p>
<ul>
<li><strong>IAM (Identity and Access Management)</strong> : Permet la gestion des utilisateurs, des rôles et des autorisations, assurant un contrôle strict de l'accès aux ressources.</li>
<li><strong>AWS KMS (Key Management Service)</strong> : Permet de gérer les clés de chiffrement pour protéger les données stockées.</li>
<li><strong>CloudTrail</strong> : Enregistre les actions des utilisateurs et des services, offrant une piste d’audit essentielle pour la sécurité et la conformité.</li>
</ul>
<h4 id="facturation-et-gestion-des-coûts"><a class="header" href="#facturation-et-gestion-des-coûts">Facturation et gestion des coûts</a></h4>
<p>AWS propose des outils puissants pour suivre et optimiser les dépenses :</p>
<ul>
<li><strong>AWS Billing</strong> : Un tableau de bord permettant de visualiser et de gérer les dépenses en temps réel.</li>
<li><strong>AWS Cost Explorer</strong> : Permet une analyse avancée des coûts pour identifier les tendances et optimiser les dépenses.</li>
<li><strong>Budgets AWS</strong> : Permet de définir des seuils de dépenses et de recevoir des alertes en cas de dépassement, pour une gestion proactive des coûts.</li>
</ul>
<p><img src="aws/sections/../images/02_AWS_overview/aws-billing.png" alt="AWS Billing" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="3-amazon-ec2-elastic-compute-cloud"><a class="header" href="#3-amazon-ec2-elastic-compute-cloud">3. <strong>Amazon EC2 (Elastic Compute Cloud)</strong></a></h2>
<h3 id="31-introduction-à-ec2"><a class="header" href="#31-introduction-à-ec2">3.1 <strong>Introduction à EC2</strong></a></h3>
<h4 id="définition-et-utilité"><a class="header" href="#définition-et-utilité">Définition et utilité</a></h4>
<p>Amazon EC2 (Elastic Compute Cloud) est un service qui fournit des instances de calcul virtualisées dans le cloud. Il permet aux utilisateurs de louer des serveurs virtuels pour exécuter des applications, facilitant la scalabilité et la flexibilité tout en réduisant le coût de possession d'infrastructure.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html">AWS EC2 Documentation - Qu'est-ce qu'Amazon EC2 ?</a> [<a href="https://docs.aws.amazon.com/fr_fr/AWSEC2/latest/UserGuide/concepts.html"><em>fr</em></a>]</li>
</ul>
<h4 id="principales-fonctionnalités-et-cas-dutilisation"><a class="header" href="#principales-fonctionnalités-et-cas-dutilisation">Principales fonctionnalités et cas d’utilisation</a></h4>
<p>Les principales fonctionnalités incluent :</p>
<ul>
<li><strong>Scalabilité élastique</strong> : permet d’ajouter ou de supprimer des instances en fonction de la charge.</li>
<li><strong>Types d'instances variés</strong> : choix d'instances adaptées aux besoins de calcul, de mémoire, ou de stockage spécifiques.</li>
<li><strong>Facturation à la demande</strong> : paiement pour le temps utilisé, avec des options d'instances réservées et spot pour des économies supplémentaires.</li>
</ul>
<p><strong>Cas d’utilisation</strong> :</p>
<ul>
<li>Hébergement de sites web et d'applications.</li>
<li>Exécution d'analyses de données.</li>
<li>Hébergement de serveurs de développement/test.</li>
</ul>
<h4 id="image-suggestion"><a class="header" href="#image-suggestion">Image Suggestion:</a></h4>
<ul>
<li><strong>Image 1</strong>: Diagramme montrant une instance EC2 connectée à d'autres services AWS (par exemple, une base de données RDS ou un stockage S3) pour illustrer l'intégration et l'interconnectivité d'EC2 dans une infrastructure cloud.</li>
</ul>
<hr />
<h3 id="32-prise-en-main-dec2"><a class="header" href="#32-prise-en-main-dec2">3.2 <strong>Prise en main d'EC2</strong></a></h3>
<h4 id="création-dun-compte-aws"><a class="header" href="#création-dun-compte-aws">Création d'un compte AWS</a></h4>
<p>Pour utiliser EC2, il faut d'abord créer un compte AWS. Le processus d’inscription demande des informations de base et un moyen de paiement.</p>
<ul>
<li><a href="https://repost.aws/knowledge-center/create-and-activate-aws-account">Guide de création de compte AWS</a> [<a href="https://repost.aws/fr/knowledge-center/create-and-activate-aws-account"><em>fr</em></a>]</li>
</ul>
<h4 id="navigation-dans-le-tableau-de-bord-ec2"><a class="header" href="#navigation-dans-le-tableau-de-bord-ec2">Navigation dans le tableau de bord EC2</a></h4>
<p>Une fois connecté, le <strong>tableau de bord EC2</strong> présente les différentes options d’instances, le suivi des volumes EBS, la gestion des IP élastiques, et d'autres outils.</p>
<h4 id="lancement-et-connexion-à-une-instance-ec2"><a class="header" href="#lancement-et-connexion-à-une-instance-ec2">Lancement et connexion à une instance EC2</a></h4>
<ol>
<li><strong>Lancer une instance</strong> : choisir le type d'instance, le système d'exploitation, et les options de configuration de sécurité.</li>
<li><strong>Connexion</strong> : une fois l’instance lancée, vous pouvez vous connecter via SSH.</li>
</ol>
<ul>
<li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html">Guide de démarrage avec Amazon EC2</a> [<a href="https://docs.aws.amazon.com/fr_fr/AWSEC2/latest/UserGuide/EC2_GetStarted.html"><em>fr</em></a>]</li>
</ul>
<h4 id="image-suggestion-1"><a class="header" href="#image-suggestion-1">Image Suggestion:</a></h4>
<ul>
<li><strong>Image 2</strong>: Capture d'écran du tableau de bord EC2 montrant le processus de lancement d'une nouvelle instance. Cette image devrait inclure l'interface de sélection du type d’instance pour guider les nouveaux utilisateurs.</li>
</ul>
<hr />
<h3 id="33-types-dinstances"><a class="header" href="#33-types-dinstances">3.3 <strong>Types d'instances</strong></a></h3>
<h4 id="présentation-des-familles-dinstances-ec2"><a class="header" href="#présentation-des-familles-dinstances-ec2">Présentation des familles d'instances EC2</a></h4>
<p>Amazon EC2 propose plusieurs familles d'instances adaptées à différents besoins :</p>
<ul>
<li>
<p><strong>Généraliste</strong> : Instances de type "t2", "t3" (ex. t3.micro) pour des charges de travail équilibrées.</p>
</li>
<li>
<p><strong>Optimisé pour le calcul</strong> : Instances de type "c5" pour les calculs intensifs.</p>
</li>
<li>
<p><strong>Optimisé pour la mémoire</strong> : Instances "r5" pour des applications nécessitant beaucoup de mémoire.</p>
</li>
<li>
<p><strong>Optimisé pour le stockage</strong> : Instances "i3" pour des applications nécessitant des performances de stockage élevées.</p>
</li>
<li>
<p><a href="https://aws.amazon.com/ec2/instance-types/">Documentation sur les types d'instances Amazon EC2</a> [<a href="https://aws.amazon.com/fr/ec2/instance-types/"><em>fr</em></a>]</p>
</li>
</ul>
<h4 id="choix-du-type-dinstance-adapté-aux-besoins"><a class="header" href="#choix-du-type-dinstance-adapté-aux-besoins">Choix du type d'instance adapté aux besoins</a></h4>
<p>Le choix du type d'instance dépend des besoins de l’application. Pour un site web simple, un t2.micro suffira, tandis qu'une application d'apprentissage automatique pourrait nécessiter une instance GPU comme p3.</p>
<h4 id="image-suggestion-2"><a class="header" href="#image-suggestion-2">Image Suggestion:</a></h4>
<ul>
<li><strong>Image 3</strong>: Tableau comparatif des types d’instances EC2 avec leurs caractéristiques principales (vCPU, RAM, EBS, etc.). Ce tableau aidera les utilisateurs à comprendre les différences entre les familles d’instances.</li>
</ul>
<hr />
<h3 id="34-réseau-et-sécurité"><a class="header" href="#34-réseau-et-sécurité">3.4 <strong>Réseau et sécurité</strong></a></h3>
<h4 id="groupes-de-sécurité-et-pare-feu"><a class="header" href="#groupes-de-sécurité-et-pare-feu">Groupes de sécurité et pare-feu</a></h4>
<p>Les <strong>groupes de sécurité</strong> contrôlent le trafic entrant et sortant des instances EC2. Chaque instance peut avoir plusieurs groupes de sécurité associés.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-security-groups.html">Guide sur les groupes de sécurité EC2</a> [<a href="https://docs.aws.amazon.com/fr_fr/AWSEC2/latest/UserGuide/ec2-security-groups.html"><em>fr</em></a>]</li>
</ul>
<h4 id="ip-élastiques-et-accès-ssh"><a class="header" href="#ip-élastiques-et-accès-ssh">IP élastiques et accès SSH</a></h4>
<p>Les <strong>IP élastiques</strong> permettent d’avoir une adresse IP fixe associée à une instance EC2. La connexion SSH permet d'accéder aux instances Linux.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html">Documentation sur les IP élastiques et l'accès SSH</a> [<a href="https://docs.aws.amazon.com/fr_fr/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html"><em>fr</em></a>]</li>
</ul>
<h4 id="gestion-des-clés-de-sécurité"><a class="header" href="#gestion-des-clés-de-sécurité">Gestion des clés de sécurité</a></h4>
<p>Les <strong>paires de clés</strong> sont utilisées pour l’authentification lors de la connexion aux instances. AWS génère une clé privée qui doit être conservée en sécurité par l’utilisateur.</p>
<h4 id="image-suggestion-3"><a class="header" href="#image-suggestion-3">Image Suggestion:</a></h4>
<ul>
<li><strong>Image 4</strong>: Capture d’écran de la configuration d’un groupe de sécurité dans la console AWS, montrant comment définir les règles de trafic entrant pour autoriser le SSH (port 22).</li>
</ul>
<hr />
<h3 id="35-options-de-stockage"><a class="header" href="#35-options-de-stockage">3.5 <strong>Options de stockage</strong></a></h3>
<h4 id="ebs-elastic-block-store"><a class="header" href="#ebs-elastic-block-store">EBS (Elastic Block Store)</a></h4>
<p><strong>EBS</strong> est un stockage persistant qui peut être attaché à une instance EC2. Les volumes EBS sont idéaux pour stocker des données nécessitant une haute disponibilité et des sauvegardes fréquentes.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEBS.html">Guide d'utilisation d'Amazon EBS</a> [<a href="https://docs.aws.amazon.com/fr_fr/AWSEC2/latest/UserGuide/AmazonEBS.html"><em>fr</em></a>]</li>
</ul>
<h4 id="instance-store"><a class="header" href="#instance-store">Instance Store</a></h4>
<p>Le <strong>Instance Store</strong> offre un stockage temporaire qui n'est disponible que pendant la durée de vie de l'instance. Il convient aux applications nécessitant un stockage local rapide, mais non persistant.</p>
<h4 id="création-et-attachement-des-volumes-ebs"><a class="header" href="#création-et-attachement-des-volumes-ebs">Création et attachement des volumes EBS</a></h4>
<p>Les volumes EBS peuvent être créés et attachés facilement via la console EC2. Une fois attachés, ils apparaissent comme des disques locaux sur l’instance.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-attaching-volume.html">Attachement de volumes EBS</a> [<a href="https://docs.aws.amazon.com/fr_fr/AWSEC2/latest/UserGuide/ebs-attaching-volume.html"><em>fr</em></a>]</li>
</ul>
<h4 id="image-suggestion-4"><a class="header" href="#image-suggestion-4">Image Suggestion:</a></h4>
<ul>
<li><strong>Image 5</strong>: Capture d'écran montrant la création d'un volume EBS dans la console EC2. Cela devrait inclure la sélection de la taille et du type de volume pour guider les utilisateurs.</li>
</ul>
<hr />
<h3 id="36-concepts-avancés-dec2"><a class="header" href="#36-concepts-avancés-dec2">3.6 <strong>Concepts avancés d'EC2</strong></a></h3>
<h4 id="auto-scaling-et-équilibrage-de-charge"><a class="header" href="#auto-scaling-et-équilibrage-de-charge">Auto-scaling et équilibrage de charge</a></h4>
<p><strong>Auto Scaling</strong> ajuste automatiquement le nombre d’instances en fonction de la demande. <strong>Elastic Load Balancing (ELB)</strong> répartit le trafic entre les instances pour assurer une haute disponibilité et une tolérance aux pannes.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html">Documentation sur Auto Scaling</a> [<a href="https://docs.aws.amazon.com/fr_fr/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html"><em>fr</em></a>]</li>
<li><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/what-is-load-balancing.html">Documentation sur Elastic Load Balancing</a> [<a href="https://docs.aws.amazon.com/fr_fr/elasticloadbalancing/latest/userguide/what-is-load-balancing.html"><em>fr</em></a>]</li>
</ul>
<h4 id="instances-spot-et-réservées"><a class="header" href="#instances-spot-et-réservées">Instances Spot et réservées</a></h4>
<ul>
<li>
<p><strong>Instances Spot</strong> : accès à des instances à tarif réduit, idéal pour les charges de travail flexibles.</p>
</li>
<li>
<p><strong>Instances réservées</strong> : engagement sur un ou trois ans pour obtenir une réduction de coût.</p>
</li>
<li>
<p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-pricing.html">Guide des Instances Spot et Réservées</a> [<a href="https://docs.aws.amazon.com/fr_fr/AWSEC2/latest/UserGuide/ec2-pricing.html"><em>fr</em></a>]</p>
</li>
</ul>
<h4 id="groupes-de-placement-ec2"><a class="header" href="#groupes-de-placement-ec2">Groupes de placement EC2</a></h4>
<p>Les <strong>Groupes de placement</strong> permettent de contrôler la disposition des instances pour des charges de travail nécessitant une faible latence ou une bande passante élevée.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html">Documentation sur les Groupes de placement</a> [<a href="https://docs.aws.amazon.com/fr_fr/AWSEC2/latest/UserGuide/placement-groups.html"><em>fr</em></a>]</li>
</ul>
<h4 id="image-suggestion-5"><a class="header" href="#image-suggestion-5">Image Suggestion:</a></h4>
<ul>
<li><strong>Image 6</strong>: Diagramme montrant le fonctionnement d'un groupe Auto Scaling avec un ELB distribuant le trafic. Cela permet de visualiser l’évolutivité automatique d’EC2.</li>
</ul>
<hr />
<p>Cette section maintenant enrichie de liens multilingues devrait être claire et exhaustive pour les utilisateurs cherchant à explorer Amazon EC2.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="4-amazon-s3-simple-storage-service"><a class="header" href="#4-amazon-s3-simple-storage-service">4. <strong>Amazon S3 (Simple Storage Service)</strong></a></h2>
<h3 id="41-introduction-à-s3"><a class="header" href="#41-introduction-à-s3">4.1 <strong>Introduction à S3</strong></a></h3>
<h4 id="quest-ce-que-s3-"><a class="header" href="#quest-ce-que-s3-">Qu'est-ce que S3 ?</a></h4>
<p>Amazon S3 (Simple Storage Service) est un service de stockage d’objets qui permet aux utilisateurs de stocker et de récupérer n’importe quel volume de données, à tout moment et depuis n’importe où. S3 est conçu pour offrir une durabilité, une disponibilité et une sécurité élevées pour les données critiques.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html">Qu'est-ce qu'Amazon S3 ?</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/Welcome.html"><em>fr</em></a>]</li>
</ul>
<h4 id="principales-fonctionnalités-et-cas-dutilisation-1"><a class="header" href="#principales-fonctionnalités-et-cas-dutilisation-1">Principales fonctionnalités et cas d’utilisation</a></h4>
<p>Les principales fonctionnalités d'Amazon S3 incluent :</p>
<ul>
<li><strong>Stockage sécurisé</strong> : avec des options de chiffrement et des contrôles d'accès granulaire.</li>
<li><strong>Durabilité et disponibilité</strong> : S3 garantit une durabilité de 99,999999999% (11 9s) des données.</li>
<li><strong>Évolutivité et gestion simplifiée</strong> : peut stocker une quantité illimitée de données.</li>
</ul>
<p><strong>Cas d’utilisation</strong> :</p>
<ul>
<li>Sauvegarde et archivage de données.</li>
<li>Stockage d’images, vidéos et autres fichiers pour les applications web.</li>
<li>Analyse big data et stockage pour l’IA et le machine learning.</li>
</ul>
<h4 id="image-suggestion-6"><a class="header" href="#image-suggestion-6">Image Suggestion:</a></h4>
<ul>
<li><strong>Image 1</strong>: Schéma montrant un bucket S3 avec plusieurs objets (fichiers), illustrant les fonctionnalités de base de S3 (stockage sécurisé, haute disponibilité).</li>
</ul>
<p><img src="aws/sections/../images/04_AWS_S3/s3_bucket.png" alt="S3 Bucket overview" /></p>
<blockquote>
<p>Le diagramme montre comment déplacer des données vers Amazon S3, gérer les données stockées dans Amazon S3 et analyser les données avec d'autres services. Trois sections s'affichent de gauche à droite.
La première section présente une illustration d'une base de données, d'un serveur et d'un document. La première section est intitulée « Déplacer des données ». La première section indique : « Déplacez vos données vers Amazon S3, où qu'elles se trouvent - dans le nuage, dans les applications ou sur site ». Des icônes à proximité indiquent différents types de données : « données analytiques », “fichiers journaux”, “données d'application”, “vidéos et images” et “sauvegarde et archivage”.
La deuxième section est illustrée par un seau vide. La deuxième section est intitulée « Amazon S3 ». La deuxième section dit : « Stockage d'objets conçu pour stocker et récupérer n'importe quelle quantité de données à partir de n'importe quel endroit ».
La deuxième section contient plus de texte sous le titre « Stocker des données ». Le texte dit : « Créer un seau, spécifier la région, les contrôles d'accès et les options de gestion. Télécharger n'importe quelle quantité de données ». Une illustration à proximité montre un seau contenant un carré, un cercle et un triangle.
La deuxième section comporte également des icônes qui montrent les fonctionnalités d'Amazon S3. Ces fonctionnalités sont les suivantes : « Contrôlez l'accès aux données », « Optimisez les coûts grâce aux classes de stockage », « Répliquez les données dans n'importe quelle région », « Accédez à vos données depuis vos locaux ou un VPC », « Protégez et sécurisez vos données » et « Bénéficiez d'une visibilité sur votre stockage ».
La troisième section est intitulée « Analyser les données ». La troisième section dit : « Utilisez AWS et des services tiers pour analyser vos données et en tirer des enseignements. » Les icônes à proximité indiquent des méthodes d'analyse des données : « intelligence artificielle (IA) », “analyse avancée” et “apprentissage machine (ML)”.</p>
</blockquote>
<p>Voici un script d'exemple qui :</p>
<ol>
<li>Crée un Bucket S3 pour une application de stockage de photos</li>
<li>Télécharge des images dans le bucket pour en montrer le fonctionnement</li>
<li>Mets en place une politique de propriétaire pour attribuer le Bucket à un unique rôle (ou utilisateur)</li>
</ol>
<pre><code class="language-bash"># Définissez le nom du bucket et la région
BUCKET_NAME="app-stockage-photos"
REGION="eu-west-3"  # Changez cette valeur selon la région souhaitée
IMAGES=("image1.png" "image2.png" "image3.png")  # Liste des images à télécharger
#USER_ARN="arn:aws:iam::123456789012:user/specific-user"  # Remplacez par l'ARN de l'utilisateur autorisé
ROLE_ARN="arn:aws:iam::354918371346:role/Jenkins-EC2-Role"

# 1. Créer le bucket S3
aws s3api create-bucket --bucket $BUCKET_NAME --region $REGION --create-bucket-configuration LocationConstraint=$REGION
echo "Bucket $BUCKET_NAME créé dans la région $REGION."

# 2. Téléchargez les images dans le bucket
for IMAGE in "${IMAGES[@]}"; do
    aws s3 cp $IMAGE s3://$BUCKET_NAME/
    echo "$IMAGE téléchargée dans le bucket $BUCKET_NAME."
done

# 3. Configurer la politique de contrôle d’accès du bucket
cat &gt; bucket-policy.json &lt;&lt;EOL
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "AWS": "$ROLE_ARN"
            },
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::$BUCKET_NAME/*"
        }
    ]
}
EOL

aws s3api put-bucket-policy --bucket $BUCKET_NAME --policy file://bucket-policy.json
echo "Politique de contrôle d’accès configurée pour limiter l'accès au bucket $BUCKET_NAME à l'utilisateur spécifié."

# Nettoyage (optionnel) : Supprimez le fichier temporaire de politique
rm bucket-policy.json
</code></pre>
<hr />
<h3 id="42-prise-en-main-de-s3"><a class="header" href="#42-prise-en-main-de-s3">4.2 <strong>Prise en main de S3</strong></a></h3>
<h4 id="création-dun-bucket-s3"><a class="header" href="#création-dun-bucket-s3">Création d’un bucket S3</a></h4>
<p>Un <strong>bucket</strong> est un conteneur dans lequel les fichiers (objets) sont stockés. La création d’un bucket est la première étape pour utiliser Amazon S3.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/CreatingBucket.html">Guide de création d’un bucket S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/CreatingBucket.html"><em>fr</em></a>]</li>
</ul>
<h4 id="gestion-des-fichiers-objets-dans-s3"><a class="header" href="#gestion-des-fichiers-objets-dans-s3">Gestion des fichiers (objets) dans S3</a></h4>
<p>Les fichiers stockés dans S3 sont appelés <strong>objets</strong>. Chaque objet est identifié de manière unique dans un bucket par une clé (nom d'objet) et peut contenir des métadonnées.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/upload-objects.html">Gestion des objets dans Amazon S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/upload-objects.html"><em>fr</em></a>]</li>
</ul>
<h4 id="régions-et-réplication-s3"><a class="header" href="#régions-et-réplication-s3">Régions et réplication S3</a></h4>
<p>Les buckets S3 sont créés dans des régions spécifiques. AWS propose la <strong>réplication inter-région</strong> pour copier automatiquement les objets d’un bucket dans une autre région, garantissant ainsi la redondance et la conformité.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingBucket.html">Régions et réplication dans Amazon S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/UsingBucket.html"><em>fr</em></a>]</li>
</ul>
<p><img src="aws/sections/../images/04_AWS_S3/s3_console.png" alt="AWS S3 Console" /></p>
<hr />
<h3 id="43-gestion-des-données-et-sécurité"><a class="header" href="#43-gestion-des-données-et-sécurité">4.3 <strong>Gestion des données et sécurité</strong></a></h3>
<h4 id="politiques-de-bucket-et-permissions"><a class="header" href="#politiques-de-bucket-et-permissions">Politiques de bucket et permissions</a></h4>
<p>Les <strong>politiques de bucket</strong> permettent de définir des permissions pour contrôler l'accès aux buckets et aux objets qu'ils contiennent. Elles sont utilisées pour gérer les accès publics et privés.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-policies.html">Documentation sur les politiques de bucket dans S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/bucket-policies.html"><em>fr</em></a>]</li>
</ul>
<h4 id="contrôles-daccès-acl"><a class="header" href="#contrôles-daccès-acl">Contrôles d'accès (ACL)</a></h4>
<p>Les <strong>listes de contrôle d’accès (ACL)</strong> permettent de gérer les autorisations au niveau des objets. Cela inclut la possibilité de donner des accès en lecture ou en écriture à des utilisateurs spécifiques.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/acl-overview.html">Contrôles d'accès ACL dans Amazon S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/acl-overview.html"><em>fr</em></a>]</li>
</ul>
<h4 id="options-de-chiffrement"><a class="header" href="#options-de-chiffrement">Options de chiffrement</a></h4>
<p>Amazon S3 prend en charge le <strong>chiffrement côté serveur</strong> (SSE) et le <strong>chiffrement côté client</strong> pour protéger les données. Les clés de chiffrement peuvent être gérées par AWS ou par l’utilisateur.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingEncryption.html">Guide des options de chiffrement S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/UsingEncryption.html"><em>fr</em></a>]</li>
</ul>
<hr />
<h3 id="44-classes-de-stockage-et-gestion-du-cycle-de-vie"><a class="header" href="#44-classes-de-stockage-et-gestion-du-cycle-de-vie">4.4 <strong>Classes de stockage et gestion du cycle de vie</strong></a></h3>
<h4 id="classes-de-stockage-s3"><a class="header" href="#classes-de-stockage-s3">Classes de stockage S3</a></h4>
<p>Amazon S3 propose plusieurs <strong>classes de stockage</strong> adaptées aux différents cas d'utilisation, notamment :</p>
<ul>
<li>
<p><strong>Standard</strong> : pour des accès fréquents avec une haute disponibilité.</p>
</li>
<li>
<p><strong>Intelligent-Tiering</strong> : ajuste automatiquement les coûts de stockage en fonction des accès.</p>
</li>
<li>
<p><strong>Glacier</strong> et <strong>Glacier Deep Archive</strong> : pour l'archivage des données à long terme, avec des coûts de stockage très bas.</p>
</li>
<li>
<p><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-class-intro.html">Documentation sur les classes de stockage S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/storage-class-intro.html"><em>fr</em></a>]</p>
</li>
</ul>
<h4 id="politiques-de-cycle-de-vie-pour-loptimisation-des-coûts"><a class="header" href="#politiques-de-cycle-de-vie-pour-loptimisation-des-coûts">Politiques de cycle de vie pour l'optimisation des coûts</a></h4>
<p>Les <strong>politiques de cycle de vie</strong> permettent de définir des règles pour transférer automatiquement les objets entre différentes classes de stockage en fonction de leur âge ou de leur fréquence d'accès. Cela optimise les coûts en déplaçant automatiquement les objets rarement utilisés vers des classes de stockage moins chères.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/lifecycle-configuration-examples.html">Guide sur les politiques de cycle de vie S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/lifecycle-configuration-examples.html"><em>fr</em></a>]</li>
</ul>
<p><img src="aws/sections/../images/04_AWS_S3/s3_classes.jpg" alt="S3 Storage Classes" /></p>
<hr />
<h3 id="45-fonctions-avancées-de-s3"><a class="header" href="#45-fonctions-avancées-de-s3">4.5 <strong>Fonctions avancées de S3</strong></a></h3>
<h4 id="versioning-et-verrouillage-dobjets"><a class="header" href="#versioning-et-verrouillage-dobjets">Versioning et verrouillage d'objets</a></h4>
<p>La <strong>gestion des versions</strong> permet de conserver plusieurs versions d'un objet dans un bucket, tandis que le <strong>verrouillage d'objets</strong> empêche toute suppression accidentelle. Cela offre une protection contre les pertes de données.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html">Documentation sur le versioning dans S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/Versioning.html"><em>fr</em></a>]</li>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock-overview.html">Documentation sur le verrouillage d'objets S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/object-lock-overview.html"><em>fr</em></a>]</li>
</ul>
<h4 id="réplication-inter-région"><a class="header" href="#réplication-inter-région">Réplication inter-région</a></h4>
<p>La <strong>réplication inter-région</strong> permet de copier les objets d'un bucket source vers un bucket de destination dans une autre région AWS. C'est utile pour la conformité aux régulations de stockage</p>
<p>, la récupération après sinistre et l'accessibilité mondiale des données.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html">Guide de la réplication inter-région S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/replication.html"><em>fr</em></a>]</li>
</ul>
<h4 id="accélération-de-transfert-s3"><a class="header" href="#accélération-de-transfert-s3">Accélération de transfert S3</a></h4>
<p>L'<strong>accélération de transfert S3</strong> utilise le réseau AWS CloudFront pour transférer des données vers et depuis S3 plus rapidement, surtout pour les utilisateurs éloignés géographiquement du bucket S3.</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/transfer-acceleration.html">Documentation sur l'accélération de transfert S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/transfer-acceleration.html"><em>fr</em></a>]</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><p><strong>Présentation Générale de Jenkins</strong></p>
<hr />
<h3 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h3>
<p><strong>Jenkins</strong> est un outil open-source d'intégration et de livraison continues (CI/CD), principalement utilisé pour automatiser les processus de développement, de test et de déploiement des applications. Créé en 2011 comme une évolution de Hudson, Jenkins est devenu une référence dans le domaine DevOps et CI/CD grâce à sa flexibilité, son large écosystème de plugins, et sa grande communauté de contributeurs.</p>
<hr />
<h3 id="principales-fonctionnalités-de-jenkins"><a class="header" href="#principales-fonctionnalités-de-jenkins">Principales Fonctionnalités de Jenkins</a></h3>
<ol>
<li>
<p><strong>Intégration Continue (CI)</strong> : Jenkins permet aux équipes de développement de construire, tester et intégrer du code fréquemment et automatiquement, garantissant que les nouvelles modifications n’introduisent pas de régressions.</p>
</li>
<li>
<p><strong>Livraison Continue (CD)</strong> : En plus de l’intégration continue, Jenkins automatise les étapes de déploiement vers les environnements de test, de préproduction, et de production, réduisant le délai de mise en production.</p>
</li>
<li>
<p><strong>Pipeline as Code</strong> : Avec <strong>Jenkinsfile</strong>, Jenkins permet de définir les pipelines CI/CD sous forme de code, facilitant la gestion, le versioning, et la standardisation des pipelines.</p>
</li>
<li>
<p><strong>Écosystème de Plugins</strong> : Jenkins propose plus de 1 500 plugins pour étendre ses fonctionnalités. Ces plugins permettent d’intégrer Jenkins avec des outils de contrôle de version (Git, SVN), de gestion des conteneurs (Docker), de cloud (AWS, Azure, GCP), de tests, de surveillance, et bien d’autres.</p>
</li>
<li>
<p><strong>Gestion des Notifications et Reporting</strong> : Jenkins envoie des notifications (par e-mail, Slack, etc.) sur les résultats des builds et les étapes de pipeline, permettant aux équipes de suivre et d’agir en temps réel. Il génère également des rapports pour aider à analyser les performances et les résultats des tests.</p>
</li>
<li>
<p><strong>Extensibilité et Scalabilité</strong> : Jenkins peut être configuré pour distribuer des tâches sur plusieurs machines grâce à une architecture <strong>maître-agent</strong>, permettant d’exécuter des builds en parallèle et de répondre aux besoins croissants des équipes.</p>
</li>
</ol>
<hr />
<h3 id="architecture-de-jenkins"><a class="header" href="#architecture-de-jenkins">Architecture de Jenkins</a></h3>
<ol>
<li>
<p><strong>Jenkins Master</strong> : Le serveur principal gère l’interface utilisateur, les configurations de jobs, la planification des builds, et le déclenchement des tâches. Il coordonne aussi les agents et collecte les résultats des exécutions.</p>
</li>
<li>
<p><strong>Jenkins Agent</strong> : Les agents (ou "nœuds") sont des machines qui exécutent les tâches de build et de test. Cela permet de décharger le serveur principal et de répartir les tâches, ce qui est essentiel pour les grandes équipes ou les projets nécessitant des ressources importantes.</p>
</li>
<li>
<p><strong>Pipeline Jenkins</strong> : Le pipeline est un ensemble d’étapes qui représentent le workflow de CI/CD. Avec <strong>Declarative Pipeline</strong> (plus simple et structuré) ou <strong>Scripted Pipeline</strong> (plus flexible), Jenkins offre la possibilité de définir des pipelines complexes, incluant des étapes de build, de test, de déploiement, et de reporting.</p>
</li>
</ol>
<p><img src="jenkins/../jenkins/images/jenkins_architecture.png" alt="Architecture Jenkins" /></p>
<hr />
<h3 id="les-pipelines-jenkins"><a class="header" href="#les-pipelines-jenkins">Les Pipelines Jenkins</a></h3>
<p>Les pipelines permettent d’automatiser et d’orchestrer les étapes CI/CD sous forme de code.</p>
<ul>
<li><strong>Jenkinsfile</strong> : Un fichier qui décrit le pipeline en utilisant soit une syntaxe déclarative, soit une syntaxe scriptée. Le Jenkinsfile permet d’intégrer le pipeline dans le contrôle de version.</li>
<li><strong>Stages et Steps</strong> : Un pipeline est structuré en <strong>stages</strong> (phases du workflow) et <strong>steps</strong> (actions spécifiques). Par exemple, un pipeline typique inclura des étapes de build, de tests, et de déploiement.</li>
<li><strong>Multibranch Pipeline</strong> : Jenkins peut automatiquement détecter et exécuter des pipelines pour chaque branche d’un dépôt Git, permettant ainsi de tester et déployer le code de manière indépendante par branche.</li>
</ul>
<p><strong>Exemple de Jenkinsfile (Déclaratif)</strong> :</p>
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                echo 'Building...'
                sh 'make build'
            }
        }
        stage('Test') {
            steps {
                echo 'Testing...'
                sh 'make test'
            }
        }
        stage('Deploy') {
            steps {
                echo 'Deploying...'
                sh 'make deploy'
            }
        }
    }
}
</code></pre>
<hr />
<h3 id="avantages-de-jenkins"><a class="header" href="#avantages-de-jenkins">Avantages de Jenkins</a></h3>
<ol>
<li><strong>Automatisation et Productivité</strong> : En automatisant les builds et les tests, Jenkins réduit le besoin d’interventions manuelles, permettant aux équipes de se concentrer sur le développement.</li>
<li><strong>Flexibilité et Extensibilité</strong> : Grâce à son écosystème de plugins, Jenkins peut être intégré avec presque tous les outils DevOps.</li>
<li><strong>Scalabilité</strong> : L’architecture maître-agent permet d’exécuter des centaines de builds en parallèle, ce qui est essentiel pour les projets complexes.</li>
<li><strong>Transparence et Collaboration</strong> : Jenkins génère des rapports et notifications, offrant une visibilité complète sur l’état du code et facilitant la collaboration entre les équipes.</li>
</ol>
<hr />
<h3 id="cas-dusage-courants-1"><a class="header" href="#cas-dusage-courants-1">Cas d'Usage Courants</a></h3>
<ol>
<li>
<p><strong>Développement et Build Automatisé</strong> : Jenkins automatise la compilation, les tests unitaires et la vérification de qualité du code à chaque commit.</p>
</li>
<li>
<p><strong>Déploiement Automatisé et Livraison Continue</strong> : Les équipes DevOps peuvent configurer Jenkins pour déployer des applications dans divers environnements (test, préproduction, production) de manière automatique.</p>
</li>
<li>
<p><strong>Orchestration Multibranche</strong> : Avec le Multibranch Pipeline, Jenkins détecte automatiquement les branches d’un dépôt et y associe des pipelines dédiés, permettant un contrôle indépendant pour chaque branche.</p>
</li>
<li>
<p><strong>Intégration avec les Conteneurs et le Cloud</strong> : Jenkins s'intègre facilement avec Docker, Kubernetes, et des services cloud comme AWS, Azure, et Google Cloud, facilitant le déploiement d’applications conteneurisées.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="partie-1--introduction-à-jenkins-et-à-lautomatisation-cicd"><a class="header" href="#partie-1--introduction-à-jenkins-et-à-lautomatisation-cicd">Partie 1 : Introduction à Jenkins et à l’Automatisation CI/CD</a></h2>
<h3 id="objectifs"><a class="header" href="#objectifs">Objectifs</a></h3>
<p>Dans cette première partie, vous allez :</p>
<ul>
<li><strong>Comprendre</strong> ce que sont l’intégration continue (CI) et le déploiement continu (CD).</li>
<li><strong>Découvrir</strong> pourquoi et comment Jenkins joue un rôle essentiel dans la mise en place de pipelines CI/CD automatisés.</li>
</ul>
<hr />
<h3 id="11-présentation-de-lautomatisation-cicd"><a class="header" href="#11-présentation-de-lautomatisation-cicd">1.1 Présentation de l’automatisation CI/CD</a></h3>
<h4 id="quest-ce-que-lintégration-continue-ci-"><a class="header" href="#quest-ce-que-lintégration-continue-ci-">Qu'est-ce que l’intégration continue (CI) ?</a></h4>
<p>L’intégration continue (Continuous Integration ou CI) est une pratique de développement qui encourage l'intégration fréquente des modifications de code dans une branche principale. Grâce à CI, chaque modification apportée au code est automatiquement testée. Cela permet de détecter rapidement les erreurs et d'assurer la cohérence du code au fur et à mesure du développement.</p>
<h4 id="quest-ce-que-le-déploiement-continu-cd-"><a class="header" href="#quest-ce-que-le-déploiement-continu-cd-">Qu'est-ce que le déploiement continu (CD) ?</a></h4>
<p>Le déploiement continu (Continuous Deployment ou CD) est une extension de l'intégration continue. Il vise à automatiser la mise en production des modifications de code, de manière à pouvoir les livrer aux utilisateurs rapidement et en toute sécurité. En résumé, le CD est l'étape suivante qui, après l’intégration réussie des modifications de code, les déploie automatiquement dans des environnements de production.</p>
<h4 id="pourquoi-automatiser-les-pipelines-de-développement-"><a class="header" href="#pourquoi-automatiser-les-pipelines-de-développement-">Pourquoi automatiser les pipelines de développement ?</a></h4>
<p>L’automatisation des pipelines CI/CD présente de nombreux avantages :</p>
<ul>
<li><strong>Gain de temps</strong> : Les tâches répétitives comme les tests et les déploiements sont automatisées, ce qui réduit les délais de livraison.</li>
<li><strong>Réduction des erreurs humaines</strong> : En automatisant, on diminue le risque d’erreurs humaines, notamment lors de la phase de déploiement.</li>
<li><strong>Amélioration de la qualité du code</strong> : Grâce aux tests automatiques et aux validations de code, les erreurs sont détectées en amont.</li>
<li><strong>Collaboration renforcée</strong> : Les équipes peuvent travailler de manière plus agile, en intégrant leurs modifications régulièrement sans crainte de conflits de code.</li>
</ul>
<p>![Illustration des processus CI/CD](Image montrant le cycle d'intégration et de déploiement continu avec Jenkins comme outil central, et des flèches indiquant les étapes d'automatisation, des tests aux déploiements.)</p>
<hr />
<h3 id="12-introduction-à-jenkins"><a class="header" href="#12-introduction-à-jenkins">1.2 Introduction à Jenkins</a></h3>
<h4 id="quest-ce-que-jenkins-"><a class="header" href="#quest-ce-que-jenkins-">Qu’est-ce que Jenkins ?</a></h4>
<p>Jenkins est un outil open-source d’automatisation, principalement utilisé pour la mise en place de pipelines CI/CD. Il aide les équipes de développement à intégrer et à déployer régulièrement leur code, en simplifiant et en automatisant les processus de test et de déploiement.</p>
<h4 id="histoire-et-communauté-open-source"><a class="header" href="#histoire-et-communauté-open-source">Histoire et communauté open-source</a></h4>
<p>Jenkins a commencé sous le nom de Hudson en 2004 avant de devenir un projet open-source indépendant sous le nom de Jenkins en 2011. Depuis, il bénéficie du soutien d'une vaste communauté de développeurs, et des centaines de plugins ont été créés pour étendre ses fonctionnalités.</p>
<h4 id="avantages-et-fonctionnalités-de-jenkins"><a class="header" href="#avantages-et-fonctionnalités-de-jenkins">Avantages et fonctionnalités de Jenkins</a></h4>
<ul>
<li><strong>Open-source et extensible</strong> : Jenkins est gratuit et peut être personnalisé via de nombreux plugins pour répondre aux besoins spécifiques de chaque projet.</li>
<li><strong>Automatisation des tâches répétitives</strong> : Jenkins permet d’automatiser les tests, les compilations, et les déploiements, ce qui est crucial pour les équipes CI/CD.</li>
<li><strong>Flexibilité</strong> : Jenkins peut s’intégrer avec presque tous les systèmes de versionnage et outils de test.</li>
</ul>
<h4 id="présentation-de-linterface-utilisateur-de-jenkins"><a class="header" href="#présentation-de-linterface-utilisateur-de-jenkins">Présentation de l'interface utilisateur de Jenkins</a></h4>
<p>L'interface utilisateur de Jenkins est composée de plusieurs sections clés :</p>
<ul>
<li><strong>Tableau de bord</strong> : Accueil principal avec les projets et pipelines actifs.</li>
<li><strong>Jobs et builds</strong> : Sections où l’on configure les tâches et les étapes d’automatisation.</li>
<li><strong>Gestion des plugins</strong> : Permet l’ajout de fonctionnalités supplémentaires.</li>
<li><strong>Historique des builds</strong> : Suivi des builds passés et des logs associés.</li>
</ul>
<p>![Interface utilisateur de Jenkins](Image montrant l'interface utilisateur de Jenkins, avec les sections principales comme le tableau de bord, l'historique des builds, et la gestion des plugins.)</p>
<hr />
<h3 id="13-installation-de-jenkins"><a class="header" href="#13-installation-de-jenkins">1.3 Installation de Jenkins</a></h3>
<h4 id="installation-de-jenkins-sur-différentes-plateformes"><a class="header" href="#installation-de-jenkins-sur-différentes-plateformes">Installation de Jenkins sur différentes plateformes</a></h4>
<p>Pour commencer à utiliser Jenkins, il faut l’installer sur votre machine ou sur un serveur. Jenkins est compatible avec plusieurs plateformes.</p>
<ol>
<li>
<p><strong>Installation sur Windows</strong> :</p>
<ul>
<li>Téléchargez Jenkins depuis le <a href="https://www.jenkins.io/download/">site officiel</a>.</li>
<li>Suivez les étapes d’installation, qui incluent la configuration d’un chemin pour Java.</li>
<li>Une fois installé, démarrez Jenkins et accédez à l’interface via <code>http://localhost:8080</code>.</li>
</ul>
</li>
<li>
<p><strong>Installation sur Linux</strong> :</p>
<ul>
<li>Sur une distribution comme Ubuntu, vous pouvez installer Jenkins en ajoutant son dépôt :
<pre><code class="language-bash">sudo apt update
sudo apt install jenkins
</code></pre>
</li>
<li>Lancez Jenkins avec la commande <code>sudo systemctl start jenkins</code> et accédez à l’interface via <code>http://localhost:8080</code>.</li>
</ul>
</li>
<li>
<p><strong>Installation avec Docker</strong> :</p>
<ul>
<li>Si vous préférez utiliser Docker, exécutez la commande suivante pour démarrer Jenkins dans un conteneur :
<pre><code class="language-bash">docker run -p 8080:8080 -p 50000:50000 jenkins/jenkins:lts
</code></pre>
</li>
<li>Accédez ensuite à Jenkins via <code>http://localhost:8080</code>.</li>
</ul>
</li>
</ol>
<h4 id="configuration-initiale-de-jenkins"><a class="header" href="#configuration-initiale-de-jenkins">Configuration initiale de Jenkins</a></h4>
<p>Après l’installation, suivez les étapes de configuration initiale :</p>
<ul>
<li><strong>Installation des plugins recommandés</strong> : Jenkins propose une liste de plugins essentiels, qui permettent de configurer des fonctionnalités de base (intégration Git, pipelines, etc.).</li>
<li><strong>Création d’un compte administrateur</strong> : Sécurisez votre Jenkins en créant un compte administrateur.</li>
<li><strong>Paramètres de base</strong> : Explorez les paramètres, notamment ceux pour l'ajout de serveurs de build et la gestion des notifications.</li>
</ul>
<p>![Installation de Jenkins](Image montrant les étapes de l’installation de Jenkins sur Docker, avec une console affichant la commande de lancement et une vue du tableau de bord Jenkins une fois installé.)</p>
<hr />
<h3 id="exercice--installer-jenkins-sur-sa-machine-locale-ou-via-docker"><a class="header" href="#exercice--installer-jenkins-sur-sa-machine-locale-ou-via-docker">Exercice : Installer Jenkins sur sa machine locale ou via Docker</a></h3>
<p><strong>Objectif de l'exercice</strong> : Installer Jenkins pour pouvoir l’utiliser dans les prochaines sections.</p>
<p><strong>Étapes de l’exercice</strong> :</p>
<ol>
<li><strong>Choisissez la méthode d’installation</strong> : Windows, Linux ou Docker, selon votre système.</li>
<li><strong>Téléchargez et installez Jenkins</strong> : Suivez les étapes spécifiques pour votre plateforme.</li>
<li><strong>Accédez à Jenkins via le navigateur</strong> : Ouvrez <code>http://localhost:8080</code> pour accéder à l’interface.</li>
<li><strong>Configuration initiale</strong> : Installez les plugins recommandés et créez un compte administrateur.</li>
</ol>
<blockquote>
<p><strong>Astuce</strong> : Si vous n’avez pas installé Docker, cette installation peut être une bonne opportunité d’apprendre à l’utiliser, car cela simplifie la gestion de Jenkins.</p>
</blockquote>
<hr />
<h4 id="ressources-supplémentaires"><a class="header" href="#ressources-supplémentaires">Ressources supplémentaires</a></h4>
<ul>
<li><a href="https://www.jenkins.io/doc/book/installing/">Documentation officielle de Jenkins - Installation</a></li>
<li><a href="https://hub.docker.com/r/jenkins/jenkins/">Documentation Docker pour Jenkins</a></li>
</ul>
<hr />
<h4 id="questions-de-révision"><a class="header" href="#questions-de-révision">Questions de Révision</a></h4>
<details>
<summary><h3 style="display:inline-block">Questions de Révision</h3></summary>
<details>
<summary>Qu'est-ce que l'intégration continue (CI) ?</summary>
CI est une pratique de développement consistant à intégrer fréquemment des modifications de code, qui sont ensuite testées automatiquement pour détecter rapidement les erreurs.
</details>
<details>
<summary>Quels sont les principaux avantages de Jenkins ?</summary>
Jenkins est open-source, extensible, et permet d'automatiser les tâches CI/CD, ce qui aide les équipes à livrer des modifications plus rapidement et de manière fiable.
</details>
<details>
<summary>Comment peut-on installer Jenkins via Docker ?</summary>
En exécutant la commande `docker run -p 8080:8080 -p 50000:50000 jenkins/jenkins:lts`, ce qui démarre Jenkins dans un conteneur accessible sur `http://localhost:8080`.
</details>
</details>
<div style="break-before: page; page-break-before: always;"></div><h2 id="partie-2--premiers-pas-avec-jenkins"><a class="header" href="#partie-2--premiers-pas-avec-jenkins">Partie 2 : Premiers Pas avec Jenkins</a></h2>
<h3 id="objectifs-1"><a class="header" href="#objectifs-1">Objectifs</a></h3>
<p>Dans cette deuxième partie, vous allez apprendre à :</p>
<ul>
<li><strong>Créer et exécuter des jobs simples et paramétrés</strong> dans Jenkins.</li>
<li><strong>Comprendre la structure d’un job</strong> et ses étapes.</li>
<li><strong>Planifier et déclencher des builds automatiquement</strong> avec différentes méthodes, y compris les webhooks.</li>
</ul>
<hr />
<h3 id="21-création-dun-job-jenkins-basique"><a class="header" href="#21-création-dun-job-jenkins-basique">2.1 Création d’un job Jenkins basique</a></h3>
<h4 id="présentation-des-types-de-jobs-dans-jenkins"><a class="header" href="#présentation-des-types-de-jobs-dans-jenkins">Présentation des types de jobs dans Jenkins</a></h4>
<p>Jenkins propose plusieurs types de jobs, chacun adapté à des besoins variés :</p>
<ul>
<li><strong>Freestyle</strong> : Un job flexible pour des tâches simples comme exécuter des scripts ou déployer des fichiers. Idéal pour commencer et tester des configurations de base.</li>
<li><strong>Pipeline</strong> : Un job basé sur un script Jenkinsfile, permettant de créer des workflows complexes en tant que code.</li>
<li><strong>Multibranch Pipeline</strong> : Spécialement conçu pour les projets gérant plusieurs branches, chaque branche déclenche automatiquement un pipeline dédié.</li>
<li><strong>Folder</strong> : Permet de regrouper plusieurs jobs dans un dossier, utile pour organiser des projets de grande envergure.</li>
</ul>
<p>Dans cette partie, nous allons commencer avec un <strong>job Freestyle</strong>, qui convient bien aux démonstrations et aux configurations de base.</p>
<h4 id="création-dun-job-freestyle"><a class="header" href="#création-dun-job-freestyle">Création d’un job Freestyle</a></h4>
<ol>
<li><strong>Accédez au tableau de bord Jenkins</strong> et cliquez sur <strong>New Item</strong> (Nouvel élément).</li>
<li><strong>Nommez votre job</strong> (par exemple, “Job de test”) et sélectionnez <strong>Freestyle project</strong> (Projet Freestyle).</li>
<li>Cliquez sur <strong>OK</strong> pour créer le job.</li>
</ol>
<h4 id="exécution-dun-script-shell-ou-de-commande-windows-simple"><a class="header" href="#exécution-dun-script-shell-ou-de-commande-windows-simple">Exécution d'un script Shell ou de commande Windows simple</a></h4>
<p>Pour ce premier job, nous allons configurer un script simple qui affiche "Hello, World!" :</p>
<ol>
<li>Dans les paramètres du job, allez à la section <strong>Build</strong> (Construire) et choisissez <strong>Execute shell</strong> (ou <strong>Exécuter une commande sous Windows</strong> sur un système Windows).</li>
<li>Dans la zone de texte, entrez la commande suivante :
<pre><code class="language-bash">echo "Hello, World!"
</code></pre>
</li>
<li>Cliquez sur <strong>Save</strong> (Sauvegarder) pour enregistrer le job.</li>
</ol>
<p><img src="jenkins/sections/../images/02_Basics/freestyle.jpg" alt="Configuration d&#39;un job freestyle Jenkins" /></p>
<blockquote>
<p>Source: https://www.geeksforgeeks.org/creating-and-configuring-freestyle-projects-in-jenkins/</p>
</blockquote>
<hr />
<h3 id="création-de-jobs-paramétrés"><a class="header" href="#création-de-jobs-paramétrés">Création de jobs paramétrés</a></h3>
<p>Les <strong>jobs paramétrés</strong> permettent de personnaliser l’exécution d’un job avec des valeurs dynamiques, comme le choix d’une branche spécifique ou l’ajout d’un nom de version.</p>
<p>Pour configurer un job paramétré :</p>
<ol>
<li>Ouvrez un job existant ou créez-en un nouveau.</li>
<li>Cochez l'option <strong>This project is parameterized</strong> (Ce projet est paramétré) dans les paramètres du job.</li>
<li>Cliquez sur <strong>Add Parameter</strong> (Ajouter un paramètre) pour choisir le type de paramètre :
<ul>
<li><strong>String Parameter</strong> : Pour entrer du texte (ex. : nom de branche).</li>
<li><strong>Boolean Parameter</strong> : Pour activer ou désactiver certaines étapes.</li>
<li><strong>Choice Parameter</strong> : Sélectionner parmi plusieurs options prédéfinies.</li>
<li><strong>File Parameter</strong> : Téléverser un fichier à utiliser dans le job.</li>
</ul>
</li>
</ol>
<p><strong>Exemple : Créer un job avec un paramètre de branche</strong></p>
<ol>
<li>Ajoutez un <strong>String Parameter</strong> nommé <code>BRANCH_NAME</code>.</li>
<li>Dans la section <strong>Build</strong>, configurez une commande Shell pour utiliser le paramètre :
<pre><code class="language-bash">echo "Building branch: $BRANCH_NAME"
</code></pre>
</li>
<li>Lors de l’exécution du job, Jenkins vous demandera la valeur de <code>BRANCH_NAME</code>, qui sera utilisée dans le script.</li>
</ol>
<p><img src="jenkins/sections/../images/02_Basics/parametrized.jpg" alt="Configuration d&#39;un job paramétré dans Jenkins" /></p>
<blockquote>
<p>Source: https://www.baeldung.com/ops/jenkins-parameterized-builds</p>
</blockquote>
<hr />
<h3 id="22-gestion-des-builds"><a class="header" href="#22-gestion-des-builds">2.2 Gestion des Builds</a></h3>
<h4 id="déclencher-un-build-manuellement"><a class="header" href="#déclencher-un-build-manuellement">Déclencher un build manuellement</a></h4>
<p>Pour lancer un job manuellement :</p>
<ol>
<li>Accédez à la page du job et cliquez sur <strong>Build Now</strong> (Construire maintenant).</li>
<li>Jenkins exécute la commande définie, et un numéro de build apparaît dans l’historique des builds.</li>
</ol>
<h4 id="visualisation-des-logs-et-des-résultats-du-build"><a class="header" href="#visualisation-des-logs-et-des-résultats-du-build">Visualisation des logs et des résultats du build</a></h4>
<p>Pour examiner le résultat :</p>
<ol>
<li>Cliquez sur le numéro du build (par exemple, <strong>#1</strong>) dans la section <strong>Build History</strong>.</li>
<li>Accédez aux <strong>Console Output</strong> (Sortie de console) pour voir les détails de l’exécution du job. Vous devriez y voir la sortie de votre script, par exemple, "Hello, World!".</li>
</ol>
<h4 id="rebuild-copie-et-suppression-des-builds"><a class="header" href="#rebuild-copie-et-suppression-des-builds">Rebuild, copie et suppression des builds</a></h4>
<ul>
<li><strong>Rebuild</strong> : Cliquez sur <strong>Rebuild</strong> dans la page de détails pour relancer le job avec les mêmes paramètres.</li>
<li><strong>Copie</strong> : Pour cloner un job, choisissez <strong>Copy</strong> dans les paramètres et donnez un nouveau nom.</li>
<li><strong>Suppression</strong> : Dans les paramètres du job, choisissez <strong>Delete</strong> pour supprimer un job dont vous n’avez plus besoin.</li>
</ul>
<p><img src="jenkins/sections/../images/02_Basics/logs.png" alt="Visualisation des logs Jenkins" /></p>
<hr />
<h3 id="23-planification-des-builds"><a class="header" href="#23-planification-des-builds">2.3 Planification des Builds</a></h3>
<h4 id="exécutions-périodiques--cron-et-triggers"><a class="header" href="#exécutions-périodiques--cron-et-triggers">Exécutions périodiques : cron et triggers</a></h4>
<p>Jenkins permet d’automatiser les builds à des intervalles réguliers grâce à des expressions cron :</p>
<ol>
<li>Dans la configuration du job, cochez <strong>Build periodically</strong> (Construire périodiquement).</li>
<li>Entrez une expression cron. Par exemple, pour exécuter le job chaque jour à minuit :
<pre><code>H 0 * * *
</code></pre>
Cette syntaxe permet de planifier un build quotidien à minuit tout en optimisant la répartition des ressources.</li>
</ol>
<h4 id="triggers-de-build--scm-polling"><a class="header" href="#triggers-de-build--scm-polling">Triggers de build : SCM polling</a></h4>
<p>Le <strong>SCM polling</strong> (surveillance du dépôt) permet à Jenkins de surveiller un dépôt de code (comme Git) et de déclencher un build lorsque des modifications sont détectées.</p>
<ol>
<li>Cochez <strong>Poll SCM</strong> dans les paramètres du job.</li>
<li>Définissez une expression cron pour la fréquence de surveillance. Par exemple :
<pre><code>H/5 * * * *
</code></pre>
Ce cron vérifie les modifications toutes les 5 minutes.</li>
</ol>
<h4 id="triggers-de-build--webhooks"><a class="header" href="#triggers-de-build--webhooks">Triggers de build : Webhooks</a></h4>
<p>Les <strong>webhooks</strong> permettent à des services externes (comme GitHub) de déclencher des jobs Jenkins lorsqu’il y a des mises à jour. Pour configurer un webhook :</p>
<ol>
<li>Dans Jenkins, copiez l’URL du job que vous souhaitez déclencher.</li>
<li>Dans les paramètres de votre dépôt (par exemple, sur GitHub), configurez un webhook en collant l’URL du job Jenkins.</li>
<li>Désormais, chaque fois qu’un commit ou une PR est créée, Jenkins recevra une notification et déclenchera le build.</li>
</ol>
<blockquote>
<p><strong>Remarque</strong> : Les webhooks sont utiles pour des projets où des modifications sont apportées fréquemment et où un build doit être déclenché instantanément.</p>
</blockquote>
<p><img src="jenkins/sections/../images/02_Basics/webhook.jpg" alt="Planification de builds Jenkins avec webhooks" /></p>
<blockquote>
<p>Tutoriels pour le setup d'un webhook Github avec Jenkins :</p>
<ul>
<li>https://medium.com/@sangeetv09/how-to-configure-webhook-in-github-and-jenkins-for-automatic-trigger-with-cicd-pipeline-34133e9de0ea</li>
<li>https://www.blazemeter.com/blog/how-to-integrate-your-github-repository-to-your-jenkins-project</li>
</ul>
</blockquote>
<hr />
<h3 id="exercice--créer-un-job-jenkins-pour-exécuter-un-script-hello-world-et-planifier-un-build-quotidien"><a class="header" href="#exercice--créer-un-job-jenkins-pour-exécuter-un-script-hello-world-et-planifier-un-build-quotidien">Exercice : Créer un job Jenkins pour exécuter un script “Hello, World!” et planifier un build quotidien</a></h3>
<p><strong>Objectif de l'exercice</strong> : Créer et planifier un job Jenkins qui exécute une commande de type “Hello, World!” et configurez-le pour s’exécuter automatiquement.</p>
<p><strong>Étapes de l’exercice</strong> :</p>
<ol>
<li><strong>Créer un nouveau job</strong> : Depuis le tableau de bord Jenkins, créez un job <strong>Freestyle</strong> nommé “Hello World”.</li>
<li><strong>Configurer le build</strong> :
<ul>
<li>Ajoutez une étape <strong>Execute shell</strong> (ou <strong>Commande Windows</strong>) avec la commande :
<pre><code class="language-bash">echo "Hello, World!"
</code></pre>
</li>
</ul>
</li>
<li><strong>Déclencher manuellement le build</strong> : Une fois le job sauvegardé, lancez-le en utilisant <strong>Build Now</strong> et vérifiez la sortie de console.</li>
<li><strong>Planifier un build quotidien</strong> : Dans la configuration du job, activez <strong>Build periodically</strong> et entrez l’expression cron suivante pour un build quotidien à 8h00 :
<pre><code>H 8 * * *
</code></pre>
</li>
<li><strong>(Optionnel) Ajouter un paramètre de branche</strong> : Configurez le job pour inclure un <strong>String Parameter</strong> nommé <code>BRANCH_NAME</code>, et modifiez le script pour afficher cette valeur.</li>
</ol>
<hr />
<h4 id="ressources-supplémentaires-1"><a class="header" href="#ressources-supplémentaires-1">Ressources supplémentaires</a></h4>
<ul>
<li><a href="https://www.jenkins.io/doc/pipeline/steps/">Documentation de Jenkins - Types de Jobs</a></li>
<li><a href="https://www.jenkins.io/doc/book/pipeline/syntax/#cron-syntax">Syntaxe cron de Jenkins</a></li>
<li><a href="https://www.jenkins.io/blog/2019/01/07/webhook-firewalls/">Configurer un webhook avec GitHub et Jenkins</a></li>
</ul>
<hr />
<h4 id="questions-de-révision-1"><a class="header" href="#questions-de-révision-1">Questions de Révision</a></h4>
<details>
<summary><h3 style="display:inline-block">Questions de Révision</h3></summary>
<details>
<summary>Quels types de jobs
<p>peut-on créer dans Jenkins ?</summary>
Les principaux types de jobs sont : Freestyle, Pipeline, Multibranch Pipeline, et Folder.</p>
</details>
<details>
<summary>Comment peut-on visualiser les logs d’un build ?</summary>
Dans la page du build, cliquez sur **Console Output** pour voir les logs détaillés.
</details>
<details>
<summary>Comment configurer un job pour s’exécuter automatiquement tous les jours à 8h00 ?</summary>
Activez **Build periodically** dans la configuration du job et entrez l’expression cron `H 8 * * *`.
</details>
<details>
<summary>Comment un webhook déclenche-t-il un build Jenkins ?</summary>
En configurant le webhook dans les paramètres d’un dépôt (par exemple, GitHub), chaque mise à jour du dépôt envoie une notification à Jenkins pour déclencher le build.
</details>
</details>
<div style="break-before: page; page-break-before: always;"></div><h2 id="partie-3--introduction-aux-pipelines-jenkins"><a class="header" href="#partie-3--introduction-aux-pipelines-jenkins">Partie 3 : Introduction aux Pipelines Jenkins</a></h2>
<h3 id="objectifs-2"><a class="header" href="#objectifs-2">Objectifs</a></h3>
<p>Dans cette partie, vous allez :</p>
<ul>
<li><strong>Découvrir les pipelines Jenkins</strong> et leur structure.</li>
<li><strong>Créer un premier pipeline simple</strong> en utilisant la syntaxe déclarative avec un Jenkinsfile.</li>
</ul>
<hr />
<h3 id="31-quest-ce-quun-pipeline-jenkins-"><a class="header" href="#31-quest-ce-quun-pipeline-jenkins-">3.1 Qu’est-ce qu’un pipeline Jenkins ?</a></h3>
<h4 id="présentation-des-pipelines-jenkins"><a class="header" href="#présentation-des-pipelines-jenkins">Présentation des pipelines Jenkins</a></h4>
<p>Un <strong>pipeline Jenkins</strong> est une suite d’étapes automatisées qui gère le cycle de vie complet d’un projet de développement, de la construction jusqu'au déploiement. Contrairement aux jobs Freestyle, les pipelines Jenkins sont codés dans des fichiers <strong>Jenkinsfile</strong>, ce qui permet de versionner et de partager facilement la configuration du pipeline.</p>
<h4 id="différence-entre-pipelines-déclaratifs-et-pipelines-scriptés"><a class="header" href="#différence-entre-pipelines-déclaratifs-et-pipelines-scriptés">Différence entre pipelines déclaratifs et pipelines scriptés</a></h4>
<ul>
<li><strong>Pipeline déclaratif</strong> : Utilise une syntaxe claire et structurée. C'est le choix recommandé pour les utilisateurs débutants et pour les configurations simples.</li>
<li><strong>Pipeline scripté</strong> : Basé sur le langage Groovy, il est plus flexible et complexe, permettant des scripts personnalisés.</li>
</ul>
<p>Dans ce cours, nous nous concentrerons sur la syntaxe <strong>déclarative</strong>, qui est plus facile à comprendre et à maintenir.</p>
<hr />
<h3 id="32-création-dun-pipeline-jenkins-avec-le-jenkinsfile"><a class="header" href="#32-création-dun-pipeline-jenkins-avec-le-jenkinsfile">3.2 Création d’un pipeline Jenkins avec le Jenkinsfile</a></h3>
<p>Un pipeline dans Jenkins se compose de plusieurs <strong>blocs</strong>. Explorons chacun d’eux en détail.</p>
<h4 id="structure-de-base-dun-jenkinsfile"><a class="header" href="#structure-de-base-dun-jenkinsfile">Structure de base d’un Jenkinsfile</a></h4>
<p>Un Jenkinsfile contient un ensemble de blocs hiérarchisés qui définissent l’agent, les étapes, et les actions du pipeline. Voici les blocs principaux :</p>
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('StageName') {
            steps {
                // steps to perform
            }
        }
    }
}
</code></pre>
<h4 id="les-blocs-principaux-dun-jenkinsfile"><a class="header" href="#les-blocs-principaux-dun-jenkinsfile">Les blocs principaux d’un Jenkinsfile</a></h4>
<ol>
<li>
<p><strong>Bloc <code>pipeline</code></strong> : Le bloc racine qui encapsule tout le pipeline.</p>
<ul>
<li>Ce bloc est obligatoire dans un Jenkinsfile.</li>
<li>Il contient les autres blocs comme <code>agent</code>, <code>stages</code>, et <code>post</code>.</li>
</ul>
</li>
<li>
<p><strong>Bloc <code>agent</code></strong> : Définit l’environnement dans lequel le pipeline s’exécutera.</p>
<ul>
<li>L’agent peut être défini au niveau global pour tout le pipeline, ou au niveau de chaque étape.</li>
<li><strong>Exemples d’agents</strong> :
<ul>
<li><code>agent any</code> : Exécute le pipeline sur n'importe quel agent disponible.</li>
<li><code>agent none</code> : Aucun agent par défaut ; utile si chaque étape définit son propre agent.</li>
<li><code>agent { label 'docker' }</code> : Exécute le pipeline sur un agent spécifique nommé "docker".</li>
<li><code>agent { docker { image 'maven:3.8.1' } }</code> : Exécute le pipeline dans un conteneur Docker basé sur l'image spécifiée (ex. Maven).</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Bloc <code>stages</code></strong> : Contient toutes les étapes (stages) du pipeline.</p>
<ul>
<li>Un pipeline est structuré en plusieurs <strong>stages</strong> représentant les grandes phases, comme <code>Build</code>, <code>Test</code>, et <code>Deploy</code>.</li>
<li>Ce bloc est obligatoire pour organiser le pipeline.</li>
</ul>
</li>
<li>
<p><strong>Bloc <code>stage</code></strong> : Définit une étape particulière du pipeline.</p>
<ul>
<li>Chaque <strong>stage</strong> doit avoir un nom (par exemple, <code>Build</code> ou <code>Test</code>) et peut contenir un ou plusieurs <strong>steps</strong> (actions à réaliser).</li>
<li>Des stages peuvent s’exécuter en parallèle en utilisant <code>parallel</code>, ce qui est utile pour exécuter plusieurs tests simultanément.</li>
</ul>
</li>
<li>
<p><strong>Bloc <code>steps</code></strong> : Contient les actions (commands) à exécuter dans un stage.</p>
<ul>
<li><strong>Steps</strong> inclut des commandes comme <code>sh</code>, <code>bat</code> (pour Windows), ou encore <code>echo</code>.</li>
<li><strong>Exemples de steps</strong> :
<ul>
<li><code>sh 'echo Hello World'</code> : Exécute une commande shell sur un système Unix.</li>
<li><code>bat 'echo Hello World'</code> : Exécute une commande sur un système Windows.</li>
<li><code>git 'https://github.com/example/repo.git'</code> : Clone un dépôt Git.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Bloc <code>post</code></strong> : Contient les actions à effectuer après l’exécution des stages.</p>
<ul>
<li>Utilisé pour des étapes de nettoyage ou de notifications en cas de succès, d'échec, ou toujours.</li>
<li><strong>Sous-blocs courants</strong> :
<ul>
<li><code>always</code> : Exécute les actions quels que soient les résultats du pipeline.</li>
<li><code>success</code> : Exécute les actions uniquement si le pipeline réussit.</li>
<li><code>failure</code> : Exécute les actions uniquement si le pipeline échoue.</li>
</ul>
</li>
<li><strong>Exemple</strong> :
<pre><code class="language-groovy">post {
    success {
        echo 'Pipeline completed successfully.'
    }
    failure {
        echo 'Pipeline failed.'
    }
}
</code></pre>
</li>
</ul>
</li>
</ol>
<hr />
<h4 id="exemple-de-jenkinsfile-détaillé"><a class="header" href="#exemple-de-jenkinsfile-détaillé">Exemple de Jenkinsfile détaillé</a></h4>
<p>Voici un Jenkinsfile de base illustrant les blocs <code>pipeline</code>, <code>agent</code>, <code>stages</code>, <code>steps</code>, et <code>post</code>.</p>
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                echo 'Building...'
                // Add build steps here, e.g., sh 'mvn clean package'
            }
        }
        stage('Test') {
            steps {
                echo 'Testing...'
                // Add test steps here, e.g., sh 'mvn test'
            }
        }
        stage('Deploy') {
            steps {
                echo 'Deploying...'
                // Add deployment steps here, e.g., sh 'scp target/*.jar user@server:/path'
            }
        }
    }
    post {
        success {
            echo 'Pipeline completed successfully.'
        }
        failure {
            echo 'Pipeline failed.'
        }
    }
}
</code></pre>
<p>Dans cet exemple :</p>
<ul>
<li><strong>Stage Build</strong> : Simule l’étape de compilation. On pourrait y ajouter des commandes pour compiler le projet, comme <code>mvn clean package</code>.</li>
<li><strong>Stage Test</strong> : Simule l’étape de test. On pourrait y ajouter une commande de test, comme <code>mvn test</code>.</li>
<li><strong>Stage Deploy</strong> : Simule l’étape de déploiement. Cette étape peut inclure des commandes pour copier les fichiers sur un serveur distant.</li>
<li><strong>Bloc post</strong> : Envoie un message de réussite ou d’échec dans les logs.</li>
</ul>
<hr />
<h3 id="exercice--créer-un-jenkinsfile-pour-un-pipeline-simple-avec-les-étapes-build-test-et-deploy"><a class="header" href="#exercice--créer-un-jenkinsfile-pour-un-pipeline-simple-avec-les-étapes-build-test-et-deploy">Exercice : Créer un Jenkinsfile pour un pipeline simple avec les étapes "Build", "Test" et "Deploy"</a></h3>
<p><strong>Objectif de l'exercice</strong> : Créer un Jenkinsfile pour configurer un pipeline simple avec trois étapes (Build, Test, Deploy) et exécuter ce pipeline dans Jenkins.</p>
<p><strong>Étapes de l’exercice</strong> :</p>
<ol>
<li><strong>Créer un nouveau job Pipeline</strong> : Depuis le tableau de bord Jenkins, créez un job de type <strong>Pipeline</strong> et donnez-lui un nom (par exemple, "Pipeline Hello World").</li>
<li><strong>Créer le fichier Jenkinsfile</strong> :
<ul>
<li>Dans votre dépôt de code, créez un fichier nommé <code>Jenkinsfile</code>.</li>
<li>Ajoutez le code suivant :
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                echo 'Building...'
            }
        }
        stage('Test') {
            steps {
                echo 'Testing...'
            }
        }
        stage('Deploy') {
            steps {
                echo 'Deploying...'
            }
        }
    }
    post {
        success {
            echo 'Pipeline completed successfully.'
        }
        failure {
            echo 'Pipeline failed.'
        }
    }
}
</code></pre>
</li>
<li>Enregistrez le fichier et assurez-vous qu’il est accessible depuis Jenkins.</li>
</ul>
</li>
<li><strong>Lancer le pipeline</strong> : Accédez à votre job pipeline dans Jenkins et cliquez sur <strong>Build Now</strong> pour exécuter le pipeline.</li>
<li><strong>Vérifier les logs</strong> : Après exécution, vérifiez les logs pour voir les messages "Building...", "Testing...", et "Deploying...".</li>
<li>**</li>
</ol>
<p>Visualiser avec Blue Ocean** : Si Blue Ocean est installé, visualisez le pipeline pour suivre chaque étape graphiquement.</p>
<hr />
<h4 id="ressources-supplémentaires-2"><a class="header" href="#ressources-supplémentaires-2">Ressources supplémentaires</a></h4>
<ul>
<li><a href="https://www.jenkins.io/doc/book/pipeline/">Documentation officielle des pipelines Jenkins</a></li>
</ul>
<hr />
<h4 id="questions-de-révision-2"><a class="header" href="#questions-de-révision-2">Questions de Révision</a></h4>
<details>
<summary><h3 style="display:inline-block">Questions de Révision</h3></summary>
<details>
<summary>Qu'est-ce qu'un pipeline Jenkins ?</summary>
Un pipeline Jenkins est un workflow codé qui définit les étapes de construction, de test et de déploiement d’un projet.
</details>
<details>
<summary>À quoi sert le bloc `agent` dans un Jenkinsfile ?</summary>
Le bloc `agent` définit l’environnement où le pipeline va s’exécuter (par exemple, sur un serveur Docker ou un agent spécifique).
</details>
<details>
<summary>Comment fonctionne le bloc `post` dans un Jenkinsfile ?</summary>
Le bloc `post` permet d’exécuter des actions après les étapes du pipeline, en fonction de son statut (succès, échec, etc.).
</details>
</details>
<div style="break-before: page; page-break-before: always;"></div><h2 id="partie-4--gestion-des-jobs-et-pipelines-dans-jenkins"><a class="header" href="#partie-4--gestion-des-jobs-et-pipelines-dans-jenkins">Partie 4 : Gestion des Jobs et Pipelines dans Jenkins</a></h2>
<h3 id="objectifs-3"><a class="header" href="#objectifs-3">Objectifs</a></h3>
<p>Dans cette partie, vous allez :</p>
<ul>
<li><strong>Structurer et configurer des pipelines avancés</strong> avec plusieurs stages et steps.</li>
<li><strong>Maîtriser l’utilisation des agents Jenkins</strong>, pour exécuter des pipelines sur différents environnements.</li>
<li><strong>Gérer les post-actions</strong> afin de déclencher des actions automatiques, comme des notifications en fonction du succès ou de l’échec des pipelines.</li>
</ul>
<hr />
<h3 id="41-stages-et-steps-dans-les-pipelines"><a class="header" href="#41-stages-et-steps-dans-les-pipelines">4.1 Stages et Steps dans les pipelines</a></h3>
<h4 id="structuration-dun-pipeline-avec-plusieurs-stages"><a class="header" href="#structuration-dun-pipeline-avec-plusieurs-stages">Structuration d’un pipeline avec plusieurs stages</a></h4>
<p>Dans un pipeline Jenkins, le bloc <code>stages</code> est utilisé pour diviser le processus en plusieurs phases, appelées <strong>stages</strong>. Chaque stage représente une étape du cycle de vie du projet, comme <code>Build</code>, <code>Test</code>, ou <code>Deploy</code>. Cela permet de structurer le pipeline de manière claire et logique, et chaque stage peut être exécuté indépendamment ou en parallèle.</p>
<p><strong>Exemple de définition de plusieurs stages :</strong></p>
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                echo 'Building project...'
                // Commandes de build, ex. : sh 'mvn clean package'
            }
        }
        stage('Test') {
            steps {
                echo 'Running tests...'
                // Commandes de test, ex. : sh 'mvn test'
            }
        }
        stage('Deploy') {
            steps {
                echo 'Deploying application...'
                // Commandes de déploiement, ex. : scp ou ssh
            }
        }
    }
}
</code></pre>
<p>Dans cet exemple :</p>
<ul>
<li><strong>Stage Build</strong> : Représente la compilation du projet.</li>
<li><strong>Stage Test</strong> : Effectue des tests pour vérifier le bon fonctionnement.</li>
<li><strong>Stage Deploy</strong> : Gère le déploiement de l’application.</li>
</ul>
<p>Ces stages sont exécutés dans l’ordre, de haut en bas.</p>
<h4 id="utilisation-des-steps-dans-chaque-stage"><a class="header" href="#utilisation-des-steps-dans-chaque-stage">Utilisation des steps dans chaque stage</a></h4>
<p>Les <strong>steps</strong> sont les actions spécifiques qui s’exécutent dans chaque stage. Elles incluent des commandes de compilation, de test, de déploiement, ou des scripts personnalisés. Dans Jenkins, on utilise souvent les instructions <code>sh</code> pour des commandes Unix/Linux et <code>bat</code> pour des commandes Windows.</p>
<p><strong>Exemple de steps :</strong></p>
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                sh 'mvn clean package'
            }
        }
        stage('Test') {
            steps {
                sh 'mvn test'
            }
        }
        stage('Deploy') {
            steps {
                sh 'scp target/*.jar user@server:/path'
            }
        }
    }
}
</code></pre>
<p>Dans cet exemple, chaque étape exécute une commande spécifique :</p>
<ul>
<li><code>Build</code> : Compile le projet Maven.</li>
<li><code>Test</code> : Exécute les tests Maven.</li>
<li><code>Deploy</code> : Copie l’artefact compilé vers un serveur distant.</li>
</ul>
<hr />
<h3 id="42-agents-jenkins"><a class="header" href="#42-agents-jenkins">4.2 Agents Jenkins</a></h3>
<h4 id="introduction-aux-agents"><a class="header" href="#introduction-aux-agents">Introduction aux agents</a></h4>
<p>Les <strong>agents Jenkins</strong> sont des environnements d’exécution utilisés pour réaliser les étapes d’un pipeline. Jenkins permet d’assigner un agent pour exécuter tout un pipeline ou bien un agent spécifique pour chaque stage.</p>
<h4 id="définir-un-agent-pour-un-pipeline-ou-un-stage"><a class="header" href="#définir-un-agent-pour-un-pipeline-ou-un-stage">Définir un agent pour un pipeline ou un stage</a></h4>
<ol>
<li><strong>Agent global</strong> : Lorsqu’un agent est défini au niveau du pipeline, il s’applique à toutes les étapes. L'agent global le plus couramment utilisé est <code>agent any</code>, qui utilise n'importe quel agent disponible.</li>
<li><strong>Agent par stage</strong> : On peut aussi assigner un agent spécifique à chaque stage. Cela permet de définir des environnements différents pour les différentes phases du pipeline (par exemple, une instance AWS EC2 pour le build et une autre pour le test).</li>
</ol>
<p><strong>Exemple de pipeline avec des agents spécifiques :</strong></p>
<pre><code class="language-groovy">pipeline {
    agent none
    stages {
        stage('Build') {
            agent { label 'build-server' }
            steps {
                sh 'mvn clean package'
            }
        }
        stage('Test') {
            agent { label 'test-server' }
            steps {
                sh 'mvn test'
            }
        }
        stage('Deploy') {
            agent { label 'deploy-server' }
            steps {
                sh 'scp target/*.jar user@production-server:/path'
            }
        }
    }
}
</code></pre>
<p>Dans cet exemple :</p>
<ul>
<li>Le pipeline n’a pas d’agent global (<code>agent none</code>).</li>
<li>Chaque stage utilise un agent spécifique, désigné par un <strong>label</strong> (<code>build-server</code>, <code>test-server</code>, <code>deploy-server</code>). Ces labels correspondent aux agents configurés dans Jenkins.</li>
</ul>
<hr />
<h3 id="43-gestion-des-post-actions"><a class="header" href="#43-gestion-des-post-actions">4.3 Gestion des post-actions</a></h3>
<p>Les <strong>post-actions</strong> dans Jenkins permettent d’exécuter des actions après la fin d’un pipeline, en fonction du statut de son exécution (succès, échec, ou peu importe le résultat). Elles sont utilisées pour :</p>
<ul>
<li><strong>Envoyer des notifications</strong> (ex. : e-mail, Slack) en cas de succès ou d’échec.</li>
<li><strong>Nettoyer les ressources</strong> ou archiver des logs à la fin d’un job.</li>
<li><strong>Déclencher des jobs en chaîne</strong> selon le résultat.</li>
</ul>
<h4 id="types-de-post-actions"><a class="header" href="#types-de-post-actions">Types de post-actions</a></h4>
<ol>
<li><strong><code>always</code></strong> : Exécute l’action indépendamment du succès ou de l’échec du pipeline.</li>
<li><strong><code>success</code></strong> : Exécute l’action uniquement si le pipeline s’achève sans erreur.</li>
<li><strong><code>failure</code></strong> : Exécute l’action uniquement en cas d’échec du pipeline.</li>
</ol>
<p><strong>Exemple de post-actions dans un Jenkinsfile :</strong></p>
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                sh 'mvn clean package'
            }
        }
        stage('Test') {
            steps {
                sh 'mvn test'
            }
        }
        stage('Deploy') {
            steps {
                sh 'scp target/*.jar user@production-server:/path'
            }
        }
    }
    post {
        success {
            echo 'Pipeline completed successfully.'
            // Commande pour envoyer une notification de succès (ex. : Slack ou e-mail)
        }
        failure {
            echo 'Pipeline failed.'
            // Commande pour envoyer une notification d’échec (ex. : Slack ou e-mail)
        }
        always {
            echo 'Cleaning up resources...'
            // Commande pour nettoyer ou archiver les artefacts
        }
    }
}
</code></pre>
<p>Dans cet exemple :</p>
<ul>
<li><strong>Bloc <code>success</code></strong> : Exécute des actions uniquement si le pipeline réussit, par exemple en envoyant une notification de succès.</li>
<li><strong>Bloc <code>failure</code></strong> : Déclenche des actions en cas d’échec, comme une alerte par e-mail ou une notification dans Slack.</li>
<li><strong>Bloc <code>always</code></strong> : Effectue des actions de nettoyage ou d’archivage, quel que soit le résultat du pipeline.</li>
</ul>
<hr />
<h3 id="exercice--configurer-un-pipeline-avec-des-stages-des-steps-spécifiques-et-des-notifications-de-succèséchec"><a class="header" href="#exercice--configurer-un-pipeline-avec-des-stages-des-steps-spécifiques-et-des-notifications-de-succèséchec">Exercice : Configurer un pipeline avec des stages, des steps spécifiques, et des notifications de succès/échec</a></h3>
<p><strong>Objectif de l'exercice</strong> : Créer un pipeline avec plusieurs stages, incluant des steps spécifiques pour chaque stage, et configurer des notifications de succès ou d’échec à la fin du pipeline.</p>
<p><strong>Étapes de l’exercice</strong> :</p>
<ol>
<li><strong>Créer un nouveau job Pipeline</strong> : Dans Jenkins, créez un job de type <strong>Pipeline</strong> et donnez-lui un nom (par exemple, "Pipeline Avancé").</li>
<li><strong>Créer le Jenkinsfile</strong> :
<ul>
<li>Dans votre dépôt de code, créez un fichier nommé <code>Jenkinsfile</code>.</li>
<li>Ajoutez le code suivant :
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                echo 'Building project...'
                // Commande de build, ex. : sh 'mvn clean package'
            }
        }
        stage('Test') {
            steps {
                echo 'Running tests...'
                // Commande de test, ex. : sh 'mvn test'
            }
        }
        stage('Deploy') {
            steps {
                echo 'Deploying application...'
                // Commande de déploiement, ex. : scp ou ssh
            }
        }
    }
    post {
        success {
            echo 'Pipeline completed successfully!'
            // Ajouter une notification de succès (ex. : e-mail, Slack)
        }
        failure {
            echo 'Pipeline failed.'
            // Ajouter une notification d’échec (ex. : e-mail, Slack)
        }
        always {
            echo 'Cleaning up resources...'
            // Ajouter des commandes pour nettoyer ou archiver les artefacts
        }
    }
}
</code></pre>
</li>
</ul>
</li>
<li><strong>Lancer le pipeline</strong> : Dans Jenkins, exécutez le pipeline en cliquant sur <strong>Build Now</strong> et vérifiez les messages de succès ou d’échec en fonction du résultat de l’exécution.</li>
<li><strong>Vérifier les logs et notifications</strong> : Accédez aux logs pour voir le détail des étapes et assurez-vous que les messages de succès/échec sont affichés comme prévu.</li>
</ol>
<hr />
<h3 id="ressources-supplémentaires-3"><a class="header" href="#ressources-supplémentaires-3">Ressources supplémentaires</a></h3>
<ul>
<li><a href="https://www.jenkins.io/doc/book/pipeline/">Documentation des pipelines Jenkins</a></li>
<li><a href="https://www.jenkins.io/doc/book/pipeline/syntax/#post">Gestion des post-actions dans les pipelines</a></li>
<li><a href="https://www.jenkins.io/doc/book/using/using-agents/">Configuration des agents Jenkins</a></li>
</ul>
<hr />
<h3 id="questions-de-révision-3"><a class="header" href="#questions-de-révision-3">Questions de Révision</a></h3>
<details>
<summary><h3 style="display:inline-block">Questions de Révision</h3></summary>
<details>
<summary>Qu'est-ce qu'un stage dans un pipeline Jenkins ?</summary>
Un stage est une étape dans le pipeline, utilisée pour diviser le processus en phases distinctes comme "Build", "Test", et "Deploy".
</details>
<details>
<summary>Pourquoi utiliser des agents différents pour chaque stage ?</summary>
Cela permet d’exécuter chaque phase dans un environnement optimisé pour cette étape, par exemple un serveur de test pour le stage de test et un serveur de production pour le déploiement.
</details>
<details>
<summary>Quelles sont les post-actions les plus courantes dans un pipeline Jenkins ?</summary>
Les post-actions courantes sont `success` pour les actions de réussite, `failure` pour les échecs, et `always` pour les actions à exécuter quel que soit le résultat.
</details>
</details><div style="break-before: page; page-break-before: always;"></div><h2 id="partie-5--utilisation-de-plugins-et-bibliothèques-partagées-dans-jenkins"><a class="header" href="#partie-5--utilisation-de-plugins-et-bibliothèques-partagées-dans-jenkins">Partie 5 : Utilisation de Plugins et Bibliothèques Partagées dans Jenkins</a></h2>
<h3 id="objectifs-4"><a class="header" href="#objectifs-4">Objectifs</a></h3>
<p>Dans cette partie, vous allez :</p>
<ul>
<li><strong>Comprendre l’importance des plugins dans Jenkins</strong> et installer les plugins essentiels pour les pipelines CI/CD.</li>
<li><strong>Découvrir les bibliothèques partagées</strong> pour créer des pipelines réutilisables et modulaires.</li>
</ul>
<hr />
<h3 id="51-installation-et-gestion-des-plugins"><a class="header" href="#51-installation-et-gestion-des-plugins">5.1 Installation et gestion des plugins</a></h3>
<h4 id="introduction-aux-plugins-et-leur-utilité"><a class="header" href="#introduction-aux-plugins-et-leur-utilité">Introduction aux plugins et leur utilité</a></h4>
<p>Les plugins Jenkins permettent d’étendre les fonctionnalités de base en ajoutant des outils et des intégrations indispensables aux pipelines CI/CD. Ils permettent, entre autres :</p>
<ul>
<li><strong>D’intégrer des outils externes</strong> (comme Git, Docker) dans Jenkins.</li>
<li><strong>D’améliorer l’interface utilisateur</strong> avec des options de visualisation, comme le plugin <strong>Blue Ocean</strong>.</li>
<li><strong>D’automatiser des tâches</strong> pour accélérer les workflows et ajouter des fonctionnalités avancées (par exemple, intégration de Slack pour les notifications).</li>
</ul>
<h4 id="installation-des-plugins-essentiels-pour-cicd"><a class="header" href="#installation-des-plugins-essentiels-pour-cicd">Installation des plugins essentiels pour CI/CD</a></h4>
<ol>
<li><strong>Accéder à la gestion des plugins</strong> : Allez dans <strong>Manage Jenkins &gt; Manage Plugins</strong>.</li>
<li><strong>Plugins recommandés</strong> :
<ul>
<li><strong>Git Plugin</strong> : Intègre les dépôts Git dans les pipelines Jenkins.</li>
<li><strong>Pipeline Plugin</strong> : Permet de créer des pipelines en tant que code dans un Jenkinsfile.</li>
<li><strong>Docker Pipeline</strong> : Intègre Docker dans Jenkins pour exécuter des étapes du pipeline dans des conteneurs.</li>
<li><strong>Blue Ocean</strong> : Fournit une interface utilisateur moderne pour visualiser et suivre les pipelines.</li>
<li><strong>Credentials Binding Plugin</strong> : Gère et utilise en sécurité les informations d’identification.</li>
</ul>
</li>
</ol>
<hr />
<h3 id="52-création-et-utilisation-de-bibliothèques-partagées"><a class="header" href="#52-création-et-utilisation-de-bibliothèques-partagées">5.2 Création et utilisation de bibliothèques partagées</a></h3>
<h4 id="quest-ce-quune-bibliothèque-partagée-"><a class="header" href="#quest-ce-quune-bibliothèque-partagée-">Qu’est-ce qu’une bibliothèque partagée ?</a></h4>
<p>Une <strong>bibliothèque partagée</strong> est un ensemble de scripts et de fonctions centralisés que vous pouvez réutiliser dans différents pipelines Jenkins, réduisant ainsi la redondance et facilitant la maintenance. Les bibliothèques partagées permettent :</p>
<ul>
<li><strong>D’organiser des étapes courantes</strong> (ex. : vérification de code, configuration d’environnement).</li>
<li><strong>De créer des pipelines modulaires</strong> en encapsulant des étapes récurrentes.</li>
</ul>
<h4 id="structuration-dune-bibliothèque-partagée"><a class="header" href="#structuration-dune-bibliothèque-partagée">Structuration d'une bibliothèque partagée</a></h4>
<ol>
<li><strong>Créer un dépôt Git pour la bibliothèque</strong> : Définissez un dépôt Git pour stocker le code de la bibliothèque partagée.</li>
<li><strong>Organisation des dossiers dans la bibliothèque</strong> :
<ul>
<li><strong>vars/</strong> : Contient des scripts Groovy de fonctions réutilisables.</li>
<li><strong>src/</strong> : Contient des classes Groovy organisées en packages.</li>
<li><strong>resources/</strong> : Contient des fichiers de configuration statiques.</li>
</ul>
</li>
</ol>
<p><strong>Exemple de structure de répertoire</strong> :</p>
<pre><code>my-shared-library/
├── vars/
│   └── helloWorld.groovy
├── src/
│   └── org/
│       └── example/
│           └── utils/
│               └── Helper.groovy
└── resources/
    └── config/
        └── default-config.yaml
</code></pre>
<p><strong>Exemple de script dans <code>vars/helloWorld.groovy</code></strong> :</p>
<pre><code class="language-groovy">def call(String name = 'World') {
    echo "Hello, ${name}!"
}
</code></pre>
<p><img src="jenkins/sections/../images/05_Libraries/libraries.png" alt="Structure d&#39;une bibliothèque partagée dans Jenkins" /></p>
<blockquote>
<p>Source: https://www.jenkins.io/doc/book/pipeline/shared-libraries/</p>
</blockquote>
<h4 id="utiliser-une-bibliothèque-partagée-dans-un-jenkinsfile"><a class="header" href="#utiliser-une-bibliothèque-partagée-dans-un-jenkinsfile">Utiliser une bibliothèque partagée dans un Jenkinsfile</a></h4>
<ol>
<li>
<p><strong>Déclarer la bibliothèque partagée</strong> :</p>
<ul>
<li>Allez dans <strong>Manage Jenkins &gt; Configure System</strong> et ajoutez la bibliothèque partagée dans <strong>Global Pipeline Libraries</strong> en spécifiant son nom et le dépôt Git associé.</li>
</ul>
</li>
<li>
<p><strong>Appeler des fonctions de la bibliothèque dans un Jenkinsfile</strong> :</p>
<ul>
<li>Dans un Jenkinsfile, utilisez l’annotation <strong>@Library</strong> pour importer la bibliothèque.</li>
</ul>
</li>
</ol>
<p><strong>Exemple de Jenkinsfile utilisant une bibliothèque partagée</strong> :</p>
<pre><code class="language-groovy">@Library('my-shared-library') _

pipeline {
    agent any
    stages {
        stage('Greeting') {
            steps {
                helloWorld('Jenkins User') // Appel de la fonction définie dans vars/helloWorld.groovy
            }
        }
        stage('Build') {
            steps {
                echo 'Building the project...'
                // Autres étapes de build
            }
        }
    }
}
</code></pre>
<hr />
<h3 id="exercice--installer-le-plugin-git-et-configurer-un-pipeline-pour-cloner-et-exécuter-un-projet-github"><a class="header" href="#exercice--installer-le-plugin-git-et-configurer-un-pipeline-pour-cloner-et-exécuter-un-projet-github">Exercice : Installer le plugin Git et configurer un pipeline pour cloner et exécuter un projet GitHub</a></h3>
<p><strong>Objectif de l'exercice</strong> : Installer le plugin Git, puis configurer un pipeline Jenkins pour cloner un projet depuis GitHub et exécuter une commande sur le code récupéré.</p>
<p><strong>Étapes de l’exercice</strong> :</p>
<ol>
<li>
<p><strong>Installer le plugin Git</strong> :</p>
<ul>
<li>Accédez à <strong>Manage Jenkins &gt; Manage Plugins &gt; Available</strong> et recherchez <strong>Git Plugin</strong>.</li>
<li>Installez le plugin et redémarrez Jenkins si nécessaire.</li>
</ul>
</li>
<li>
<p><strong>Créer un nouveau job Pipeline</strong> :</p>
<ul>
<li>Depuis le tableau de bord Jenkins, créez un job de type <strong>Pipeline</strong> et nommez-le (par exemple, "GitHub Clone and Build").</li>
</ul>
</li>
<li>
<p><strong>Configurer le Jenkinsfile pour cloner un dépôt GitHub</strong> :</p>
<ul>
<li>Dans le dépôt Git associé au job, créez un fichier nommé <code>Jenkinsfile</code>.</li>
<li>Ajoutez le code suivant au Jenkinsfile pour cloner un projet et exécuter un build.</li>
</ul>
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Clone Repository') {
            steps {
                // Remplacez 'https://github.com/username/repository.git' par l’URL de votre dépôt
                git 'https://github.com/username/repository.git'
            }
        }
        stage('Build') {
            steps {
                echo 'Building the project...'
                // Ajoutez ici la commande pour compiler ou exécuter le projet, ex. : sh 'make build'
            }
        }
    }
}
</code></pre>
</li>
<li>
<p><strong>Exécuter le pipeline</strong> :</p>
<ul>
<li>Allez dans votre job Jenkins et cliquez sur <strong>Build Now</strong> pour exécuter le pipeline.</li>
<li>Surveillez les logs pour vérifier que le dépôt a été cloné et que la commande de build s’est exécutée.</li>
</ul>
</li>
</ol>
<hr />
<h3 id="liens-vers-la-documentation"><a class="header" href="#liens-vers-la-documentation">Liens vers la documentation</a></h3>
<ul>
<li><a href="https://plugins.jenkins.io/">Documentation officielle des plugins Jenkins</a></li>
<li><a href="https://www.jenkins.io/doc/book/pipeline/shared-libraries/">Guide des bibliothèques partagées dans Jenkins</a></li>
</ul>
<hr />
<h3 id="questions-de-révision-4"><a class="header" href="#questions-de-révision-4">Questions de Révision</a></h3>
<details>
<summary><h3 style="display:inline-block">Questions de Révision</h3></summary>
<details>
<summary>Pourquoi utiliser des plugins dans Jenkins ?</summary>
<details>
<summary>Solution</summary>
Les plugins permettent d’étendre les fonctionnalités de Jenkins en intégrant des outils tiers (ex. : Git, Docker) et en ajoutant des fonctionnalités spécifiques pour les pipelines CI/CD.
</details>
</details>
<details>
<summary>Quels sont les plugins essentiels pour les pipelines CI/CD ?</summary>
<details>
<summary>Solution</summary>
Les plugins essentiels incluent le **Git Plugin** pour le contrôle de version, le **Pipeline Plugin** pour la gestion des pipelines, le **Docker Pipeline** pour l’intégration de Docker, et **Blue Ocean** pour la visualisation.
</details>
</details>
<details>
<summary>Comment déclarer une bibliothèque partagée dans Jenkins ?</summary>
<details>
<summary>Solution</summary>
Déclarez la bibliothèque partagée dans **Manage Jenkins > Configure System > Global Pipeline Libraries**, en précisant son nom et le dépôt Git associé.
</details>
</details>
<details>
<summary>Pourquoi utiliser des bibliothèques partagées dans Jenkins ?</summary>
<details>
<summary>Solution</summary>
Les bibliothèques partagées permettent de centraliser et réutiliser du code dans plusieurs pipelines, réduisant ainsi la duplication de code et facilitant la maintenance.
</details>
</details>
</details>
<hr />
<h3 id="conseils-pratiques"><a class="header" href="#conseils-pratiques">Conseils Pratiques</a></h3>
<ol>
<li><strong>Planifiez les mises à jour de plugins régulièrement</strong> pour bénéficier des améliorations de sécurité et de performance.</li>
<li><strong>Utilisez des bibliothèques partagées</strong> pour standardiser les étapes fréquentes des pipelines et faciliter leur maintenance.</li>
<li><strong>Sauvegardez votre configuration Jenkins</strong> (y compris les plugins) pour assurer une reprise rapide en cas de problème.
<a href="https://www.jenkins.io/doc/book/system-administration/backing-up/">Documentation sur les sauvegardes Jenkins</a></li>
</ol>
<hr />
<h3 id="défi-intermédiaire"><a class="header" href="#défi-intermédiaire">Défi Intermédiaire</a></h3>
<details>
<summary><h3 style="display:inline-block">Défi Intermédiaire</h3></summary>
**Objectif** : Configurer un pipeline Jenkins pour utiliser une bibliothèque partagée et un plugin de notification.
<p><strong>Contexte</strong> : Vous avez un pipeline complexe nécessitant des étapes standardisées de vérification de code et de tests, que vous souhaitez appeler depuis une bibliothèque partagée. Ajoutez également une étape de notification en fin de pipeline.</p>
<details>
<summary><b>Étapes principales</b></summary>
1. Créez une bibliothèque partagée avec une fonction `codeQualityCheck` dans le dossier `vars`.
2. Déclarez la bibliothèque dans Jenkins, sous **Global Pipeline Libraries**.
3. Configurez un pipeline pour exécuter la fonction `codeQualityCheck` et utilisez un plugin de notification (Slack ou email) pour notifier en fin de pipeline.
</details>
<p><strong>Compétences renforcées</strong> :</p>
<ul>
<li>Gestion des bibliothèques partagées</li>
<li>Utilisation de plugins de notification</li>
</ul>
<details>
<summary><b>Solution suggérée</b></summary>
Définissez `codeQualityCheck` dans `vars/codeQualityCheck.groovy` pour qu’elle effectue des tests ou des vérifications. Dans le Jenkinsfile, appelez cette fonction et configurez le plugin de notification pour envoyer une alerte en fin de pipeline.
</details>
</details>
<div style="break-before: page; page-break-before: always;"></div><h2 id="partie-6--automatisation-avancée-avec-jenkins-et-aws"><a class="header" href="#partie-6--automatisation-avancée-avec-jenkins-et-aws">Partie 6 : Automatisation Avancée avec Jenkins et AWS</a></h2>
<h3 id="objectifs-5"><a class="header" href="#objectifs-5">Objectifs</a></h3>
<p>Dans cette partie, vous allez :</p>
<ul>
<li><strong>Intégrer Jenkins avec des services AWS</strong> (EC2 et S3) en utilisant les rôles IAM pour une sécurité renforcée.</li>
<li><strong>Automatiser le provisionnement et la configuration des agents Jenkins</strong> sur EC2 en utilisant des clés SSH.</li>
</ul>
<hr />
<h3 id="61-introduction-à-lintégration-jenkins-et-aws"><a class="header" href="#61-introduction-à-lintégration-jenkins-et-aws">6.1 Introduction à l’intégration Jenkins et AWS</a></h3>
<h4 id="vue-densemble-des-possibilités-dintégration-de-jenkins-avec-aws"><a class="header" href="#vue-densemble-des-possibilités-dintégration-de-jenkins-avec-aws">Vue d’ensemble des possibilités d’intégration de Jenkins avec AWS</a></h4>
<p>Grâce à AWS, Jenkins peut :</p>
<ul>
<li><strong>Créer et gérer des instances EC2</strong> pour automatiser le déploiement et les tests d'applications.</li>
<li><strong>Stocker et gérer des artefacts</strong> dans S3, comme les logs et les résultats des tests.</li>
<li><strong>Assurer la sécurité des accès AWS</strong> en utilisant des rôles IAM, ce qui permet d’accorder les permissions nécessaires sans stocker de clés d’accès dans Jenkins.</li>
</ul>
<h4 id="configuration-des-rôles-iam-pour-jenkins"><a class="header" href="#configuration-des-rôles-iam-pour-jenkins">Configuration des rôles IAM pour Jenkins</a></h4>
<p>Pour permettre à Jenkins d'interagir en toute sécurité avec AWS, vous pouvez associer un <strong>rôle IAM</strong> aux instances EC2 de Jenkins plutôt que de stocker des informations d'identification dans Jenkins.</p>
<ol>
<li>
<p><strong>Créer un rôle IAM pour les instances EC2 de Jenkins</strong> :</p>
<ul>
<li>Dans la console IAM d’AWS, créez un rôle avec les permissions nécessaires (ex. : accès S3 pour stockage des artefacts, accès EC2 pour le lancement et la gestion des instances).</li>
<li>Assignez ce rôle aux instances EC2 sur lesquelles Jenkins s’exécute.</li>
</ul>
</li>
<li>
<p><strong>Configurer Jenkins pour utiliser le rôle IAM</strong> :</p>
<ul>
<li>Le rôle IAM attaché à l’instance EC2 sur laquelle Jenkins est exécuté fournit automatiquement les permissions AWS nécessaires. Aucune configuration supplémentaire d'informations d'identification n'est requise dans Jenkins.</li>
</ul>
</li>
</ol>
<p><img src="jenkins/sections/../images/06_AWS_Automation/IAM_Console.png" alt="Configuration d&#39;un rôle IAM pour Jenkins" /></p>
<hr />
<h3 id="62-provisionnement-de-linfrastructure-avec-ec2-et-configuration-dagents-jenkins"><a class="header" href="#62-provisionnement-de-linfrastructure-avec-ec2-et-configuration-dagents-jenkins">6.2 Provisionnement de l’infrastructure avec EC2 et configuration d’agents Jenkins</a></h3>
<h4 id="création-dinstances-ec2-via-jenkins"><a class="header" href="#création-dinstances-ec2-via-jenkins">Création d’instances EC2 via Jenkins</a></h4>
<p>Avec AWS CLI et les rôles IAM, vous pouvez automatiser la création d’instances EC2 directement depuis Jenkins.</p>
<ol>
<li>
<p><strong>Installer AWS CLI sur Jenkins</strong> :</p>
<ul>
<li>Sur l'instance Jenkins, installez AWS CLI pour permettre à Jenkins d’exécuter des commandes AWS directement.</li>
<li>Le rôle IAM associé à l'instance Jenkins donne accès aux services AWS nécessaires sans stockage de clés d’accès.</li>
</ul>
</li>
<li>
<p><strong>Exemple de script pour lancer une instance EC2 depuis un Jenkinsfile</strong> :</p>
<ul>
<li>Utilisez la commande <code>aws ec2 run-instances</code> pour lancer une instance EC2 avec les paramètres requis (image AMI, type d'instance, groupe de sécurité, et clé SSH).</li>
</ul>
</li>
</ol>
<p><strong>Exemple de Jenkinsfile pour lancer une instance EC2</strong> :</p>
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Launch EC2 Instance') {
            steps {
                sh '''
                aws ec2 run-instances --image-id ami-0abcdef1234567890 --instance-type t2.micro --key-name my-key --security-groups my-security-group
                '''
            }
        }
    }
}
</code></pre>
<p>Dans cet exemple :</p>
<ul>
<li><strong>Rôle IAM</strong> : L'instance Jenkins utilise les permissions de son rôle IAM pour exécuter <code>aws ec2 run-instances</code> sans informations d'identification explicites.</li>
<li><strong>Clé SSH</strong> : La clé SSH <code>my-key</code> est utilisée pour la connexion SSH à l'instance EC2 après son lancement.</li>
</ul>
<h4 id="configuration-dagents-jenkins-avec-ssh"><a class="header" href="#configuration-dagents-jenkins-avec-ssh">Configuration d’agents Jenkins avec SSH</a></h4>
<p>Une fois l’instance EC2 lancée, vous pouvez configurer cette instance comme agent Jenkins en utilisant une clé SSH.</p>
<ol>
<li>
<p><strong>Récupérer l’adresse IP de l’instance EC2</strong> :</p>
<ul>
<li>Après avoir lancé l’instance EC2, utilisez AWS CLI pour obtenir son adresse IP publique.</li>
</ul>
</li>
<li>
<p><strong>Ajouter un agent Jenkins avec la clé SSH</strong> :</p>
<ul>
<li>Dans Jenkins, accédez à <strong>Manage Jenkins &gt; Manage Nodes and Clouds &gt; New Node</strong>.</li>
<li>Donnez un nom à l’agent (ex. : <code>ec2-agent</code>) et sélectionnez <strong>Permanent Agent</strong>.</li>
<li>Configurez les paramètres de l'agent :
<ul>
<li><strong>Remote root directory</strong> : Spécifiez le répertoire de travail sur l’instance EC2 (ex. : <code>/home/ubuntu/jenkins</code>).</li>
<li><strong>Launch method</strong> : Choisissez <strong>Launch agent via SSH</strong> et configurez les informations d’accès SSH.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Configurer l’authentification SSH avec la clé privée</strong> :</p>
<ul>
<li><strong>Host</strong> : Entrez l’adresse IP publique de l’instance EC2.</li>
<li><strong>Credentials</strong> : Sélectionnez une clé SSH existante dans Jenkins ou ajoutez une nouvelle clé privée pour vous connecter à l’instance EC2.</li>
<li><strong>Host Key Verification Strategy</strong> : Choisissez <strong>Non verifying Verification Strategy</strong> ou configurez l’empreinte de clé pour plus de sécurité.</li>
</ul>
</li>
</ol>
<hr />
<h3 id="63-stockage-et-gestion-des-artefacts-avec-s3"><a class="header" href="#63-stockage-et-gestion-des-artefacts-avec-s3">6.3 Stockage et gestion des artefacts avec S3</a></h3>
<h4 id="utilisation-de-s3-pour-stocker-les-logs-et-artefacts"><a class="header" href="#utilisation-de-s3-pour-stocker-les-logs-et-artefacts">Utilisation de S3 pour stocker les logs et artefacts</a></h4>
<p>S3 est un excellent choix pour stocker les artefacts de builds, les logs, et les résultats des tests, notamment pour les projets de grande envergure.</p>
<ol>
<li>
<p><strong>Créer un bucket S3 pour les artefacts Jenkins</strong> :</p>
<ul>
<li>Dans la console S3, créez un bucket dédié aux artefacts Jenkins.</li>
<li>Configurez des dossiers pour organiser les artefacts, comme <code>logs</code>, <code>builds</code>, ou <code>reports</code>.</li>
</ul>
</li>
<li>
<p><strong>Script pour transférer les artefacts vers S3</strong> :</p>
<ul>
<li>Dans un Jenkinsfile, utilisez AWS CLI pour copier les fichiers de build ou logs depuis Jenkins vers le bucket S3.</li>
<li>La commande <code>aws s3 cp</code> permet de copier des fichiers et dossiers vers un bucket S3.</li>
</ul>
</li>
</ol>
<p><strong>Exemple de Jenkinsfile pour transférer les artefacts dans S3</strong> :</p>
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                echo 'Building the project...'
                sh 'make build' // Exemple de commande de build
            }
        }
        stage('Upload to S3') {
            steps {
                sh '''
                aws s3 cp build/output.zip s3://my-jenkins-artifacts/builds/output.zip
                aws s3 cp logs/test.log s3://my-jenkins-artifacts/logs/test.log
                '''
            }
        }
    }
}
</code></pre>
<p>Dans cet exemple :</p>
<ul>
<li><strong>Rôle IAM</strong> : Le rôle IAM associé à l'instance Jenkins doit disposer des permissions nécessaires pour écrire dans le bucket S3.</li>
<li><strong>Upload vers S3</strong> : Les artefacts <code>output.zip</code> et <code>test.log</code> sont transférés vers des dossiers spécifiques dans le bucket S3.</li>
</ul>
<h4 id="configuration-des-permissions-pour-sécuriser-laccès-à-s3"><a class="header" href="#configuration-des-permissions-pour-sécuriser-laccès-à-s3">Configuration des permissions pour sécuriser l’accès à S3</a></h4>
<ol>
<li><strong>Configurer les permissions S3 dans le rôle IAM</strong> :
<ul>
<li>Dans la console IAM, modifiez le rôle associé à Jenkins pour accorder uniquement les permissions <code>s3:PutObject</code> et <code>s3:GetObject</code> pour le bucket S3 de Jenkins.</li>
</ul>
</li>
<li><strong>Contrôler l'accès aux artefacts S3</strong> :
<ul>
<li>Configurez le bucket S3 pour qu'il soit privé, limitant ainsi l’accès aux artefacts aux seules entités ayant les bonnes permissions IAM.</li>
</ul>
</li>
</ol>
<hr />
<h3 id="exercice--automatisation-avec-jenkins-ec2-et-s3"><a class="header" href="#exercice--automatisation-avec-jenkins-ec2-et-s3">Exercice : Automatisation avec Jenkins, EC2, et S3</a></h3>
<p><strong>Objectif de l'exercice</strong> : Créer un job Jenkins pour lancer une instance EC2, configurer cette instance comme agent Jenkins avec SSH, déployer une application, et stocker les logs et artefacts dans S3.</p>
<p><strong>Étapes de l’exercice</strong> :</p>
<ol>
<li><strong>Lancer une instance EC2 avec AWS CLI</strong> : Configurez un pipeline Jenkins pour lancer une instance EC2 avec les paramètres d'AMI, de groupe de sécurité, et de clé SSH.</li>
<li><strong>Configurer l’instance comme agent Jenkins</strong> : Utilisez l’adresse IP publique de l’instance EC2 et configurez l’agent dans <strong>Manage Nodes</strong> en utilisant une connexion SSH et une clé privée.</li>
<li><strong>Déployer une application</strong> : Ajoutez un script pour déployer une application sur l’instance EC2 (par exemple, copie de fichiers ou exécution d’un serveur).</li>
<li><strong>Transférer les logs et artefacts dans S3</strong> : Configurez une étape pour copier les fichiers générés vers un bucket S3 dédié.</li>
</ol>
<hr />
<h3 id="liens-vers-la-documentation-1"><a class="header" href="#liens-vers-la-documentation-1">Liens vers la documentation</a></h3>
<ul>
<li><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html">Documentation AWS IAM pour les rôles EC2</a> [<a href="https://docs.aws.amazon.com/fr_fr/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html"> <em>fr</em></a>]</li>
<li><a href="https://aws.amazon.com/cli/">Documentation AWS CLI</a> [<a href="https://aws.amazon.com/fr/cli/"><em>fr</em></a>]</li>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/GetStartedWithS3.html">Tutoriel AWS S3 pour le stockage d’artefacts</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/GetStartedWithS3.html"><em>fr</em></a>]</li>
</ul>
<hr />
<h3 id="questions-de-révision-5"><a class="header" href="#questions-de-révision-5">Questions de Révision</a></h3>
<details>
<summary><h3 style="display:inline-block">Questions de Révision</h3></summary>
<details>
<summary>Comment Jenkins utilise-t-il les rôles IAM pour interagir avec AWS ?</summary>
<details>
<summary>Solution</summary>
Les rôles IAM, associés aux instances EC2, fournissent les permissions nécessaires pour accéder aux services AWS sans utiliser de clés d’accès dans Jenkins.
</details>
</details>
<details>
<summary>Pourquoi utiliser SSH pour configurer un agent Jenkins sur EC2 ?</summary>
<details>
<summary>Solution</summary>
SSH permet une connexion sécurisée entre Jenkins et l'instance EC2, facilitant la gestion des agents sans stockage de mots de passe dans Jenkins.
</details>
</details>
<details>
<summary>Quels types d'artefacts pouvez-vous stocker dans S3 depuis Jenkins ?</summary>
<details>
<summary>Solution</summary>
Les artefacts incluent les logs de build, les résultats des tests, les fichiers de configuration, et les packages de déploiement (ex. : `.zip`, `.jar`).
</details>
</details>
</details>
<hr />
<h3 id="conseils-pratiques-1"><a class="header" href="#conseils-pratiques-1">Conseils Pratiques</a></h3>
<ol>
<li><strong>Vérifiez les permissions du rôle IAM</strong> : Assurez-vous que le rôle IAM dispose des permissions minimales nécessaires pour accéder aux services EC2 et S3.</li>
<li><strong>Utilisez des clés SSH dédiées pour chaque agent</strong> : Pour une meilleure sécurité, utilisez une clé SSH spécifique à chaque agent EC2.</li>
<li><strong>Automatisez les étapes de nettoyage</strong> : Configurez une tâche pour arrêter ou supprimer les instances EC2 une fois les tests ou déploiements terminés, réduisant ainsi les coûts.
<a href="https://aws.amazon.com/blogs/devops/">Guide d’automatisation AWS pour Jenkins</a></li>
</ol>
<hr />
<h3 id="défi-intermédiaire-1"><a class="header" href="#défi-intermédiaire-1">Défi Intermédiaire</a></h3>
<details>
<summary><h3 style="display:inline-block">Défi Intermédiaire</h3></summary>
**Objectif** : Configurer un pipeline Jenkins avancé qui utilise EC2 comme agent, exécute un déploiement, et envoie les artefacts vers S3.
<p><strong>Contexte</strong> : Vous devez automatiser le déploiement d'une application sur une instance EC2 et stocker les logs de déploiement dans S3 pour archivage.</p>
<details>
<summary><b>Étapes principales</b></summary>
1. Créez un pipeline pour lancer une instance EC2 et configurer cette instance comme agent Jenkins avec SSH.
2. Déployez une application en utilisant une commande de build.
3. Configurez le pipeline pour copier les logs dans un bucket S3.
</details>
<p><strong>Compétences renforcées</strong> :</p>
<ul>
<li>Utilisation d'EC2 et S3 dans Jenkins</li>
<li>Configuration d'agents Jenkins dynamiques</li>
</ul>
<details>
<summary><b>Solution suggérée</b></summary>
Configurez le pipeline pour appeler AWS CLI avec le rôle IAM. Utilisez `aws s3 cp` pour transférer les artefacts et logs dans S3 après le déploiement.
</details>
</details>
<div style="break-before: page; page-break-before: always;"></div><h2 id="partie-7--cas-pratique-final---mise-en-place-dun-pipeline-cicd-avec-aws-et-jenkins"><a class="header" href="#partie-7--cas-pratique-final---mise-en-place-dun-pipeline-cicd-avec-aws-et-jenkins">Partie 7 : Cas Pratique Final - Mise en Place d'un Pipeline CI/CD avec AWS et Jenkins</a></h2>
<h3 id="objectifs-6"><a class="header" href="#objectifs-6">Objectifs</a></h3>
<p>Dans cette partie, vous allez :</p>
<ul>
<li><strong>Appliquer tous les concepts appris</strong> pour configurer un pipeline CI/CD complet avec Jenkins et AWS.</li>
<li><strong>Automatiser le déploiement</strong> d’une application web sur EC2 et la gestion des artefacts avec S3.</li>
</ul>
<hr />
<h3 id="71-mise-en-place-du-dépôt-et-du-jenkinsfile"><a class="header" href="#71-mise-en-place-du-dépôt-et-du-jenkinsfile">7.1 Mise en place du dépôt et du Jenkinsfile</a></h3>
<h4 id="préparation-dun-dépôt-git-avec-un-jenkinsfile"><a class="header" href="#préparation-dun-dépôt-git-avec-un-jenkinsfile">Préparation d’un dépôt Git avec un Jenkinsfile</a></h4>
<p>Pour ce projet, créez un dépôt Git qui contiendra le code de votre application ainsi qu’un Jenkinsfile configuré pour le pipeline CI/CD.</p>
<ol>
<li>
<p><strong>Créer le dépôt Git</strong> :</p>
<ul>
<li>Créez un dépôt Git (ex. : sur GitHub ou GitLab) pour le projet, et ajoutez-y le code source de votre application.</li>
</ul>
</li>
<li>
<p><strong>Écrire un Jenkinsfile</strong> :</p>
<ul>
<li>Le Jenkinsfile contiendra les étapes de build, de test, et de déploiement de votre application.</li>
<li>Structurez-le avec des stages pour chaque étape clé.</li>
</ul>
</li>
</ol>
<p><strong>Exemple de structure de Jenkinsfile</strong> :</p>
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                echo 'Building the application...'
                // Ajoutez ici les commandes de build, ex. : sh 'npm install' ou 'mvn clean package'
            }
        }
        stage('Test') {
            steps {
                echo 'Running tests...'
                // Ajoutez ici les commandes pour les tests, ex. : sh 'npm test' ou 'mvn test'
            }
        }
        stage('Deploy') {
            steps {
                echo 'Deploying to EC2...'
                // Appel des scripts ou playbooks Ansible pour le déploiement sur EC2
            }
        }
    }
}
</code></pre>
<hr />
<h3 id="72-déploiement-dune-application-sur-ec2"><a class="header" href="#72-déploiement-dune-application-sur-ec2">7.2 Déploiement d’une application sur EC2</a></h3>
<h4 id="automatiser-la-création-et-la-configuration-de-linfrastructure-avec-ec2-et-ansible"><a class="header" href="#automatiser-la-création-et-la-configuration-de-linfrastructure-avec-ec2-et-ansible">Automatiser la création et la configuration de l’infrastructure avec EC2 et Ansible</a></h4>
<p>Pour cette partie, nous utiliserons Jenkins pour créer des instances EC2 et Ansible pour configurer l’infrastructure et déployer l’application.</p>
<ol>
<li>
<p><strong>Automatiser le lancement d’une instance EC2</strong> :</p>
<ul>
<li>Utilisez AWS CLI dans Jenkins pour lancer une instance EC2, ou configurez un agent EC2 dédié au déploiement.</li>
</ul>
</li>
<li>
<p><strong>Configurer l’instance avec Ansible</strong> :</p>
<ul>
<li>Après le lancement, utilisez Ansible pour installer les dépendances et déployer l’application.</li>
<li>Exemple de tâches Ansible : installation de serveurs web, configuration de l’application, démarrage des services.</li>
</ul>
</li>
</ol>
<p><strong>Exemple de playbook Ansible pour configurer l’instance</strong> :</p>
<pre><code class="language-yaml">- name: Configurer et déployer l'application sur EC2
  hosts: webserver
  tasks:
    - name: Installer Nginx
      yum:
        name: nginx
        state: present
    - name: Copier les fichiers de l'application
      copy:
        src: /path/to/app/
        dest: /var/www/html/
    - name: Démarrer Nginx
      service:
        name: nginx
        state: started
</code></pre>
<h4 id="déploiement-automatisé-de-lapplication-sur-ec2"><a class="header" href="#déploiement-automatisé-de-lapplication-sur-ec2">Déploiement automatisé de l’application sur EC2</a></h4>
<p>Le déploiement peut être automatisé en appelant le playbook Ansible dans le Jenkinsfile.</p>
<p><strong>Exemple d’appel d’Ansible dans un Jenkinsfile</strong> :</p>
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Deploy') {
            steps {
                echo 'Deploying the application using Ansible...'
                sh 'ansible-playbook -i inventory.ini deploy-app.yml'
            }
        }
    }
}
</code></pre>
<p>Dans cet exemple :</p>
<ul>
<li><strong>inventory.ini</strong> : Contient l’adresse IP de l’instance EC2 (par exemple, obtenue dynamiquement).</li>
<li><strong>deploy-app.yml</strong> : Le playbook Ansible pour déployer l’application.</li>
</ul>
<hr />
<h3 id="73-gestion-des-artefacts-et-journalisation"><a class="header" href="#73-gestion-des-artefacts-et-journalisation">7.3 Gestion des artefacts et journalisation</a></h3>
<h4 id="sauvegarde-des-artefacts-de-build-dans-s3"><a class="header" href="#sauvegarde-des-artefacts-de-build-dans-s3">Sauvegarde des artefacts de build dans S3</a></h4>
<p>Les artefacts générés (par exemple, les fichiers de build, les logs) peuvent être stockés dans un bucket S3 pour archivage et accès futur.</p>
<ol>
<li>
<p><strong>Configurer un bucket S3 pour les artefacts Jenkins</strong> :</p>
<ul>
<li>Créez un bucket S3 dédié pour stocker les artefacts générés par Jenkins.</li>
<li>Assurez-vous que le rôle IAM associé à l'instance Jenkins a les permissions nécessaires pour écrire dans le bucket.</li>
</ul>
</li>
<li>
<p><strong>Script pour transférer les artefacts vers S3</strong> :</p>
<ul>
<li>Dans le Jenkinsfile, utilisez <code>aws s3 cp</code> pour transférer les artefacts de build vers le bucket S3.</li>
</ul>
</li>
</ol>
<p><strong>Exemple de Jenkinsfile pour sauvegarder les artefacts dans S3</strong> :</p>
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                echo 'Building the application...'
                // Exécuter les commandes de build
            }
        }
        stage('Upload Artifacts to S3') {
            steps {
                echo 'Uploading artifacts to S3...'
                sh 'aws s3 cp build/output.zip s3://my-jenkins-artifacts/builds/output.zip'
            }
        }
    }
}
</code></pre>
<hr />
<h3 id="projet-final--créer-un-pipeline-cicd-complet-avec-jenkins-aws-ec2-et-s3"><a class="header" href="#projet-final--créer-un-pipeline-cicd-complet-avec-jenkins-aws-ec2-et-s3">Projet final : Créer un pipeline CI/CD complet avec Jenkins, AWS EC2 et S3</a></h3>
<p><strong>Objectif du projet</strong> : Configurer un pipeline complet pour automatiser le déploiement d'une application web, incluant les étapes de build, de test, et de déploiement sur une instance EC2, ainsi que la gestion des artefacts avec S3.</p>
<p><strong>Étapes du projet</strong> :</p>
<ol>
<li><strong>Préparer le dépôt et le Jenkinsfile</strong> : Créez un Jenkinsfile avec les étapes de build, de test, et de déploiement.</li>
<li><strong>Lancer et configurer une instance EC2</strong> :
<ul>
<li>Utilisez AWS CLI dans Jenkins pour lancer une instance EC2.</li>
<li>Configurez cette instance avec Ansible en installant les dépendances et déployant l’application.</li>
</ul>
</li>
<li><strong>Transférer les artefacts vers S3</strong> : Utilisez le Jenkinsfile pour sauvegarder les artefacts de build dans un bucket S3.</li>
<li><strong>(Optionnel) Configurer CloudWatch pour la surveillance</strong> : Configurez CloudWatch pour surveiller l’utilisation des ressources et recevoir des alertes en cas d’anomalie.</li>
</ol>
<hr />
<h3 id="liens-vers-la-documentation-2"><a class="header" href="#liens-vers-la-documentation-2">Liens vers la documentation</a></h3>
<ul>
<li><a href="https://docs.aws.amazon.com/cloudwatch/">Documentation AWS pour CloudWatch</a> [<a href="https://docs.aws.amazon.com/fr_fr/cloudwatch/"><em>fr</em></a>]</li>
<li><a href="https://docs.ansible.com/ansible/latest/scenario_guides/guide_aws.html">Guide d’utilisation d’Ansible avec AWS</a></li>
<li><a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-services-s3-commands.html">Documentation AWS CLI pour le stockage S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/cli/latest/userguide/cli-services-s3-commands.html"><em>fr</em></a>]</li>
</ul>
<hr />
<h3 id="questions-de-révision-6"><a class="header" href="#questions-de-révision-6">Questions de Révision</a></h3>
<details>
<summary><h3 style="display:inline-block">Questions de Révision</h3></summary>
<details>
<summary>Pourquoi utiliser Ansible pour configurer une instance EC2 dans un pipeline CI/CD ?</summary>
<details>
<summary>Solution</summary>
Ansible permet d’automatiser la configuration de l’instance EC2 en installant les dépendances et en déployant l’application, ce qui simplifie et accélère le processus de déploiement.
</details>
</details>
<details>
<
<p>summary&gt;Comment Jenkins peut-il sauvegarder des artefacts dans S3 ?</summary></p>
<details>
<summary>Solution</summary>
Jenkins peut utiliser AWS CLI et le rôle IAM associé à son instance pour exécuter des commandes `aws s3 cp` afin de transférer les artefacts dans un bucket S3.
</details>
</details>
<details>
<summary>Quels sont les avantages de configurer CloudWatch pour une application déployée ?</summary>
<details>
<summary>Solution</summary>
CloudWatch permet de surveiller l’utilisation des ressources (comme le CPU et la mémoire), de collecter des logs et de configurer des alertes en cas d’anomalies, améliorant ainsi la fiabilité de l’application.
</details>
</details>
</details>
<hr />
<h3 id="conseils-pratiques-2"><a class="header" href="#conseils-pratiques-2">Conseils Pratiques</a></h3>
<ol>
<li><strong>Utilisez les rôles IAM pour la sécurité</strong> : Associez un rôle IAM à l’instance Jenkins pour gérer les permissions AWS de manière sécurisée, sans avoir à stocker des clés d’accès.</li>
<li><strong>Automatisez les sauvegardes d’artefacts</strong> : Configurez Jenkins pour sauvegarder automatiquement les artefacts critiques (logs, fichiers de build) dans S3 après chaque exécution du pipeline.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><p><strong>Présentation Générale d'Ansible</strong></p>
<hr />
<h3 id="introduction-2"><a class="header" href="#introduction-2">Introduction</a></h3>
<p><strong>Ansible</strong> est un outil open-source d’automatisation IT permettant de gérer la configuration, le déploiement, et l’orchestration des applications et des infrastructures. Développé par Red Hat, Ansible est largement utilisé par les équipes DevOps et les administrateurs système pour sa simplicité, sa flexibilité, et son modèle d'exécution sans agent. Grâce à Ansible, les tâches complexes et répétitives peuvent être automatisées, rendant les processus plus rapides, standardisés et sans erreurs.</p>
<hr />
<h3 id="principales-fonctionnalités-dansible"><a class="header" href="#principales-fonctionnalités-dansible">Principales Fonctionnalités d'Ansible</a></h3>
<ol>
<li>
<p><strong>Gestion de la Configuration</strong> : Ansible permet de définir des configurations pour les serveurs et applications, garantissant que chaque déploiement est cohérent.</p>
</li>
<li>
<p><strong>Automatisation des Tâches Répétitives</strong> : Ansible simplifie des tâches telles que l'installation de logiciels, la configuration des réseaux, et le déploiement d'applications en les automatisant.</p>
</li>
<li>
<p><strong>Déploiement d'Applications</strong> : Les playbooks Ansible peuvent être utilisés pour déployer des applications sur des serveurs et orchestrer des processus complexes de CI/CD.</p>
</li>
<li>
<p><strong>Orchestration Multinœuds</strong> : Ansible peut coordonner des actions sur plusieurs serveurs simultanément, pratique pour des infrastructures importantes nécessitant des mises à jour synchronisées ou des déploiements en parallèle.</p>
</li>
<li>
<p><strong>Infrastructure-as-Code (IaC)</strong> : Avec Ansible, les configurations d'infrastructure sont définies sous forme de code, ce qui permet un contrôle de version, une documentation claire et la réutilisation des configurations.</p>
</li>
</ol>
<hr />
<h3 id="fonctionnement-et-architecture-dansible"><a class="header" href="#fonctionnement-et-architecture-dansible">Fonctionnement et Architecture d'Ansible</a></h3>
<p>Ansible utilise un modèle "push" sans agent : les instructions de configuration sont "poussées" depuis le serveur de gestion vers les hôtes cibles, sans qu'aucun agent ne soit requis sur les machines distantes.</p>
<ol>
<li><strong>Serveur de Gestion (Control Node)</strong> : Le serveur à partir duquel les administrateurs exécutent les commandes et les playbooks Ansible pour configurer et gérer les hôtes.</li>
<li><strong>Hôtes (Managed Nodes)</strong> : Les machines sur lesquelles Ansible effectue des actions. L’accès se fait principalement via SSH, sans installation de logiciel spécifique sur les hôtes.</li>
<li><strong>Inventaire</strong> : Fichier qui liste les hôtes et groupes d'hôtes que l’on souhaite gérer avec Ansible. Les hôtes peuvent être classés en groupes pour appliquer des configurations spécifiques.</li>
<li><strong>Modules</strong> : Des modules sont les unités d’action d’Ansible ; chaque module exécute une tâche (par exemple, installation de logiciels, gestion de services, copie de fichiers).</li>
<li><strong>Playbooks</strong> : Les playbooks sont des fichiers YAML décrivant les séquences de tâches. Ils spécifient les actions à effectuer sur les hôtes, avec une syntaxe lisible et facilement maintenable.</li>
</ol>
<hr />
<h3 id="les-playbooks-ansible"><a class="header" href="#les-playbooks-ansible">Les Playbooks Ansible</a></h3>
<p>Les <strong>playbooks</strong> sont le cœur de la configuration dans Ansible. Ils décrivent des processus d’automatisation sous forme de code, rendant chaque étape de configuration répétable et prévisible.</p>
<ul>
<li><strong>Syntaxe YAML</strong> : Les playbooks utilisent YAML, un format lisible et intuitif.</li>
<li><strong>Blocs de tâches</strong> : Un playbook est structuré en <strong>tâches</strong> successives (steps) appliquées aux hôtes spécifiés.</li>
<li><strong>Variables et Rôles</strong> : Ansible permet d'utiliser des variables pour rendre les playbooks flexibles et des rôles pour organiser les tâches de manière modulaire.</li>
</ul>
<p><strong>Exemple de playbook pour installer un serveur web</strong> :</p>
<pre><code class="language-yaml">- name: Installer et configurer un serveur web
  hosts: webservers
  tasks:
    - name: Installer Apache
      apt:
        name: apache2
        state: present
    - name: Démarrer le service Apache
      service:
        name: apache2
        state: started
</code></pre>
<hr />
<h3 id="principaux-avantages-dansible"><a class="header" href="#principaux-avantages-dansible">Principaux Avantages d'Ansible</a></h3>
<ol>
<li><strong>Simplicité et Facilité d'Utilisation</strong> : Ansible est conçu pour être intuitif et facile à apprendre, grâce à sa syntaxe en YAML et son modèle sans agent.</li>
<li><strong>Sans Agent</strong> : Contrairement à de nombreux outils de gestion de configuration, Ansible ne nécessite pas d’agent installé sur les hôtes, réduisant ainsi la charge administrative et les besoins en ressources.</li>
<li><strong>Flexibilité et Évolutivité</strong> : Ansible peut gérer un petit nombre de serveurs comme des centaines, et fonctionne sur des environnements hybrides (sur site, cloud, multicloud).</li>
<li><strong>Approche Declarative</strong> : Ansible utilise une approche déclarative, où l’administrateur spécifie l’état désiré plutôt que les étapes précises pour l’atteindre. Cela rend les configurations plus robustes et moins sujettes aux erreurs.</li>
<li><strong>Écosystème de Modules</strong> : Ansible possède une bibliothèque de modules étendue pour interagir avec divers systèmes (bases de données, réseaux, clouds, conteneurs), ce qui permet de gérer pratiquement tous les aspects d'une infrastructure.</li>
</ol>
<hr />
<h3 id="cas-dusage-courants-2"><a class="header" href="#cas-dusage-courants-2">Cas d'Usage Courants</a></h3>
<ol>
<li><strong>Provisionnement de Serveurs</strong> : Ansible configure automatiquement les serveurs en fonction des besoins (installation des logiciels, configuration réseau, sécurité).</li>
<li><strong>Déploiement d'Applications</strong> : Grâce aux playbooks, Ansible permet de déployer des applications sur plusieurs serveurs de manière uniforme.</li>
<li><strong>Automatisation DevOps et CI/CD</strong> : Intégré dans des pipelines CI/CD, Ansible automatise les déploiements et assure la cohérence entre les environnements de test, préproduction et production.</li>
<li><strong>Gestion Multi-Cloud</strong> : Ansible supporte des environnements hybrides et peut être utilisé pour provisionner des ressources dans des clouds tels qu’AWS, Azure, Google Cloud, et des environnements sur site.</li>
<li><strong>Maintenance et Mise à Jour des Serveurs</strong> : En gérant l’installation de mises à jour, Ansible assure la sécurité et le bon fonctionnement des serveurs sur une base régulière.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="partie-1--introduction-à-ansible-et-aux-playbooks"><a class="header" href="#partie-1--introduction-à-ansible-et-aux-playbooks">Partie 1 : Introduction à Ansible et aux Playbooks</a></h2>
<h3 id="objectifs-7"><a class="header" href="#objectifs-7">Objectifs</a></h3>
<p>Dans cette première partie, vous découvrirez :</p>
<ul>
<li>Les principes fondamentaux d’Ansible et ses avantages pour l’automatisation.</li>
<li>Comment installer et configurer Ansible pour un usage de base.</li>
<li>La structure de base d’un playbook Ansible et ses éléments essentiels.</li>
</ul>
<hr />
<h3 id="11-présentation-dansible-et-de-ses-concepts-fondamentaux"><a class="header" href="#11-présentation-dansible-et-de-ses-concepts-fondamentaux">1.1 Présentation d'Ansible et de ses Concepts Fondamentaux</a></h3>
<p>Ansible est un outil d’automatisation open-source conçu pour simplifier la gestion des infrastructures, avec des fonctionnalités d’<strong>infrastructure-as-code</strong> (IaC) pour décrire l’infrastructure sous forme de code.</p>
<h4 id="concepts-clés-"><a class="header" href="#concepts-clés-">Concepts clés :</a></h4>
<ul>
<li><strong>Agentless</strong> : Ansible ne nécessite pas d’agent installé sur les machines distantes, ce qui réduit la complexité de gestion.</li>
<li><strong>Infrastructure-as-Code</strong> : Permet de décrire l’infrastructure dans des fichiers de configuration (playbooks).</li>
<li><strong>Exécution en parallèle</strong> : Capacité d'exécuter des tâches simultanément sur plusieurs machines.</li>
</ul>
<p><img src="ansible/sections/../images/01_Introduction/architecture.jpg" alt="Présentation d&#39;Ansible" /></p>
<p><strong>Utilisation d’Ansible pour AWS</strong><br />
Ansible est souvent utilisé pour gérer des environnements cloud, comme AWS, permettant de configurer des ressources (instances EC2, buckets S3, etc.) et de les gérer à grande échelle. Cette approche aide les équipes à standardiser et automatiser leur infrastructure.</p>
<hr />
<h3 id="12-installation-et-configuration-de-base"><a class="header" href="#12-installation-et-configuration-de-base">1.2 Installation et Configuration de Base</a></h3>
<h4 id="installation-dansible"><a class="header" href="#installation-dansible">Installation d'Ansible</a></h4>
<p>Ansible s’installe facilement et est compatible avec de nombreux systèmes d’exploitation :</p>
<ol>
<li><strong>Linux/Mac</strong> : Utilisation de <code>apt</code>, <code>yum</code>, ou <code>brew</code>.</li>
<li><strong>Windows</strong> : Utilisation de Windows Subsystem for Linux (WSL) pour installer Ansible dans un environnement Linux.</li>
</ol>
<p><img src="ansible/sections/../images/01_Introduction/ansible_installation.png" alt="Installation d&#39;Ansible" /></p>
<blockquote>
<p>Source: https://www.frostbyte.us/ansible-integrated-development-environment-setup-on-windows/</p>
</blockquote>
<h4 id="structure-dun-projet-ansible"><a class="header" href="#structure-dun-projet-ansible">Structure d’un projet Ansible</a></h4>
<p>Un projet Ansible typique comporte trois éléments principaux :</p>
<ul>
<li><strong><code>ansible.cfg</code></strong> : Fichier de configuration qui définit les paramètres globaux d’Ansible.</li>
<li><strong><code>inventory</code></strong> : Fichier qui liste les hôtes à gérer (sous forme d’adresses IP ou de noms de domaine).</li>
<li><strong>Playbook</strong> : Fichier YAML contenant des tâches automatisées pour gérer ou configurer les hôtes.</li>
</ul>
<p><strong>Exercice</strong> : Installer Ansible et configurer un inventaire simple avec une machine de test.</p>
<ol>
<li>Installez Ansible en suivant les instructions pour votre système d’exploitation.</li>
<li>Créez un fichier <code>inventory</code> en y ajoutant l'adresse IP ou le nom de domaine d'une machine de test.</li>
<li>Configurez <code>ansible.cfg</code> pour spécifier le fichier d’inventaire par défaut et tester la connexion.</li>
</ol>
<hr />
<h3 id="13-structure-de-base-dun-playbook"><a class="header" href="#13-structure-de-base-dun-playbook">1.3 Structure de Base d'un Playbook</a></h3>
<p>Un <strong>playbook</strong> est un fichier YAML qui définit une série de tâches à exécuter sur des hôtes spécifiés. La structure de base d’un playbook inclut :</p>
<ul>
<li><strong>hosts</strong> : Les machines sur lesquelles les tâches seront exécutées.</li>
<li><strong>tasks</strong> : Une liste de tâches à exécuter.</li>
<li><strong>vars</strong> : Variables qui définissent des valeurs réutilisables dans le playbook.</li>
</ul>
<pre><code class="language-yaml">- name: Playbook de base
  hosts: all
  vars:
    user: ubuntu
  tasks:
    - name: Vérifier la connexion avec les hôtes
      ping:
    - name: Récupérer les informations système
      setup:
</code></pre>
<p><img src="ansible/sections/../images/01_Introduction/example_structure.png" alt="Structure de base d&#39;un playbook" /></p>
<blockquote>
<p>Source: https://www.middlewareinventory.com/blog/ansible-playbook-example/</p>
</blockquote>
<h4 id="explication-des-blocs"><a class="header" href="#explication-des-blocs">Explication des blocs</a></h4>
<ul>
<li><strong><code>hosts</code></strong> : Détermine les hôtes ciblés (par exemple, <code>all</code> pour toutes les machines de l'inventaire).</li>
<li><strong><code>vars</code></strong> : Les variables permettent de personnaliser et de réutiliser des valeurs.</li>
<li><strong><code>tasks</code></strong> : Chaque tâche utilise un module (par exemple, <code>ping</code>, <code>setup</code>) pour exécuter une action spécifique.</li>
</ul>
<p><strong>Exercice</strong> : Créer un playbook simple pour effectuer des vérifications basiques</p>
<ol>
<li><strong>Objectif</strong> : Créer un playbook pour tester la connexion avec les hôtes et récupérer des informations système.</li>
<li><strong>Étapes</strong> :
<ul>
<li>Créez un fichier <code>simple-playbook.yml</code>.</li>
<li>Ajoutez un bloc <code>hosts</code> pour spécifier les machines cibles et un bloc <code>tasks</code> avec les modules <code>ping</code> et <code>setup</code>.</li>
<li>Exécutez le playbook avec la commande :
<pre><code class="language-bash">ansible-playbook -i inventory simple-playbook.yml
</code></pre>
</li>
<li>Vérifiez que le playbook s'exécute correctement et renvoie les résultats des tests.</li>
</ul>
</li>
</ol>
<hr />
<h3 id="liens-vers-la-documentation-3"><a class="header" href="#liens-vers-la-documentation-3">Liens vers la Documentation</a></h3>
<ul>
<li><a href="https://docs.ansible.com/ansible/latest/index.html">Documentation officielle d'Ansible</a> [<a href="https://docs.ansible.com/ansible/latest/index.html"><em>fr</em></a>]</li>
<li><a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html">Installation d'Ansible</a> [<a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html"><em>fr</em></a>]</li>
<li><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks.html">Guide d'écriture de playbooks</a> [<a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks.html"><em>fr</em></a>]</li>
</ul>
<hr />
<h3 id="questions-de-révision-7"><a class="header" href="#questions-de-révision-7">Questions de Révision</a></h3>
<details>
<summary><h3 style="display:inline-block">Questions de Révision</h3></summary>
<details>
<summary>Qu'est-ce qu'un inventaire dans Ansible ?</summary>
<details>
<summary>Solution</summary>
Un inventaire est un fichier qui liste les hôtes à gérer, en indiquant leurs adresses IP ou noms de domaine, et parfois des informations supplémentaires (comme les groupes).
</details>
</details>
<details>
<summary>Quels sont les trois blocs principaux d’un playbook Ansible ?</summary>
<details>
<summary>Solution</summary>
Les trois blocs principaux sont `hosts` (pour les hôtes cibles), `tasks` (pour les tâches à exécuter), et `vars` (pour les variables).
</details>
</details>
<details>
<summary>À quoi sert le fichier `ansible.cfg` dans un projet Ansible ?</summary>
<details>
<summary>Solution</summary>
Le fichier `ansible.cfg` permet de configurer les paramètres globaux d'Ansible, comme le fichier d'inventaire par défaut, le comportement de connexion, et d'autres options.
</details>
</details>
</details>
<hr />
<h3 id="conseils-pratiques-3"><a class="header" href="#conseils-pratiques-3">Conseils Pratiques</a></h3>
<ol>
<li><strong>Nommer vos tâches de manière explicite</strong> pour mieux comprendre le déroulement des exécutions dans les logs.</li>
<li><strong>Utiliser les variables</strong> pour éviter la répétition de valeurs spécifiques dans les playbooks.</li>
<li><strong>Tester la connexion aux hôtes</strong> avec une commande Ansible simple (comme <code>ping</code>) avant d'exécuter des playbooks complexes.
<a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks.html">Plus de détails sur les playbooks</a></li>
</ol>
<hr />
<h3 id="défi-intermédiaire-2"><a class="header" href="#défi-intermédiaire-2">Défi Intermédiaire</a></h3>
<details>
<summary><h3 style="display:inline-block">Défi Intermédiaire</h3></summary>
**Objectif** : Configurer un playbook pour automatiser les vérifications de connectivité et d’information système sur plusieurs hôtes.
<p><strong>Contexte</strong> : Vous devez vérifier la connectivité et collecter des informations système sur plusieurs serveurs dans un inventaire.</p>
<details>
<summary><b>Étapes principales</b></summary>
<ol>
<li> Créez un fichier `multi-check.yml` avec `hosts` ciblant plusieurs hôtes de l’inventaire.</li>
<li>Ajoutez des tâches pour exécuter des vérifications `ping` et collecter les informations système (`setup`).</li>
<li>Exécutez le playbook et vérifiez les résultats sur chaque hôte.</li>
</ol>
</details>
<p><strong>Compétences renforcées</strong> :</p>
<ul>
<li>Création de playbooks simples</li>
<li>Exécution de commandes de vérification sur plusieurs hôtes</li>
</ul>
<details>
<summary><b>Solution suggérée</b></summary>
Utilisez le playbook suivant :
<pre><code class="language-yaml">- name: Vérifications sur plusieurs hôtes
  hosts: all
  tasks:
    - name: Vérifier la connexion
      ping:
    - name: Collecter les informations système
      setup:
</code></pre>
<p>Exécutez-le avec :</p>
<pre><code class="language-bash">ansible-playbook -i inventory multi-check.yml
</code></pre>
</details>
</details>
<div style="break-before: page; page-break-before: always;"></div><h2 id="partie-2--Écriture-et-exécution-de-playbooks-ansible"><a class="header" href="#partie-2--Écriture-et-exécution-de-playbooks-ansible">Partie 2 : Écriture et Exécution de Playbooks Ansible</a></h2>
<h3 id="objectifs-8"><a class="header" href="#objectifs-8">Objectifs</a></h3>
<p>Dans cette partie, vous allez :</p>
<ul>
<li>Découvrir les modules Ansible essentiels pour l’automatisation des tâches courantes.</li>
<li>Apprendre à utiliser les variables et les boucles pour gérer les tâches répétitives.</li>
<li>Comprendre la gestion des conditions pour créer des playbooks dynamiques et adaptatifs.</li>
</ul>
<hr />
<h3 id="21-les-modules-essentiels-dansible"><a class="header" href="#21-les-modules-essentiels-dansible">2.1 Les Modules Essentiels d'Ansible</a></h3>
<p>Ansible fournit de nombreux modules pour gérer diverses tâches de configuration. Voici quelques modules essentiels :</p>
<ul>
<li><strong>ping</strong> : Teste la connexion entre Ansible et l’hôte cible.</li>
<li><strong>command</strong> et <strong>shell</strong> : Exécutent des commandes sur les hôtes. <strong>command</strong> est sécurisé par défaut, tandis que <strong>shell</strong> est utilisé pour des commandes nécessitant une interprétation par le shell.</li>
<li><strong>file</strong> : Permet de créer, supprimer ou configurer les propriétés d’un fichier ou d’un dossier.</li>
<li><strong>package</strong> : Installe, met à jour ou supprime des packages.</li>
<li><strong>service</strong> : Gère les services sur les hôtes (démarrage, arrêt, redémarrage).</li>
</ul>
<blockquote>
<p>Une explication des principaux <a href="https://dev.to/faruq2991/my-ansible-learning-journey-exploring-essential-modules-2e6c">modules</a> ansible.</p>
</blockquote>
<h4 id="exercice--créer-un-playbook-pour-installer-et-démarrer-un-service-web"><a class="header" href="#exercice--créer-un-playbook-pour-installer-et-démarrer-un-service-web">Exercice : Créer un playbook pour installer et démarrer un service web</a></h4>
<p><strong>Objectif</strong> : Créer un playbook pour installer un serveur web (par exemple, Apache) et démarrer le service.</p>
<p><strong>Étapes</strong> :</p>
<ol>
<li>Créez un fichier <code>install_web.yml</code>.</li>
<li>Utilisez le module <code>package</code> pour installer Apache.</li>
<li>Utilisez le module <code>service</code> pour démarrer Apache et s’assurer qu’il s’exécute au démarrage.</li>
</ol>
<p><strong>Exemple de playbook</strong> :</p>
<pre><code class="language-yaml">- name: Installer et démarrer un serveur web
  hosts: all
  tasks:
    - name: Installer Apache
      package:
        name: apache2
        state: present
    - name: Démarrer Apache
      service:
        name: apache2
        state: started
        enabled: true
</code></pre>
<hr />
<h3 id="22-variables-et-boucles-dans-les-playbooks"><a class="header" href="#22-variables-et-boucles-dans-les-playbooks">2.2 Variables et Boucles dans les Playbooks</a></h3>
<p>Les variables et les boucles permettent de créer des playbooks plus flexibles et réutilisables.</p>
<h4 id="définition-et-utilisation-des-variables"><a class="header" href="#définition-et-utilisation-des-variables">Définition et Utilisation des Variables</a></h4>
<p>Les variables dans Ansible permettent de stocker des valeurs dynamiques, par exemple le nom d’un package ou le chemin d’un fichier.</p>
<p><strong>Exemple d’utilisation de variables</strong> :</p>
<pre><code class="language-yaml">- name: Playbook avec variables
  hosts: all
  vars:
    package_name: apache2
  tasks:
    - name: Installer le package
      package:
        name: "{{ package_name }}"
        state: present
</code></pre>
<h4 id="boucles-loop-dans-les-playbooks"><a class="header" href="#boucles-loop-dans-les-playbooks">Boucles (loop) dans les Playbooks</a></h4>
<p>Le paramètre <code>loop</code> est utilisé pour exécuter une tâche sur plusieurs éléments, comme l’installation de plusieurs packages ou la création de plusieurs fichiers.</p>
<p><strong>Exemple d’utilisation de loop</strong> :</p>
<pre><code class="language-yaml">- name: Installer plusieurs packages
  hosts: all
  tasks:
    - name: Installer des packages
      package:
        name: "{{ item }}"
        state: present
      loop:
        - apache2
        - curl
        - git
</code></pre>
<p><img src="ansible/sections/../images/02_Basics/variables.png" alt="Utilisation des variables et des boucles dans Ansible" /></p>
<blockquote>
<p>Source: https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_variables.html#creating-valid-variable-names</p>
</blockquote>
<h4 id="exercice--Écrire-un-playbook-pour-installer-plusieurs-packages"><a class="header" href="#exercice--Écrire-un-playbook-pour-installer-plusieurs-packages">Exercice : Écrire un playbook pour installer plusieurs packages</a></h4>
<p><strong>Objectif</strong> : Créer un playbook pour installer plusieurs packages (par exemple, Apache, Git, et Curl) en utilisant des variables et des boucles.</p>
<p><strong>Étapes</strong> :</p>
<ol>
<li>Créez un fichier <code>install_packages.yml</code>.</li>
<li>Définissez une variable contenant la liste des packages à installer.</li>
<li>Utilisez <code>loop</code> pour installer chaque package.</li>
</ol>
<p><strong>Exemple de playbook</strong> :</p>
<pre><code class="language-yaml">- name: Installer plusieurs packages
  hosts: all
  vars:
    packages:
      - apache2
      - git
      - curl
  tasks:
    - name: Installer les packages
      package:
        name: "{{ item }}"
        state: present
      loop: "{{ packages }}"
</code></pre>
<hr />
<h3 id="23-gestion-des-conditions-et-logique"><a class="header" href="#23-gestion-des-conditions-et-logique">2.3 Gestion des Conditions et Logique</a></h3>
<p>Les conditions permettent d’exécuter des tâches uniquement lorsque certaines conditions sont remplies, en utilisant le mot-clé <code>when</code>.</p>
<h4 id="utilisation-des-conditions-avec-when"><a class="header" href="#utilisation-des-conditions-avec-when">Utilisation des Conditions avec <code>when</code></a></h4>
<p>Le mot-clé <code>when</code> permet d’exécuter une tâche sous certaines conditions. Cela peut être utile pour gérer des actions spécifiques en fonction de l'état du système ou des variables.</p>
<p><strong>Exemple d’utilisation de <code>when</code></strong> :</p>
<pre><code class="language-yaml">- name: Démarrer un service uniquement si Apache est installé
  hosts: all
  tasks:
    - name: Vérifier si Apache est installé
      shell: dpkg -l | grep apache2
      register: apache_installed
      ignore_errors: true

    - name: Démarrer Apache si installé
      service:
        name: apache2
        state: started
      when: apache_installed.rc == 0
</code></pre>
<h4 id="exercice--créer-un-playbook-pour-vérifier-et-redémarrer-un-service"><a class="header" href="#exercice--créer-un-playbook-pour-vérifier-et-redémarrer-un-service">Exercice : Créer un playbook pour vérifier et redémarrer un service</a></h4>
<p><strong>Objectif</strong> : Écrire un playbook pour vérifier l'état d'un service (par exemple, Apache) et le redémarrer s’il n’est pas actif.</p>
<p><strong>Étapes</strong> :</p>
<ol>
<li>Créez un fichier <code>check_restart_service.yml</code>.</li>
<li>Ajoutez une tâche pour vérifier l'état du service avec <code>service_facts</code>.</li>
<li>Utilisez une condition pour redémarrer le service si nécessaire.</li>
</ol>
<p><strong>Exemple de playbook</strong> :</p>
<pre><code class="language-yaml">- name: Vérifier et redémarrer un service
  hosts: all
  tasks:
    - name: Obtenir les informations sur les services
      service_facts:

    - name: Redémarrer Apache si arrêté
      service:
        name: apache2
        state: restarted
      when: ansible_facts.services["apache2"].state != "running"
</code></pre>
<p><img src="ansible/sections/../images/02_Basics/when.png" alt="Conditions et logique dans Ansible" /></p>
<blockquote>
<p>Source: https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_conditionals.html</p>
</blockquote>
<hr />
<h3 id="liens-vers-la-documentation-4"><a class="header" href="#liens-vers-la-documentation-4">Liens vers la Documentation</a></h3>
<ul>
<li><a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/index.html">Modules Ansible</a></li>
<li><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html">Documentation des boucles Ansible</a></li>
<li><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html">Conditions avec <code>when</code></a></li>
</ul>
<hr />
<h3 id="questions-de-révision-8"><a class="header" href="#questions-de-révision-8">Questions de Révision</a></h3>
<details>
<summary><h3 style="display:inline-block">Questions de Révision</h3></summary>
<details>
<summary>Quel module Ansible utiliser pour installer un package ?</summary>
<details>
<summary>Solution</summary>
Le module `package` est utilisé pour installer, mettre à jour ou supprimer des packages sur les hôtes cibles.
</details>
</details>
<details>
<summary>Comment exécuter une tâche de manière répétitive avec Ansible ?</summary>
<details>
<summary>Solution</summary>
En utilisant le paramètre `loop` dans le bloc de tâche, ce qui permet de répéter la tâche pour chaque élément de la liste fournie.
</details>
</details>
<details>
<summary>Qu’est-ce que `when` dans un playbook Ansible ?</summary>
<details>
<summary>Solution</summary>
Le mot-clé `when` permet d’exécuter une tâche uniquement si une certaine condition est remplie.
</details>
</details>
</details>
<hr />
<h3 id="conseils-pratiques-4"><a class="header" href="#conseils-pratiques-4">Conseils Pratiques</a></h3>
<ol>
<li><strong>Utilisez <code>loop</code> pour réduire la redondance</strong> et rendre vos playbooks plus concis.</li>
<li><strong>Définissez des variables pour les valeurs réutilisables</strong> comme les noms de packages et chemins de fichiers.</li>
<li><strong>Testez les conditions</strong> avant d’exécuter des tâches critiques pour éviter les erreurs.
<a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html">Guide des conditions dans Ansible</a></li>
</ol>
<hr />
<h3 id="défi-intermédiaire-3"><a class="header" href="#défi-intermédiaire-3">Défi Intermédiaire</a></h3>
<details>
<summary><h3 style="display:inline-block">Défi Intermédiaire</h3></summary>
**Objectif** : Créer un playbook Ansible pour gérer l’installation et le redémarrage conditionnel de plusieurs services.
<p><strong>Contexte</strong> : Vous devez installer et gérer plusieurs services (comme Apache, Nginx, et Docker) sur une infrastructure. Si l’un des services est déjà installé mais n’est pas en cours d’exécution, le playbook doit le redémarrer.</p>
<details>
<summary><b>Étapes principales</b></summary>
<ol>
<li>Créez un playbook <code>service_management.yml</code>.</li>
<li>Utilisez <code>loop</code> pour gérer plusieurs services avec <code>package</code> et <code>service</code>.</li>
<li>Utilisez <code>when</code> pour vérifier l’état des services et redémarrer ceux qui ne sont pas actifs.</li>
</ol>
</details>
<p><strong>Compétences renforcées</strong> :</p>
<ul>
<li>Utilisation des modules essentiels</li>
<li>Boucles et conditions dans les tâches</li>
</ul>
<details>
<summary><b>Solution suggérée</b></summary>
Utilisez un playbook semblable à ceci :
<pre><code class="language-yaml">- name: Gestion des services
  hosts: all
  vars:
    services:
      - apache2
      - nginx
      - docker
  tasks:
    - name: Installer les services
      package:
        name: "{{ item }}"
        state: present
      loop: "{{ services }}"

    - name: Redémarrer les services si arrêtés
      service:
        name: "{{ item }}"
        state: restarted
      loop: "{{ services }}"
      when: ansible_facts.services[item].state != "running"
</code></pre>
</details>
</details>
<div style="break-before: page; page-break-before: always;"></div><h2 id="partie-3--automatisation-avec-ansible-et-aws"><a class="header" href="#partie-3--automatisation-avec-ansible-et-aws">Partie 3 : Automatisation avec Ansible et AWS</a></h2>
<h3 id="objectifs-9"><a class="header" href="#objectifs-9">Objectifs</a></h3>
<p>Dans cette partie, vous allez :</p>
<ul>
<li>Découvrir comment Ansible peut être utilisé pour gérer des ressources AWS.</li>
<li>Apprendre à configurer Ansible pour AWS avec un rôle IAM.</li>
<li>Créer et gérer des ressources AWS, notamment des instances EC2 et des buckets S3.</li>
</ul>
<hr />
<h3 id="31-introduction-aux-modules-aws-dans-ansible"><a class="header" href="#31-introduction-aux-modules-aws-dans-ansible">3.1 Introduction aux Modules AWS dans Ansible</a></h3>
<p>Ansible propose des modules spécifiques pour gérer les services AWS, permettant de créer et de configurer des ressources comme EC2, S3, RDS, et ELB de manière automatisée.</p>
<h4 id="présentation-des-modules-aws"><a class="header" href="#présentation-des-modules-aws">Présentation des modules AWS</a></h4>
<ul>
<li><a href="https://docs.ansible.com/ansible/latest/collections/amazon/aws/ec2_instance_module.html#ansible-collections-amazon-aws-ec2-instance-module"><strong>ec2</strong></a> : Pour lancer, arrêter et gérer des instances EC2.</li>
<li><a href="https://docs.ansible.com/ansible/latest/collections/amazon/aws/s3_bucket_module.html#ansible-collections-amazon-aws-s3-bucket-module"><strong>aws_s3</strong></a> : Pour créer et gérer des buckets S3, ainsi que pour uploader ou télécharger des fichiers.</li>
<li><a href="https://docs.ansible.com/ansible/latest/collections/amazon/aws/rds_instance_module.html#ansible-collections-amazon-aws-rds-instance-module"><strong>rds</strong></a> : Pour provisionner et configurer des bases de données RDS.</li>
<li><a href="https://docs.ansible.com/ansible/latest/collections/amazon/aws/elb_application_lb_module.html#ansible-collections-amazon-aws-elb-application-lb-module"><strong>elb</strong></a> : Pour créer et gérer des load balancers dans AWS.</li>
</ul>
<blockquote>
<p>Voir aussi le <a href="https://docs.ansible.com/ansible/latest/collections/amazon/aws/docsite/guide_aws.html">guide aws</a> d'ansible et la <a href="https://docs.ansible.com/ansible/latest/collections/amazon/aws/index.html">liste complète</a> des modules aws</p>
</blockquote>
<h4 id="configuration-dansible-pour-aws-avec-un-rôle-iam"><a class="header" href="#configuration-dansible-pour-aws-avec-un-rôle-iam">Configuration d'Ansible pour AWS avec un Rôle IAM</a></h4>
<p>Pour que Ansible puisse interagir avec AWS, configurez-le pour utiliser un rôle IAM attaché à l’instance de gestion. Ce rôle doit avoir les permissions nécessaires pour accéder aux services AWS (EC2, S3, etc.).</p>
<ol>
<li>
<p><strong>Créer un rôle IAM avec des permissions AWS</strong> :</p>
<ul>
<li>Dans la console IAM, créez un rôle avec les permissions nécessaires pour EC2 et S3.</li>
<li>Associez ce rôle à l'instance de gestion Ansible.</li>
</ul>
</li>
<li>
<p><strong>Configurer les informations d’identification dans Ansible</strong> :</p>
<ul>
<li>Ansible utilisera le rôle IAM de l’instance de gestion pour accéder aux services AWS. Aucune clé d'accès n'est nécessaire dans le fichier de configuration.</li>
</ul>
</li>
</ol>
<p><strong>Exercice</strong> : Configurer Ansible pour AWS en utilisant un rôle IAM sur une instance de gestion</p>
<ol>
<li><strong>Objectif</strong> : Configurer Ansible pour gérer les ressources AWS depuis une instance EC2 avec un rôle IAM attaché.</li>
<li><strong>Étapes</strong> :
<ul>
<li>Créez un rôle IAM avec des permissions de gestion pour EC2 et S3.</li>
<li>Associez ce rôle à l'instance de gestion Ansible.</li>
<li>Vérifiez l'accès en exécutant une commande Ansible pour interagir avec AWS.</li>
</ul>
</li>
</ol>
<hr />
<h3 id="32-provisionner-des-instances-ec2"><a class="header" href="#32-provisionner-des-instances-ec2">3.2 Provisionner des Instances EC2</a></h3>
<p>Le module <code>ec2</code> dans Ansible permet de créer, configurer et gérer des instances EC2. Cela facilite le provisionnement d’infrastructures dynamiques en automatisant le lancement d’instances, la gestion de la configuration réseau, et bien plus encore.</p>
<h4 id="utilisation-du-module-ec2-pour-lancer-et-arrêter-des-instances"><a class="header" href="#utilisation-du-module-ec2-pour-lancer-et-arrêter-des-instances">Utilisation du module <code>ec2</code> pour lancer et arrêter des instances</a></h4>
<ol>
<li><strong>Paramètres clés</strong> :
<ul>
<li><code>instance_type</code> : Type d'instance à lancer (ex. : <code>t2.micro</code>).</li>
<li><code>ami</code> : Identifiant de l’image AMI à utiliser.</li>
<li><code>key_name</code> : Clé SSH pour l’accès à l’instance.</li>
<li><code>security_groups</code> : Groupes de sécurité associés à l’instance.</li>
</ul>
</li>
</ol>
<p><strong>Exemple de playbook pour lancer une instance EC2</strong> :</p>
<pre><code class="language-yaml">- name: Lancer une instance EC2
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Lancer une instance EC2
      ec2:
        key_name: "my-key"
        instance_type: "t2.micro"
        image: "ami-0abcdef1234567890"
        wait: yes
        region: "us-west-2"
        security_group: "my-security-group"
        count: 1
      register: ec2_info

    - name: Afficher l'IP publique de l'instance
      debug:
        msg: "Instance IP: {{ ec2_info.instances[0].public_ip }}"
</code></pre>
<h4 id="exercice--Écrire-un-playbook-pour-lancer-une-instance-ec2-et-y-appliquer-une-configuration-de-base"><a class="header" href="#exercice--Écrire-un-playbook-pour-lancer-une-instance-ec2-et-y-appliquer-une-configuration-de-base">Exercice : Écrire un playbook pour lancer une instance EC2 et y appliquer une configuration de base</a></h4>
<p><strong>Objectif</strong> : Créer un playbook pour lancer une instance EC2 et configurer un service de base (comme Apache).</p>
<p><strong>Étapes</strong> :</p>
<ol>
<li>Créez un playbook nommé <code>launch_ec2.yml</code>.</li>
<li>Utilisez le module <code>ec2</code> pour lancer une instance EC2.</li>
<li>Ajoutez des tâches pour installer Apache et démarrer le service sur l’instance.</li>
</ol>
<hr />
<h3 id="33-gestion-du-stockage-avec-s3"><a class="header" href="#33-gestion-du-stockage-avec-s3">3.3 Gestion du Stockage avec S3</a></h3>
<p>S3 est un service de stockage d'objets dans AWS, utile pour conserver des artefacts de builds, des logs, ou des fichiers de configuration. Le module <code>aws_s3</code> permet de créer et gérer des buckets S3, ainsi que d'uploader ou de télécharger des fichiers.</p>
<h4 id="utilisation-du-module-aws_s3-pour-gérer-le-stockage-des-artefacts-et-des-logs"><a class="header" href="#utilisation-du-module-aws_s3-pour-gérer-le-stockage-des-artefacts-et-des-logs">Utilisation du module <code>aws_s3</code> pour gérer le stockage des artefacts et des logs</a></h4>
<ol>
<li><strong>Tâches courantes</strong> :
<ul>
<li><strong>Création de buckets</strong> : Créer des espaces de stockage pour organiser les artefacts et les logs.</li>
<li><strong>Upload et gestion des fichiers</strong> : Transférer des fichiers dans des buckets pour les rendre disponibles ou archivés.</li>
<li><strong>Configuration des permissions</strong> : Définir les permissions d'accès aux fichiers et aux buckets.</li>
</ul>
</li>
</ol>
<p><strong>Exemple de playbook pour créer un bucket S3 et y uploader un fichier</strong> :</p>
<pre><code class="language-yaml">- name: Gestion d'un bucket S3
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Créer un bucket S3
      aws_s3:
        bucket: "my-ansible-bucket"
        mode: create
        region: "us-west-2"

    - name: Uploader un fichier dans le bucket S3
      aws_s3:
        bucket: "my-ansible-bucket"
        object: "config/config.txt"
        src: "/path/to/local/config.txt"
        mode: put
</code></pre>
<p><img src="ansible/sections/../images/02_Basics/s3_bucket.png" alt="Gestion d&#39;un bucket S3 avec Ansible" /></p>
<h4 id="exercice--créer-un-playbook-pour-créer-un-bucket-s3-et-y-stocker-des-fichiers-de-configuration-ou-des-artefacts"><a class="header" href="#exercice--créer-un-playbook-pour-créer-un-bucket-s3-et-y-stocker-des-fichiers-de-configuration-ou-des-artefacts">Exercice : Créer un playbook pour créer un bucket S3 et y stocker des fichiers de configuration ou des artefacts</a></h4>
<p><strong>Objectif</strong> : Écrire un playbook pour créer un bucket S3 et y uploader un fichier de configuration ou un artefact.</p>
<p><strong>Étapes</strong> :</p>
<ol>
<li>Créez un fichier <code>s3_storage.yml</code>.</li>
<li>Utilisez le module <code>aws_s3</code> pour créer un bucket S3.</li>
<li>Ajoutez une tâche pour uploader un fichier de configuration dans le bucket.</li>
</ol>
<hr />
<h3 id="liens-vers-la-documentation-5"><a class="header" href="#liens-vers-la-documentation-5">Liens vers la Documentation</a></h3>
<ul>
<li><a href="https://docs.ansible.com/ansible/latest/collections/amazon/aws/ec2_instance_module.html">Documentation du module <code>ec2</code> dans Ansible</a></li>
<li><a href="https://docs.ansible.com/ansible/latest/collections/amazon/aws/aws_s3_module.html">Documentation du module <code>aws_s3</code></a></li>
<li><a href="https://docs.ansible.com/ansible/latest/scenario_guides/guide_aws.html">Configuration d’Ansible avec AWS</a></li>
</ul>
<hr />
<h3 id="questions-de-révision-9"><a class="header" href="#questions-de-révision-9">Questions de Révision</a></h3>
<details>
<summary><h3 style="display:inline-block">Questions de Révision</h3></summary>
<details>
<summary>Quel module Ansible permet de lancer et de gérer des instances EC2 ?</summary>
<details>
<summary>Solution</summary>
Le module `ec2` permet de lancer, arrêter et gérer des instances EC2.
</details>
</details>
<details>
<summary>Quelles permissions IAM sont nécessaires pour qu'Ansible gère les ressources AWS ?</summary>
<details>
<summary>Solution</summary>
Les permissions nécessaires dépendent des services utilisés, comme `ec2:RunInstances` pour EC2 et `s3:PutObject` pour S3, configurées dans un rôle IAM.
</details>
</details>
<details>
<summary>Comment Ansible interagit-il avec S3 pour gérer les artefacts ?</summary>
<details>
<summary>Solution</summary>
Ansible utilise le module `aws_s3` pour créer des buckets, uploader des fichiers, et gérer les permissions de manière automatisée.
</details>
</details>
</details>
<hr />
<h3 id="conseils-pratiques-5"><a class="header" href="#conseils-pratiques-5">Conseils Pratiques</a></h3>
<ol>
<li><strong>Utilisez des noms uniques pour les buckets S3</strong> : Les noms de buckets doivent être uniques globalement.</li>
<li><strong>Configurez le rôle IAM avec le principe de moindre privilège</strong> : Assurez-vous que le rôle IAM de l’instance de gestion a uniquement les permissions nécessaires pour éviter les risques de sécurité.</li>
<li><strong>Testez les modules AWS en mode débogage</strong> : Utilisez l'option <code>check_mode</code> pour tester les modifications sans les appliquer réellement.
<a href="https://docs.ansible.com/ansible/latest/scenario_guides/guide_aws.html">Plus de détails sur la configuration AWS</a></li>
</ol>
<hr />
<h3 id="défi-intermédiaire-4"><a class="header" href="#défi-intermédiaire-4">Défi Intermédiaire</a></h3>
<details>
<summary><h3 style="display:inline-block">Défi Intermédiaire</h3></summary>
**Objectif** : Automatiser la gestion d'une infrastructure AWS incluant le provisionnement d'instances EC2 et la gestion des artefacts dans S3.
<p><strong>Contexte</strong> : Vous devez créer un playbook Ansible pour lancer une instance EC2, configurer le serveur avec un fichier de configuration spécifique, et sauvegarder ce fichier dans un bucket S3.</p>
<details>
<summary><b>Étapes principales</b></summary>
1. Créez un playbook nommé `aws_infra.yml`.
2. Utilisez le module `ec2` pour lancer une instance EC2.
3. Configurez le serveur avec un fichier de configuration.
4. Uploadez le fichier de configuration dans un bucket S3.
</details>
<p><strong>Compétences renforcées</strong> :</p>
<ul>
<li>Provisionnement d'instances EC2</li>
<li>Gestion de fichiers dans S3</li>
</ul>
<details>
<summary><b>Solution suggérée</b></summary>
Utilisez un playbook semblable à ceci :
<pre><code class="language-yaml">- name: Gestion de l'infrastructure AWS
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Lancer une instance EC2
      ec2:
        key_name: "my-key"
        instance_type: "t2.micro"
        image: "ami-0abcdef1234567890"
        wait: yes
        region: "us-west-2"
        security_group: "my-security-group"
      register: ec2_info

    - name: Uploader le fichier de configuration dans S3
      aws_s3:
        bucket: "my-ansible-bucket"
        object: "config/config.txt"
        src: "/path/to/local/config.txt"
        mode: put
</code></pre>
</details>
</details>
<div style="break-before: page; page-break-before: always;"></div><h2 id="partie-4--playbooks-avancés-pour-aws-avec-s3"><a class="header" href="#partie-4--playbooks-avancés-pour-aws-avec-s3">Partie 4 : Playbooks Avancés pour AWS avec S3</a></h2>
<h3 id="objectifs-10"><a class="header" href="#objectifs-10">Objectifs</a></h3>
<p>Dans cette partie, vous allez :</p>
<ul>
<li>Découvrir comment automatiser les tâches de gestion de stockage dans AWS S3 avec Ansible.</li>
<li>Apprendre à créer, configurer et gérer les fichiers et les artefacts dans des buckets S3.</li>
<li>Utiliser les bonnes pratiques de sécurité et d’optimisation pour gérer les permissions et les coûts de stockage.</li>
</ul>
<hr />
<h3 id="41-introduction-à-la-gestion-de-s3-avec-ansible"><a class="header" href="#41-introduction-à-la-gestion-de-s3-avec-ansible">4.1 Introduction à la Gestion de S3 avec Ansible</a></h3>
<p>S3 est un service de stockage d'objets dans AWS, utile pour conserver des artefacts, des fichiers de configuration, des logs, et plus encore. En utilisant Ansible, nous pouvons automatiser les tâches de gestion de S3, ce qui facilite le stockage et l’organisation de fichiers de manière centralisée.</p>
<h4 id="concepts-clés"><a class="header" href="#concepts-clés">Concepts clés</a></h4>
<ul>
<li><strong>Utilisation de S3</strong> : S3 permet de stocker, organiser et partager des fichiers de manière efficace, tout en garantissant leur sécurité.</li>
<li><strong>Modules Ansible pour S3</strong> : Le module <code>aws_s3</code> permet de créer, configurer et gérer des buckets S3.</li>
</ul>
<hr />
<h3 id="42-création-et-configuration-de-buckets-s3"><a class="header" href="#42-création-et-configuration-de-buckets-s3">4.2 Création et Configuration de Buckets S3</a></h3>
<h4 id="création-de-buckets-s3-avec-ansible"><a class="header" href="#création-de-buckets-s3-avec-ansible">Création de Buckets S3 avec Ansible</a></h4>
<p>Le module <code>aws_s3</code> permet de créer des buckets directement depuis Ansible, en évitant de passer par la console AWS.</p>
<p><strong>Exercice</strong> : Écrire un playbook pour créer un bucket S3 avec des paramètres personnalisés.</p>
<p><strong>Objectif</strong> : Créer un bucket S3 avec un nom unique et configurer la région.</p>
<ol>
<li>Créez un playbook nommé <code>create_bucket.yml</code>.</li>
<li>Utilisez le module <code>aws_s3</code> pour spécifier le nom et la région du bucket.</li>
</ol>
<p><strong>Exemple de playbook</strong> :</p>
<pre><code class="language-yaml">- name: Créer un bucket S3 avec Ansible
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Créer le bucket S3
      aws_s3:
        bucket: "my-ansible-bucket"
        mode: create
        region: "us-west-2"
</code></pre>
<h4 id="configuration-des-permissions-et-politiques-de-sécurité"><a class="header" href="#configuration-des-permissions-et-politiques-de-sécurité">Configuration des Permissions et Politiques de Sécurité</a></h4>
<p>Les permissions et les politiques de sécurité S3 permettent de restreindre l'accès aux ressources du bucket. Avec Ansible, vous pouvez configurer des règles de sécurité précises pour contrôler qui peut accéder aux fichiers stockés dans S3.</p>
<p><strong>Exercice</strong> : Configurer un playbook pour définir des permissions spécifiques sur un bucket S3</p>
<p><strong>Objectif</strong> : Limiter l’accès au bucket à des rôles IAM spécifiques.</p>
<ol>
<li>Ajoutez une politique de sécurité dans le playbook pour restreindre l'accès aux utilisateurs autorisés.</li>
</ol>
<p><strong>Exemple de configuration des permissions</strong> :</p>
<pre><code class="language-yaml">- name: Configurer les permissions du bucket S3
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Appliquer une politique de sécurité au bucket S3
      aws_s3:
        bucket: "my-ansible-bucket"
        policy: |
          {
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Allow",
                "Principal": {
                  "AWS": "arn:aws:iam::123456789012:role/MyRole"
                },
                "Action": "s3:*",
                "Resource": "arn:aws:s3:::my-ansible-bucket/*"
              }
            ]
          }
        mode: put
</code></pre>
<hr />
<h3 id="43-gestion-des-fichiers-dans-s3-avec-ansible"><a class="header" href="#43-gestion-des-fichiers-dans-s3-avec-ansible">4.3 Gestion des Fichiers dans S3 avec Ansible</a></h3>
<h4 id="téléversement-et-téléchargement-de-fichiers-dans-s3"><a class="header" href="#téléversement-et-téléchargement-de-fichiers-dans-s3">Téléversement et Téléchargement de Fichiers dans S3</a></h4>
<p>Le module <code>aws_s3</code> peut être utilisé pour téléverser ou télécharger des fichiers dans S3, facilitant ainsi le stockage d’artefacts, de logs et de configurations.</p>
<p><strong>Exercice</strong> : Écrire un playbook pour téléverser des fichiers de logs vers un bucket S3</p>
<p><strong>Objectif</strong> : Uploader des logs générés par un playbook de configuration dans un bucket S3 pour stockage et analyse.</p>
<ol>
<li>Créez un playbook nommé <code>upload_logs.yml</code>.</li>
<li>Ajoutez une tâche pour uploader un fichier de logs dans le bucket S3.</li>
</ol>
<p><strong>Exemple de playbook pour l’upload de fichiers</strong> :</p>
<pre><code class="language-yaml">- name: Uploader des logs dans S3
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Uploader le fichier de logs
      aws_s3:
        bucket: "my-ansible-bucket"
        object: "logs/deployment.log"
        src: "/path/to/local/deployment.log"
        mode: put
</code></pre>
<h4 id="organisation-et-gestion-des-objets-s3"><a class="header" href="#organisation-et-gestion-des-objets-s3">Organisation et Gestion des Objets S3</a></h4>
<p>Les fichiers peuvent être organisés dans S3 en utilisant des préfixes et des sous-dossiers virtuels, ce qui facilite leur gestion et leur récupération.</p>
<p><strong>Exercice</strong> : Configurer un playbook pour organiser les artefacts d’un déploiement CI/CD dans un bucket S3</p>
<p><strong>Objectif</strong> : Stocker les artefacts par projet et date pour faciliter le suivi.</p>
<ol>
<li>Créez un playbook pour organiser les fichiers d’un déploiement avec des préfixes pour chaque projet et date.</li>
</ol>
<hr />
<h3 id="44-gestion-des-versions-et-de-la-rétention-des-objets"><a class="header" href="#44-gestion-des-versions-et-de-la-rétention-des-objets">4.4 Gestion des Versions et de la Rétention des Objets</a></h3>
<h4 id="activer-et-gérer-le-versioning-dans-un-bucket-s3"><a class="header" href="#activer-et-gérer-le-versioning-dans-un-bucket-s3">Activer et Gérer le Versioning dans un Bucket S3</a></h4>
<p>Le versioning dans S3 permet de conserver différentes versions d'un même fichier, utile pour les mises à jour fréquentes ou la conservation de configurations.</p>
<p><strong>Exercice</strong> : Écrire un playbook pour activer le versioning et configurer la rétention</p>
<p><strong>Objectif</strong> : Activer le versioning sur un bucket S3 et définir des règles de cycle de vie pour la suppression automatique.</p>
<ol>
<li>Ajoutez des paramètres de versioning et de cycle de vie dans votre playbook pour activer la gestion de la rétention.</li>
</ol>
<p><strong>Exemple de playbook pour le versioning et la rétention</strong> :</p>
<pre><code class="language-yaml">- name: Activer le versioning et configurer la rétention
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Activer le versioning sur le bucket S3
      aws_s3:
        bucket: "my-ansible-bucket"
        versioning: yes
        mode: put

    - name: Configurer la règle de cycle de vie pour le nettoyage automatique
      aws_s3:
        bucket: "my-ansible-bucket"
        lifecycle:
          - id: "Retain non-current versions"
            status: "Enabled"
            noncurrentVersionExpiration:
              noncurrentDays: 30
</code></pre>
<hr />
<h3 id="45-défis-et-bonnes-pratiques-pour-lautomatisation-de-s3-avec-ansible"><a class="header" href="#45-défis-et-bonnes-pratiques-pour-lautomatisation-de-s3-avec-ansible">4.5 Défis et Bonnes Pratiques pour l’Automatisation de S3 avec Ansible</a></h3>
<h4 id="gestion-des-permissions-et-des-politiques-de-sécurité"><a class="header" href="#gestion-des-permissions-et-des-politiques-de-sécurité">Gestion des Permissions et des Politiques de Sécurité</a></h4>
<p>Adoptez les meilleures pratiques pour sécuriser les accès aux fichiers stockés dans S3. Utilisez des stratégies de bucket pour limiter les accès aux rôles IAM autorisés et assurez-vous que les permissions sont minimales.</p>
<h4 id="optimisation-des-coûts-de-stockage"><a class="header" href="#optimisation-des-coûts-de-stockage">Optimisation des Coûts de Stockage</a></h4>
<p>S3 propose plusieurs classes de stockage (Standard, Intelligent-Tiering, Glacier) pour gérer les coûts en fonction de l’utilisation des fichiers.</p>
<p><strong>Exercice</strong> : Écrire un playbook pour configurer le cycle de vie d’un bucket S3 et déplacer les fichiers peu utilisés</p>
<p><strong>Objectif</strong> : Configurer des règles pour déplacer automatiquement les fichiers rarement consultés vers une classe de stockage moins coûteuse.</p>
<ol>
<li>Ajoutez une règle de cycle de vie dans votre playbook pour transférer les fichiers après une certaine période vers Glacier.</li>
</ol>
<p><strong>Exemple de playbook pour l’optimisation des coûts</strong> :</p>
<pre><code class="language-yaml">- name: Configurer le cycle de vie pour réduire les coûts de stockage
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Ajouter une règle de cycle de vie
      aws_s3:
        bucket: "my-ansible-bucket"
        lifecycle:
          - id: "Transition to Glacier"
            status: "Enabled"
            transitions:
              - days: 90
                storageClass: "GLACIER"
</code></pre>
<hr />
<h3 id="liens-vers-la-documentation-6"><a class="header" href="#liens-vers-la-documentation-6">Liens vers la Documentation</a></h3>
<ul>
<li><a href="https://docs.ansible.com/ansible/latest/collections/amazon/aws/aws_s3_module.html">Documentation du module <code>aws_s3</code> dans Ansible</a></li>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/lifecycle-configuration-examples.html">Documentation des stratégies de cycle de vie S3</a> [<a href="https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/lifecycle-configuration-examples.html"><em>fr</em></a>]</li>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/security-best-practices.html">Guide des permissions et sécurité S3</a></li>
</ul>
<hr />
<h3 id="questions-de-révision-10"><a class="header" href="#questions-de-révision-10">Questions de Révision</a></h3>
<details>
<summary><h3 style="display:inline-block">Questions de Révision</h3></summary>
<details>
<summary>Quel module Ansible permet de gérer les buckets et fichiers S3 ?</summary>
<details>
<summary>Solution</summary>
Le module `aws_s3` permet de créer des buckets, de téléverser ou télécharger des fichiers, et de configurer des règles de cycle
<p>de vie et de versioning pour S3.</p>
</details>
</details>
<details>
<summary>Comment configure-t-on des permissions spécifiques pour un bucket S3 avec Ansible ?</summary>
<details>
<summary>Solution</summary>
On peut configurer les permissions en utilisant des stratégies de sécurité (policies) directement dans le module `aws_s3` pour définir qui peut accéder aux objets du bucket.
</details>
</details>
<details>
<summary>Qu’est-ce que le versioning dans un bucket S3 et pourquoi est-il utile ?</summary>
<details>
<summary>Solution</summary>
Le versioning permet de conserver plusieurs versions d'un même fichier, ce qui est utile pour suivre les modifications ou pour restaurer d'anciennes versions en cas de suppression accidentelle.
</details>
</details>
</details>
<hr />
<h3 id="conseils-pratiques-6"><a class="header" href="#conseils-pratiques-6">Conseils Pratiques</a></h3>
<ol>
<li><strong>Utilisez des noms uniques pour les buckets S3</strong> : Les noms de buckets sont globaux et doivent être uniques dans AWS.</li>
<li><strong>Appliquez le principe de moindre privilège pour les rôles IAM</strong> : Assurez-vous que les rôles IAM utilisés pour gérer S3 ne disposent que des permissions nécessaires.</li>
<li><strong>Mettez en place des règles de cycle de vie pour optimiser les coûts de stockage</strong> : Les règles de cycle de vie automatisent le transfert de fichiers vers des classes de stockage moins coûteuses.
<a href="https://aws.amazon.com/s3/storage-classes/">Plus de détails sur la gestion des coûts dans S3</a> [<a href="https://aws.amazon.com/fr/s3/storage-classes/"><em>fr</em></a>]</li>
</ol>
<hr />
<h3 id="défi-intermédiaire-5"><a class="header" href="#défi-intermédiaire-5">Défi Intermédiaire</a></h3>
<details>
<summary><h3 style="display:inline-block">Défi Intermédiaire</h3></summary>
**Objectif** : Créer un playbook pour gérer un bucket S3 avec versioning, politiques de sécurité et règles de cycle de vie.
<p><strong>Contexte</strong> : Vous devez créer un bucket S3 pour stocker des artefacts et configurer le versioning, des règles de sécurité, et une politique de cycle de vie pour optimiser les coûts de stockage.</p>
<details>
<summary><b>Étapes principales</b></summary>
1. Créez un playbook nommé `manage_s3.yml`.
2. Utilisez le module `aws_s3` pour créer un bucket et activer le versioning.
3. Configurez une politique de sécurité pour restreindre les accès.
4. Ajoutez une règle de cycle de vie pour transférer les fichiers vers Glacier après 90 jours.
</details>
<p><strong>Compétences renforcées</strong> :</p>
<ul>
<li>Gestion avancée des buckets S3</li>
<li>Application des politiques de sécurité et de cycle de vie</li>
</ul>
<details>
<summary><b>Solution suggérée</b></summary>
Utilisez un playbook semblable à ceci :
<pre><code class="language-yaml">- name: Gestion avancée d'un bucket S3
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Créer le bucket avec versioning
      aws_s3:
        bucket: "my-advanced-bucket"
        versioning: yes
        mode: create
        region: "us-west-2"

    - name: Appliquer une politique de sécurité au bucket
      aws_s3:
        bucket: "my-advanced-bucket"
        policy: |
          {
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Allow",
                "Principal": {
                  "AWS": "arn:aws:iam::123456789012:role/MyRole"
                },
                "Action": "s3:*",
                "Resource": "arn:aws:s3:::my-advanced-bucket/*"
              }
            ]
          }
        mode: put

    - name: Configurer le cycle de vie pour optimiser les coûts
      aws_s3:
        bucket: "my-advanced-bucket"
        lifecycle:
          - id: "Transition to Glacier"
            status: "Enabled"
            transitions:
              - days: 90
                storageClass: "GLACIER"
</code></pre>
</details>
</details>
<div style="break-before: page; page-break-before: always;"></div><h2 id="partie-5--intégration-dansible-dans-un-pipeline-cicd-avec-jenkins-et-aws"><a class="header" href="#partie-5--intégration-dansible-dans-un-pipeline-cicd-avec-jenkins-et-aws">Partie 5 : Intégration d'Ansible dans un Pipeline CI/CD avec Jenkins et AWS</a></h2>
<h3 id="objectifs-11"><a class="header" href="#objectifs-11">Objectifs</a></h3>
<p>Dans cette partie, vous allez :</p>
<ul>
<li>Comprendre l’intégration d’Ansible dans un pipeline CI/CD avec Jenkins pour des déploiements automatisés.</li>
<li>Créer un pipeline Jenkins qui exécute des playbooks Ansible pour provisionner une infrastructure AWS.</li>
<li>Automatiser le déploiement d’une application et la gestion des artefacts dans un environnement cloud.</li>
</ul>
<hr />
<h3 id="51-introduction-à-lintégration-cicd-avec-jenkins-et-ansible"><a class="header" href="#51-introduction-à-lintégration-cicd-avec-jenkins-et-ansible">5.1 Introduction à l'Intégration CI/CD avec Jenkins et Ansible</a></h3>
<p>Jenkins est un outil d’intégration et de déploiement continus (CI/CD) qui permet d'automatiser les tâches de construction, de test, et de déploiement d'applications. En intégrant Ansible dans Jenkins, il devient possible d’automatiser le déploiement sur AWS en exécutant des playbooks Ansible directement depuis le pipeline Jenkins.</p>
<h4 id="avantages-de-lintégration-dansible-dans-un-pipeline-cicd"><a class="header" href="#avantages-de-lintégration-dansible-dans-un-pipeline-cicd">Avantages de l’intégration d’Ansible dans un pipeline CI/CD</a></h4>
<ul>
<li><strong>Automatisation du déploiement</strong> : Les playbooks Ansible peuvent être exécutés automatiquement à chaque changement de code ou de configuration, garantissant un déploiement rapide et cohérent.</li>
<li><strong>Standardisation des configurations</strong> : Grâce à Ansible, les configurations d’infrastructure et d’applications peuvent être uniformisées, limitant les erreurs de déploiement.</li>
<li><strong>Gestion centralisée des artefacts</strong> : Jenkins permet de suivre et stocker les logs ou artefacts de déploiement, tandis qu’Ansible gère l’infrastructure sous forme de code.</li>
</ul>
<hr />
<h3 id="52-création-dun-pipeline-jenkins-pour-lautomatisation-ansible"><a class="header" href="#52-création-dun-pipeline-jenkins-pour-lautomatisation-ansible">5.2 Création d’un Pipeline Jenkins pour l’Automatisation Ansible</a></h3>
<h4 id="Écriture-dun-jenkinsfile-pour-orchestrer-lexécution-de-playbooks-ansible"><a class="header" href="#Écriture-dun-jenkinsfile-pour-orchestrer-lexécution-de-playbooks-ansible">Écriture d’un Jenkinsfile pour orchestrer l'exécution de playbooks Ansible</a></h4>
<p>Le <strong>Jenkinsfile</strong> définit le pipeline CI/CD de Jenkins. Pour intégrer Ansible, nous définissons des étapes pour exécuter les playbooks, comme le provisioning de serveurs ou le déploiement d’applications.</p>
<p><strong>Exemple de Jenkinsfile pour exécuter un playbook Ansible</strong> :</p>
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Provision Infrastructure') {
            steps {
                ansiblePlaybook inventory: 'hosts',
                                playbook: 'provision_infra.yml'
            }
        }
    }
}
</code></pre>
<h4 id="exécution-dansible-dans-jenkins-avec-le-plugin-ansible"><a class="header" href="#exécution-dansible-dans-jenkins-avec-le-plugin-ansible">Exécution d’Ansible dans Jenkins avec le plugin Ansible</a></h4>
<ol>
<li><strong>Installation du plugin Ansible</strong> : Installez le plugin <strong>Ansible</strong> dans Jenkins pour exécuter des playbooks directement.</li>
<li><strong>Configuration des informations d’identification</strong> : Ajoutez les informations d’identification AWS dans Jenkins pour qu’il puisse accéder aux ressources cloud de manière sécurisée.</li>
<li><strong>Définition de l’inventaire</strong> : Spécifiez l’inventaire d’Ansible dans Jenkins pour exécuter les tâches sur les hôtes cibles.</li>
</ol>
<p><img src="ansible/sections/../images/05_Jenkins_AWS_Pipeline/ansible_plugin.png" alt="Intégration d&#39;Ansible dans Jenkins" /></p>
<blockquote>
<p>Source: https://plugins.jenkins.io/ansible/</p>
</blockquote>
<p><strong>Exercice</strong> : Créer un job Jenkins pour exécuter un playbook Ansible qui provisionne une infrastructure de test sur AWS</p>
<ol>
<li>Créez un Jenkinsfile avec une étape pour exécuter un playbook Ansible nommé <code>provision_infra.yml</code>.</li>
<li>Configurez Jenkins pour exécuter ce job avec le plugin Ansible, en spécifiant l’inventaire et les informations d’identification AWS.</li>
</ol>
<hr />
<h3 id="53-déploiement-automatisé-dune-application-sur-ec2-avec-ansible-et-jenkins"><a class="header" href="#53-déploiement-automatisé-dune-application-sur-ec2-avec-ansible-et-jenkins">5.3 Déploiement Automatisé d'une Application sur EC2 avec Ansible et Jenkins</a></h3>
<p>Dans cette étape, nous allons mettre en place un pipeline complet pour déployer une application sur une instance EC2 en utilisant Ansible et Jenkins. Le pipeline inclura le provisioning d’instances EC2, le déploiement de l’application, et la sauvegarde des artefacts dans S3.</p>
<h4 id="mise-en-place-dun-pipeline-complet-pour-le-déploiement-dune-application"><a class="header" href="#mise-en-place-dun-pipeline-complet-pour-le-déploiement-dune-application">Mise en place d’un pipeline complet pour le déploiement d’une application</a></h4>
<ol>
<li><strong>Création et configuration des instances EC2</strong> : Utilisez un playbook pour provisionner une ou plusieurs instances EC2 et configurer les paramètres de base.</li>
<li><strong>Déploiement de l’application et configuration de base</strong> : Ajoutez une étape pour installer l’application, configurer le serveur et les services nécessaires.</li>
<li><strong>Stockage des logs ou des artefacts dans S3</strong> : Automatisez le transfert des artefacts générés (logs, fichiers de configuration) vers S3 pour archivage.</li>
</ol>
<p><strong>Exemple de Jenkinsfile pour un pipeline de déploiement avec Ansible</strong> :</p>
<pre><code class="language-groovy">pipeline {
    agent any
   stages {
        stage('Provision EC2 Instances') {
            steps {
                ansiblePlaybook playbook: 'provision_ec2.yml'
            }
        }
        stage('Deploy Application') {
            steps {
                ansiblePlaybook playbook: 'deploy_application.yml'
            }
        }
        stage('Store Logs in S3') {
            steps {
                ansiblePlaybook playbook: 'upload_logs_s3.yml'
            }
        }
    }
}
</code></pre>
<p><img src="ansible/sections/../images/05_Jenkins_AWS_Pipeline/pipeline_flow.png" alt="Pipeline CI/CD complet avec Jenkins et Ansible" /></p>
<blockquote>
<p>Source: https://www.redhat.com/en/blog/integrating-ansible-jenkins-cicd-process</p>
</blockquote>
<hr />
<h3 id="projet-final--créer-un-pipeline-jenkins-avec-ansible-pour-provisionner-des-instances-ec2-configurer-lapplication-et-sauvegarder-les-logs-dans-s3"><a class="header" href="#projet-final--créer-un-pipeline-jenkins-avec-ansible-pour-provisionner-des-instances-ec2-configurer-lapplication-et-sauvegarder-les-logs-dans-s3">Projet final : Créer un pipeline Jenkins avec Ansible pour provisionner des instances EC2, configurer l’application, et sauvegarder les logs dans S3</a></h3>
<p><strong>Objectif du projet</strong> : Automatiser l’ensemble du processus de déploiement d’une application sur AWS en intégrant Ansible dans un pipeline CI/CD Jenkins.</p>
<p><strong>Étapes du projet</strong> :</p>
<ol>
<li>
<p><strong>Préparer les playbooks Ansible</strong> :</p>
<ul>
<li><code>provision_ec2.yml</code> : Provisionner une instance EC2 avec les paramètres nécessaires (type d’instance, sécurité, etc.).</li>
<li><code>deploy_application.yml</code> : Déployer l’application sur l’instance EC2, en installant les dépendances nécessaires.</li>
<li><code>upload_logs_s3.yml</code> : Sauvegarder les logs de déploiement dans un bucket S3.</li>
</ul>
</li>
<li>
<p><strong>Configurer le pipeline Jenkins</strong> :</p>
<ul>
<li>Créez un Jenkinsfile avec des étapes pour exécuter chaque playbook.</li>
<li>Utilisez le plugin Ansible pour exécuter les playbooks dans chaque étape du pipeline.</li>
</ul>
</li>
<li>
<p><strong>Exécuter le pipeline et vérifier les résultats</strong> :</p>
<ul>
<li>Exécutez le pipeline dans Jenkins pour provisionner, déployer, et stocker les artefacts.</li>
<li>Vérifiez que les logs sont correctement sauvegardés dans S3 et que l’application est accessible sur l’instance EC2.</li>
</ul>
</li>
</ol>
<hr />
<h3 id="liens-vers-la-documentation-7"><a class="header" href="#liens-vers-la-documentation-7">Liens vers la Documentation</a></h3>
<ul>
<li><a href="https://www.jenkins.io/doc/">Documentation officielle de Jenkins</a></li>
<li><a href="https://plugins.jenkins.io/ansible/">Documentation du plugin Ansible pour Jenkins</a></li>
<li><a href="https://www.jenkins.io/doc/book/pipeline/jenkinsfile/">Exemples de Jenkinsfile pour CI/CD</a></li>
</ul>
<hr />
<h3 id="questions-de-révision-11"><a class="header" href="#questions-de-révision-11">Questions de Révision</a></h3>
<details>
<summary><h3 style="display:inline-block">Questions de Révision</h3></summary>
<details>
<summary>Pourquoi est-il avantageux d'intégrer Ansible dans un pipeline CI/CD Jenkins ?</summary>
<details>
<summary>Solution</summary>
L'intégration d'Ansible permet l'automatisation complète des déploiements, la standardisation des configurations, et facilite la gestion des ressources cloud de manière récurrente.
</details>
</details>
<details>
<summary>Quel est le rôle du Jenkinsfile dans un pipeline Jenkins ?</summary>
<details>
<summary>Solution</summary>
Le Jenkinsfile définit les étapes du pipeline CI/CD, permettant d’orchestrer les différentes étapes de construction, test, et déploiement de manière codifiée.
</details>
</details>
<details>
<summary>Comment Jenkins exécute-t-il des playbooks Ansible ?</summary>
<details>
<summary>Solution</summary>
Jenkins exécute des playbooks Ansible en utilisant le plugin Ansible, configuré avec les informations d’identification nécessaires et le fichier d’inventaire.
</details>
</details>
</details>
<hr />
<h3 id="conseils-pratiques-7"><a class="header" href="#conseils-pratiques-7">Conseils Pratiques</a></h3>
<ol>
<li><strong>Utilisez des noms explicites pour chaque étape du pipeline</strong> dans le Jenkinsfile pour une meilleure lisibilité des logs.</li>
<li><strong>Stockez les informations d’identification de manière sécurisée dans Jenkins</strong> : utilisez les <strong>Credentials</strong> de Jenkins pour stocker les informations AWS nécessaires.</li>
<li><strong>Vérifiez l'intégration Ansible-Jenkins avec des tests de validation de configuration</strong> avant de déployer en production.
<a href="https://www.jenkins.io/doc/book/pipeline/jenkinsfile/">Guide d'intégration Ansible et Jenkins</a></li>
</ol>
<hr />
<h3 id="défi-intermédiaire-6"><a class="header" href="#défi-intermédiaire-6">Défi Intermédiaire</a></h3>
<details>
<summary><h3 style="display:inline-block">Défi Intermédiaire</h3></summary>
**Objectif** : Créer un pipeline CI/CD complet pour provisionner des instances EC2, déployer une application, et sauvegarder les logs dans S3.
<p><strong>Contexte</strong> : Vous devez configurer un pipeline Jenkins avec Ansible pour automatiser le déploiement d’une application. Les étapes incluront le provisioning d’instances EC2, l'installation de l'application, et le transfert des artefacts dans S3.</p>
<details>
<summary><b>Étapes principales</b></summary>
1. Créez les playbooks nécessaires (`provision_ec2.yml`, `deploy_application.yml`, `upload_logs_s3.yml`).
2. Configurez un Jenkinsfile pour orchestrer ces playbooks en étapes.
3. Ajoutez les informations d’identification AWS dans Jenkins et testez le pipeline.
</details>
<p><strong>Compétences renforcées</strong> :</p>
<ul>
<li>Intégration de Jenkins et Ansible pour des tâches d’automatisation</li>
<li>Création d’un pipeline CI/CD complet</li>
</ul>
<details>
<summary><b>Solution suggérée</b></summary>
Utilisez un Jenkinsfile comme suit :
<pre><code class="language-groovy">pipeline {
    agent any
    stages {
        stage('Provision EC2 Instances') {
            steps {
                ansiblePlaybook playbook: 'provision_ec2.yml'
            }
        }
        stage('Deploy Application') {
            steps {
                ansiblePlaybook playbook: 'deploy_application.yml'
            }
        }
        stage('Store Logs in S3') {
            steps {
                ansiblePlaybook playbook: 'upload_logs_s3.yml'
            }
        }
    }
}
</code></pre>
</details>
</details>
<div style="break-before: page; page-break-before: always;"></div><h2 id="partie-6--bonnes-pratiques-et-gestion-des-erreurs"><a class="header" href="#partie-6--bonnes-pratiques-et-gestion-des-erreurs">Partie 6 : Bonnes Pratiques et Gestion des Erreurs</a></h2>
<h3 id="objectifs-12"><a class="header" href="#objectifs-12">Objectifs</a></h3>
<p>Dans cette partie, vous allez :</p>
<ul>
<li>Apprendre les bonnes pratiques pour structurer des playbooks lisibles et maintenables.</li>
<li>Découvrir des techniques pour déboguer et gérer les erreurs dans Ansible.</li>
<li>Optimiser les playbooks pour une exécution plus rapide et plus efficace dans des environnements cloud AWS.</li>
</ul>
<hr />
<h3 id="61-bonnes-pratiques-pour-Écrire-des-playbooks-ansible"><a class="header" href="#61-bonnes-pratiques-pour-Écrire-des-playbooks-ansible">6.1 Bonnes Pratiques pour Écrire des Playbooks Ansible</a></h3>
<p>Un playbook bien structuré est essentiel pour faciliter la maintenance et la compréhension. Voici quelques bonnes pratiques pour écrire des playbooks clairs et efficaces.</p>
<h4 id="conseils-pour-structurer-les-playbooks"><a class="header" href="#conseils-pour-structurer-les-playbooks">Conseils pour structurer les playbooks</a></h4>
<ul>
<li><strong>Utilisez des noms explicites pour chaque tâche</strong> : Les noms de tâche permettent de comprendre rapidement l’action effectuée. Un nom clair facilite le suivi et le débogage.</li>
<li><strong>Documentez les variables</strong> : En ajoutant des commentaires, vous facilitez la compréhension et l’utilisation des variables par d’autres utilisateurs.</li>
<li><strong>Organisez les tâches par rôles ou blocs logiques</strong> : Structurez les playbooks en blocs logiques pour des sections de configuration ou de déploiement.</li>
<li><strong>Utilisez des fichiers d’inventaire et de configuration distincts</strong> : Gardez les inventaires séparés du code pour une meilleure organisation et sécurité.</li>
</ul>
<pre><code class="language-yaml">- name: Installer et configurer un serveur web
  hosts: webservers
  vars:
    package_name: "apache2"
  tasks:
    - name: Installer le package "{{ package_name }}"
      package:
        name: "{{ package_name }}"
        state: present
    - name: Démarrer le service "{{ package_name }}"
      service:
        name: "{{ package_name }}"
        state: started
</code></pre>
<blockquote>
<p>Les liens suivant regroupent les bonnes pratiques pour structurer un playbook ansible</p>
<ul>
<li>https://docs.ansible.com/ansible/2.8/user_guide/playbooks_best_practices.html</li>
<li>https://spacelift.io/blog/ansible-best-practices</li>
</ul>
</blockquote>
<hr />
<h3 id="62-débogage-et-gestion-des-erreurs"><a class="header" href="#62-débogage-et-gestion-des-erreurs">6.2 Débogage et Gestion des Erreurs</a></h3>
<p>Déboguer les playbooks est une compétence cruciale pour identifier et corriger rapidement les problèmes d’exécution.</p>
<h4 id="techniques-de-débogage"><a class="header" href="#techniques-de-débogage">Techniques de débogage</a></h4>
<ul>
<li><strong>Utilisez le mode verbeux (-v, -vv, -vvv)</strong> : Augmentez la verbosité pour obtenir des informations détaillées sur chaque étape d’un playbook.</li>
<li><strong>Utilisez le module <code>debug</code></strong> : Affichez des informations ou valeurs de variables à des étapes spécifiques pour mieux comprendre le comportement des tâches.</li>
<li><strong>Check mode (<code>--check</code>)</strong> : Simulez l’exécution sans appliquer de changements pour voir ce que le playbook ferait.</li>
</ul>
<h4 id="gestion-des-erreurs"><a class="header" href="#gestion-des-erreurs">Gestion des erreurs</a></h4>
<ul>
<li><strong>ignore_errors</strong> : Utilisez ce paramètre pour ignorer les erreurs d'une tâche spécifique, utile lorsque certaines erreurs peuvent être tolérées sans affecter le reste du processus.</li>
<li><strong>failed_when</strong> : Configurez des conditions personnalisées pour définir des erreurs, en fonction de l’état d’une variable ou du résultat d’une tâche.</li>
</ul>
<p><strong>Exemple de gestion des erreurs</strong> :</p>
<pre><code class="language-yaml">- name: Vérifier si Apache est installé
  command: "dpkg -l | grep apache2"
  register: apache_check
  ignore_errors: true

- name: Redémarrer Apache si installé
  service:
    name: apache2
    state: restarted
  when: apache_check.rc == 0
</code></pre>
<p><strong>Exercice</strong> : Créer un playbook avec des erreurs intentionnelles et utiliser les techniques de débogage pour les corriger</p>
<ol>
<li>Écrivez un playbook avec des erreurs intentionnelles (ex. : tâche de démarrage d'un service non installé).</li>
<li>Utilisez le mode verbeux et le module <code>debug</code> pour identifier et corriger les erreurs.</li>
</ol>
<hr />
<h3 id="63-optimisation-de-lexécution-ansible-sur-des-infrastructures-aws"><a class="header" href="#63-optimisation-de-lexécution-ansible-sur-des-infrastructures-aws">6.3 Optimisation de l’Exécution Ansible sur des Infrastructures AWS</a></h3>
<p>L’optimisation des playbooks est cruciale pour exécuter efficacement des tâches sur des infrastructures de grande envergure comme celles sur AWS.</p>
<h4 id="techniques-doptimisation"><a class="header" href="#techniques-doptimisation">Techniques d’optimisation</a></h4>
<ul>
<li><strong>Connexions parallèles</strong> : Configurez Ansible pour exécuter plusieurs tâches en parallèle en ajustant le paramètre <code>forks</code> dans <code>ansible.cfg</code>.</li>
<li><strong>Modules adaptés à AWS</strong> : Utilisez les modules AWS (<code>ec2</code>, <code>aws_s3</code>, etc.) pour des actions spécifiques, car ils sont optimisés pour les API AWS et réduisent les latences.</li>
<li><strong>Utilisez des rôles et des filtres de cible</strong> : Limitez le nombre de machines ou services impactés en utilisant des filtres précis dans l’inventaire ou le playbook.</li>
</ul>
<p><strong>Exemple d’optimisation avec le paramètre forks</strong> :</p>
<pre><code class="language-ini"># dans ansible.cfg
[defaults]
forks = 10
</code></pre>
<p><strong>Exercice</strong> : Optimiser un playbook existant pour le rendre plus rapide et plus résilient</p>
<ol>
<li>Prenez un playbook existant avec plusieurs tâches de provisioning AWS.</li>
<li>Augmentez la parallélisation en configurant le paramètre <code>forks</code>.</li>
<li>Exécutez le playbook optimisé et comparez le temps d'exécution.</li>
</ol>
<hr />
<h3 id="liens-vers-la-documentation-8"><a class="header" href="#liens-vers-la-documentation-8">Liens vers la Documentation</a></h3>
<ul>
<li><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_debugger.html">Documentation officielle de débogage dans Ansible</a></li>
<li><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_error_handling.html">Guide de gestion des erreurs dans Ansible</a></li>
<li><a href="https://docs.ansible.com/ansible/latest/user_guide/intro_getting_started.html#scaling-out-with-ansible">Optimisation des performances d’Ansible</a></li>
</ul>
<hr />
<h3 id="questions-de-révision-12"><a class="header" href="#questions-de-révision-12">Questions de Révision</a></h3>
<details>
<summary><h3 style="display:inline-block">Questions de Révision</h3></summary>
<details>
<summary>Pourquoi est-il important de nommer explicitement chaque tâche dans un playbook ?</summary>
<details>
<summary>Solution</summary>
Un nom explicite facilite le suivi de l'exécution et le débogage, permettant de comprendre rapidement ce que fait chaque tâche.
</details>
</details>
<details>
<summary>Quels sont les niveaux de verbosité disponibles dans Ansible pour le débogage ?</summary>
<details>
<summary>Solution</summary>
Ansible propose différents niveaux de verbosité : `-v`, `-vv`, `-vvv`, et `-vvvv`, avec un niveau plus élevé affichant plus de détails.
</details>
</details>
<details>
<summary>Comment optimiser l'exécution d'Ansible sur des infrastructures AWS étendues ?</summary>
<details>
<summary>Solution</summary>
En utilisant des connexions parallèles (via `forks`), en optimisant les modules AWS, et en ciblant précisément les hôtes et services nécessaires.
</details>
</details>
</details>
<hr />
<h3 id="conseils-pratiques-8"><a class="header" href="#conseils-pratiques-8">Conseils Pratiques</a></h3>
<ol>
<li><strong>Utilisez des niveaux de verbosité appropriés pour chaque étape de débogage</strong> : Cela vous aide à obtenir les informations nécessaires sans encombrer les logs.</li>
<li><strong>Commentez et documentez les playbooks</strong> : Les playbooks bien documentés sont plus faciles à lire et à maintenir par les équipes.</li>
<li><strong>Utilisez des fichiers d’inventaire dynamiques pour les infrastructures de grande envergure</strong> : Cela permet de gérer facilement des infrastructures cloud comme AWS.
<a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html">Guide des bonnes pratiques Ansible</a></li>
</ol>
<hr />
<h3 id="défi-intermédiaire-7"><a class="header" href="#défi-intermédiaire-7">Défi Intermédiaire</a></h3>
<details>
<summary><h3 style="display:inline-block">Défi Intermédiaire</h3></summary>
**Objectif** : Optimiser et déboguer un playbook Ansible pour gérer une infrastructure AWS étendue avec un déploiement rapide et résilient.
<p><strong>Contexte</strong> : Vous avez un playbook qui configure une infrastructure sur AWS avec plusieurs tâches. Le but est d’optimiser l’exécution et de gérer les erreurs efficacement pour un déploiement en production.</p>
<details>
<summary><b>Étapes principales</b></summary>
1. Modifiez `ansible.cfg` pour augmenter le paramètre `forks`.
2. Ajoutez des commandes de débogage avec le module `debug` pour afficher les variables clés.
3. Utilisez `ignore_errors` et `failed_when` pour gérer les erreurs de manière ciblée.
</details>
<p><strong>Compétences renforcées</strong> :</p>
<ul>
<li>Optimisation de la performance et de la résilience des playbooks Ansible</li>
<li>Gestion avancée des erreurs et débogage</li>
</ul>
<details>
<summary><b>Solution suggérée</b></summary>
Utilisez un playbook comme suit :
<pre><code class="language-yaml">- name: Déploiement optimisé sur AWS
  hosts: aws_instances
  tasks:
    - name: Provisionner une instance EC2
      ec2:
        instance_type: "t2.micro"
        image: "ami-0abcdef1234567890"
      register: ec2_info

    - name: Vérification du service après provisionnement
      service:
        name: "httpd"
        state: started
      ignore_errors: true
      when: ec2_info.changed
</code></pre>
<p>Dans <code>ansible.cfg</code>, définissez :</p>
<pre><code class="language-ini">[defaults]
forks = 10
</code></pre>
</details>
</details>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
